{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joyuno/collection-of-side-project/blob/main/%5BBaseline%5D_XGBoost%EB%A5%BC_%ED%99%9C%EC%9A%A9%ED%95%9C_%EC%B1%84%EB%AC%B4_%EB%B6%88%EC%9D%B4%ED%96%89_%EC%97%AC%EB%B6%80_%EC%98%88%EC%B8%A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ad0e82c-095a-41dd-a2ee-70e584857435",
      "metadata": {
        "id": "4ad0e82c-095a-41dd-a2ee-70e584857435"
      },
      "source": [
        "## 1. Import"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-learn scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRAhInifaqSr",
        "outputId": "419d2bd3-5c5a-44d2-8779-52c80b2013d4"
      },
      "id": "FRAhInifaqSr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting scikit-learn\n",
            "  Using cached scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Using cached scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: scikit-learn\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed scikit-learn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0919eeb-bbb3-48d4-ae3f-3dac6b370d95",
      "metadata": {
        "id": "b0919eeb-bbb3-48d4-ae3f-3dac6b370d95"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from xgboost import XGBClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd8b152b-c7a9-40f1-975a-516b764fcadd",
      "metadata": {
        "id": "cd8b152b-c7a9-40f1-975a-516b764fcadd"
      },
      "source": [
        "## 2. Data Load"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh_4yhIXs8d6",
        "outputId": "1a61052c-98db-4c40-ca6b-9d3f3aa03959"
      },
      "id": "Yh_4yhIXs8d6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kEAir4IqtD3T",
        "outputId": "6d7a5062-2498-4e69-bff3-4342460911cd"
      },
      "id": "kEAir4IqtD3T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feed2e5f-fb44-4ec5-8546-711ee29221cd",
      "metadata": {
        "id": "feed2e5f-fb44-4ec5-8546-711ee29221cd"
      },
      "outputs": [],
      "source": [
        "# 학습/평가 데이터 로드\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/dacon_project_default_prediction/train.csv').drop(columns=['UID'])\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/dacon_project_default_prediction/test.csv').drop(columns=['UID'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head() # 연간 소득 비중 보기\n",
        "\n",
        "# '대출 상환 기간' 0,1로 바꾸기\n",
        "# 총부채상환비율 (DTI) = (월 상환 부채액 / 연간 소득)\n",
        "#train_df['DTI'] = train_df['월 상환 부채액'] / (train_df['연간 소득'] / 12)\n",
        "\n",
        "# 신용 한도 대비 미상환액 비율 (Credit Utilization)\n",
        "#train_df['Credit_Utilization'] = train_df['현재 미상환 신용액'] / train_df['최대 신용한도']\n",
        "# ['연간 소득', '최대 신용한도', '현재 대출 잔액', '현재 미상환 신용액', '월 상환 부채액'] 로그변환\n",
        "#log_features = ['연간 소득', '최대 신용한도', '현재 대출 잔액', '현재 미상환 신용액', '월 상환 부채액']\n",
        "#for col in log_features:\n",
        "#    train_df[col] = np.log1p(train_df[col])  # log(1+x) 변환\n",
        "# train_df['근속 안정성'] = train_df['현재 직장 근속 연수'].apply(lambda x: 1 if x >= 7 else 0)\n",
        "#train_df['최근 연체 여부'] = train_df['마지막 연체 이후 경과 개월 수'].apply(lambda x: 1 if x < 12 else 0)\n",
        "#train_df['신용 이력 그룹'] = pd.cut(train_df['신용 거래 연수'], bins=[5, 10, 15, 20, 50], labels=[0, 1, 2, 3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "VWAPwKp9ulYT",
        "outputId": "fd503f53-4622-4db0-cf3a-7daab5525ca2"
      },
      "id": "VWAPwKp9ulYT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  주거 형태      연간 소득 현재 직장 근속 연수  체납 세금 압류 횟수  개설된 신용계좌 수  신용 거래 연수   최대 신용한도  \\\n",
              "0    자가  1941337.5      10년 이상          0.0           9      13.4  400597.5   \n",
              "1    월세  1979505.0      10년 이상          0.0           5      15.1  360679.5   \n",
              "2    월세  1356381.0          4년          0.0          12      18.8  491770.5   \n",
              "3    월세  1049017.5          6년          0.0          15      14.8  411546.0   \n",
              "4    월세  4320217.5          2년          0.0          11      26.1  895288.5   \n",
              "\n",
              "   신용 문제 발생 횟수  마지막 연체 이후 경과 개월 수  개인 파산 횟수  대출 목적 대출 상환 기간   현재 대출 잔액  \\\n",
              "0            0                 24         1  부채 통합    단기 상환   390903.0   \n",
              "1            0                 11         0  부채 통합    단기 상환  1002184.5   \n",
              "2            1                 74         3  부채 통합    단기 상환   227775.0   \n",
              "3            1                 22         1  부채 통합    단기 상환   251383.5   \n",
              "4            0                 32         0  부채 통합    장기 상환  1163176.5   \n",
              "\n",
              "   현재 미상환 신용액  월 상환 부채액  신용 점수  채무 불이행 여부  \n",
              "0    225457.5    8806.5    767          0  \n",
              "1     64749.0   24961.5    767          0  \n",
              "2    487644.0   12069.0    800          1  \n",
              "3    413211.0   31749.0    796          1  \n",
              "4     78991.5    5862.0    751          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f87fcd05-b476-408a-9446-7b4ec909066d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>주거 형태</th>\n",
              "      <th>연간 소득</th>\n",
              "      <th>현재 직장 근속 연수</th>\n",
              "      <th>체납 세금 압류 횟수</th>\n",
              "      <th>개설된 신용계좌 수</th>\n",
              "      <th>신용 거래 연수</th>\n",
              "      <th>최대 신용한도</th>\n",
              "      <th>신용 문제 발생 횟수</th>\n",
              "      <th>마지막 연체 이후 경과 개월 수</th>\n",
              "      <th>개인 파산 횟수</th>\n",
              "      <th>대출 목적</th>\n",
              "      <th>대출 상환 기간</th>\n",
              "      <th>현재 대출 잔액</th>\n",
              "      <th>현재 미상환 신용액</th>\n",
              "      <th>월 상환 부채액</th>\n",
              "      <th>신용 점수</th>\n",
              "      <th>채무 불이행 여부</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>자가</td>\n",
              "      <td>1941337.5</td>\n",
              "      <td>10년 이상</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>13.4</td>\n",
              "      <td>400597.5</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>부채 통합</td>\n",
              "      <td>단기 상환</td>\n",
              "      <td>390903.0</td>\n",
              "      <td>225457.5</td>\n",
              "      <td>8806.5</td>\n",
              "      <td>767</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>월세</td>\n",
              "      <td>1979505.0</td>\n",
              "      <td>10년 이상</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>15.1</td>\n",
              "      <td>360679.5</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>부채 통합</td>\n",
              "      <td>단기 상환</td>\n",
              "      <td>1002184.5</td>\n",
              "      <td>64749.0</td>\n",
              "      <td>24961.5</td>\n",
              "      <td>767</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>월세</td>\n",
              "      <td>1356381.0</td>\n",
              "      <td>4년</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>18.8</td>\n",
              "      <td>491770.5</td>\n",
              "      <td>1</td>\n",
              "      <td>74</td>\n",
              "      <td>3</td>\n",
              "      <td>부채 통합</td>\n",
              "      <td>단기 상환</td>\n",
              "      <td>227775.0</td>\n",
              "      <td>487644.0</td>\n",
              "      <td>12069.0</td>\n",
              "      <td>800</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>월세</td>\n",
              "      <td>1049017.5</td>\n",
              "      <td>6년</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15</td>\n",
              "      <td>14.8</td>\n",
              "      <td>411546.0</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>부채 통합</td>\n",
              "      <td>단기 상환</td>\n",
              "      <td>251383.5</td>\n",
              "      <td>413211.0</td>\n",
              "      <td>31749.0</td>\n",
              "      <td>796</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>월세</td>\n",
              "      <td>4320217.5</td>\n",
              "      <td>2년</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11</td>\n",
              "      <td>26.1</td>\n",
              "      <td>895288.5</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>부채 통합</td>\n",
              "      <td>장기 상환</td>\n",
              "      <td>1163176.5</td>\n",
              "      <td>78991.5</td>\n",
              "      <td>5862.0</td>\n",
              "      <td>751</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f87fcd05-b476-408a-9446-7b4ec909066d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f87fcd05-b476-408a-9446-7b4ec909066d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f87fcd05-b476-408a-9446-7b4ec909066d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c95fa1de-1136-4a36-964b-5e216b0e06f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c95fa1de-1136-4a36-964b-5e216b0e06f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c95fa1de-1136-4a36-964b-5e216b0e06f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"#train_df['\\ucd5c\\uadfc \\uc5f0\\uccb4 \\uc5ec\\ubd80'] = train_df['\\ub9c8\\uc9c0\\ub9c9 \\uc5f0\\uccb4 \\uc774\\ud6c4 \\uacbd\\uacfc \\uac1c\\uc6d4 \\uc218']\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"\\uc8fc\\uac70 \\ud615\\ud0dc\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc6d4\\uc138\",\n          \"\\uc790\\uac00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc5f0\\uac04 \\uc18c\\ub4dd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1286691.6875518686,\n        \"min\": 1049017.5,\n        \"max\": 4320217.5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1979505.0,\n          4320217.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud604\\uc7ac \\uc9c1\\uc7a5 \\uadfc\\uc18d \\uc5f0\\uc218\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"4\\ub144\",\n          \"2\\ub144\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uccb4\\ub0a9 \\uc138\\uae08 \\uc555\\ub958 \\ud69f\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac1c\\uc124\\ub41c \\uc2e0\\uc6a9\\uacc4\\uc88c \\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 5,\n        \"max\": 15,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc2e0\\uc6a9 \\uac70\\ub798 \\uc5f0\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.133517312720393,\n        \"min\": 13.4,\n        \"max\": 26.1,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          15.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ucd5c\\ub300 \\uc2e0\\uc6a9\\ud55c\\ub3c4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 219498.70213750695,\n        \"min\": 360679.5,\n        \"max\": 895288.5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          360679.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc2e0\\uc6a9 \\ubb38\\uc81c \\ubc1c\\uc0dd \\ud69f\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9c8\\uc9c0\\ub9c9 \\uc5f0\\uccb4 \\uc774\\ud6c4 \\uacbd\\uacfc \\uac1c\\uc6d4 \\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24,\n        \"min\": 11,\n        \"max\": 74,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac1c\\uc778 \\ud30c\\uc0b0 \\ud69f\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub300\\ucd9c \\ubaa9\\uc801\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\ubd80\\ucc44 \\ud1b5\\ud569\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub300\\ucd9c \\uc0c1\\ud658 \\uae30\\uac04\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc7a5\\uae30 \\uc0c1\\ud658\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud604\\uc7ac \\ub300\\ucd9c \\uc794\\uc561\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 442288.2718311384,\n        \"min\": 227775.0,\n        \"max\": 1163176.5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1002184.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud604\\uc7ac \\ubbf8\\uc0c1\\ud658 \\uc2e0\\uc6a9\\uc561\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 191830.81808894785,\n        \"min\": 64749.0,\n        \"max\": 487644.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          64749.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc6d4 \\uc0c1\\ud658 \\ubd80\\ucc44\\uc561\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11134.85506977976,\n        \"min\": 5862.0,\n        \"max\": 31749.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          24961.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc2e0\\uc6a9 \\uc810\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 751,\n        \"max\": 800,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          800\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ucc44\\ubb34 \\ubd88\\uc774\\ud589 \\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['신용 거래 연수'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "zxu2ZjX1DTI4",
        "outputId": "f91b2233-09c7-46ae-8f96-3874b4f5011f"
      },
      "id": "zxu2ZjX1DTI4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    10000.000000\n",
              "mean        19.879360\n",
              "std          7.206693\n",
              "min          6.000000\n",
              "25%         14.600000\n",
              "50%         17.950000\n",
              "75%         24.100000\n",
              "max         51.700000\n",
              "Name: 신용 거래 연수, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>신용 거래 연수</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>19.879360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.206693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>14.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>17.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>24.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>51.700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.groupby('현재 직장 근속 연수')['현재 직장 근속 연수'].count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "SEIK16r5QGO3",
        "outputId": "fcdf164a-bcdb-4eea-e852-8d6106f18df5"
      },
      "id": "SEIK16r5QGO3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "현재 직장 근속 연수\n",
              "10년 이상    3828\n",
              "1년         581\n",
              "1년 미만      488\n",
              "2년        1225\n",
              "3년         523\n",
              "4년         541\n",
              "5년         729\n",
              "6년         357\n",
              "7년         619\n",
              "8년         841\n",
              "9년         268\n",
              "Name: 현재 직장 근속 연수, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>현재 직장 근속 연수</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>현재 직장 근속 연수</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10년 이상</th>\n",
              "      <td>3828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1년</th>\n",
              "      <td>581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1년 미만</th>\n",
              "      <td>488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2년</th>\n",
              "      <td>1225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3년</th>\n",
              "      <td>523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4년</th>\n",
              "      <td>541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5년</th>\n",
              "      <td>729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6년</th>\n",
              "      <td>357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7년</th>\n",
              "      <td>619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8년</th>\n",
              "      <td>841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9년</th>\n",
              "      <td>268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['마지막 연체 이후 경과 개월 수'].describe() # 24개월 기준으로 잡자 28도 시도"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "j04ayF1OBVJZ",
        "outputId": "36ec15e3-19fa-4369-a748-74dd501c27b1"
      },
      "id": "j04ayF1OBVJZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    10000.000000\n",
              "mean        30.889200\n",
              "std         20.011561\n",
              "min          0.000000\n",
              "25%         14.000000\n",
              "50%         28.000000\n",
              "75%         41.000000\n",
              "max         88.000000\n",
              "Name: 마지막 연체 이후 경과 개월 수, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>마지막 연체 이후 경과 개월 수</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>30.889200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>20.011561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>28.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>41.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>88.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['주거 형태'].value_counts() #get_dummies() 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "sJJNxA72vSa3",
        "outputId": "4415b6bf-7555-4383-f886-9196dde1ea60"
      },
      "id": "sJJNxA72vSa3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "월세                  4050\n",
              "주택 담보 대출 (거주 중)     3633\n",
              "자가                  2241\n",
              "주택 담보 대출 (비거주 중)      76\n",
              "Name: 주거 형태, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>주거 형태</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>월세</th>\n",
              "      <td>4050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>주택 담보 대출 (거주 중)</th>\n",
              "      <td>3633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>자가</th>\n",
              "      <td>2241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>주택 담보 대출 (비거주 중)</th>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe() #신용 점수가 최소점수가 502점이라는 점 주목\n",
        "# 반면 신용 거래 연수와 연간 소득 max 가 지나치게 튐,//신용 문제 발생 횟수와 개인 파산 횟수는 오버 샘플링 고려해보기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "hBxp6bXtvckR",
        "outputId": "6040b13e-384a-4740-b3d9-ddb1e0cf1b10"
      },
      "id": "hBxp6bXtvckR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              연간 소득   체납 세금 압류 횟수    개설된 신용계좌 수      신용 거래 연수       최대 신용한도  \\\n",
              "count  1.000000e+04  10000.000000  10000.000000  10000.000000  1.000000e+04   \n",
              "mean   2.163959e+06      0.199300     12.248900     19.879360  1.175265e+06   \n",
              "std    1.434430e+06      0.714304      4.620572      7.206693  1.604199e+06   \n",
              "min    2.676210e+05      0.000000      2.000000      6.000000  0.000000e+00   \n",
              "25%    1.311437e+06      0.000000      9.000000     14.600000  4.482476e+05   \n",
              "50%    1.743223e+06      0.000000     12.000000     17.950000  7.670910e+05   \n",
              "75%    2.447664e+06      0.000000     15.000000     24.100000  1.147283e+06   \n",
              "max    1.722975e+07      7.000000     35.000000     51.700000  2.323233e+07   \n",
              "\n",
              "       신용 문제 발생 횟수  마지막 연체 이후 경과 개월 수      개인 파산 횟수      현재 대출 잔액  \\\n",
              "count  10000.00000       10000.000000  10000.000000  1.000000e+04   \n",
              "mean       0.62620          30.889200      0.373200  5.061200e+05   \n",
              "std        1.23419          20.011561      0.843797  2.831462e+05   \n",
              "min        0.00000           0.000000      0.000000  2.917650e+04   \n",
              "25%        0.00000          14.000000      0.000000  3.001901e+05   \n",
              "50%        0.00000          28.000000      0.000000  4.743412e+05   \n",
              "75%        1.00000          41.000000      0.000000  5.919079e+05   \n",
              "max        7.00000          88.000000      3.000000  1.373613e+06   \n",
              "\n",
              "         현재 미상환 신용액      월 상환 부채액         신용 점수     채무 불이행 여부  \n",
              "count  1.000000e+04   10000.00000  10000.000000  10000.000000  \n",
              "mean   3.649126e+05   22367.28075    744.215000      0.341200  \n",
              "std    3.537942e+05   15186.49738     56.995698      0.474136  \n",
              "min    0.000000e+00       0.00000    502.000000      0.000000  \n",
              "25%    1.471856e+05   10893.75000    704.000000      0.000000  \n",
              "50%    2.547930e+05   20160.00000    756.000000      0.000000  \n",
              "75%    4.749180e+05   30647.25000    793.000000      1.000000  \n",
              "max    3.946300e+06  153574.50000    825.000000      1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d7e2f6e-e345-496b-ae3e-001704126c0f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>연간 소득</th>\n",
              "      <th>체납 세금 압류 횟수</th>\n",
              "      <th>개설된 신용계좌 수</th>\n",
              "      <th>신용 거래 연수</th>\n",
              "      <th>최대 신용한도</th>\n",
              "      <th>신용 문제 발생 횟수</th>\n",
              "      <th>마지막 연체 이후 경과 개월 수</th>\n",
              "      <th>개인 파산 횟수</th>\n",
              "      <th>현재 대출 잔액</th>\n",
              "      <th>현재 미상환 신용액</th>\n",
              "      <th>월 상환 부채액</th>\n",
              "      <th>신용 점수</th>\n",
              "      <th>채무 불이행 여부</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.000000e+04</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>1.000000e+04</td>\n",
              "      <td>10000.00000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>1.000000e+04</td>\n",
              "      <td>1.000000e+04</td>\n",
              "      <td>10000.00000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.163959e+06</td>\n",
              "      <td>0.199300</td>\n",
              "      <td>12.248900</td>\n",
              "      <td>19.879360</td>\n",
              "      <td>1.175265e+06</td>\n",
              "      <td>0.62620</td>\n",
              "      <td>30.889200</td>\n",
              "      <td>0.373200</td>\n",
              "      <td>5.061200e+05</td>\n",
              "      <td>3.649126e+05</td>\n",
              "      <td>22367.28075</td>\n",
              "      <td>744.215000</td>\n",
              "      <td>0.341200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.434430e+06</td>\n",
              "      <td>0.714304</td>\n",
              "      <td>4.620572</td>\n",
              "      <td>7.206693</td>\n",
              "      <td>1.604199e+06</td>\n",
              "      <td>1.23419</td>\n",
              "      <td>20.011561</td>\n",
              "      <td>0.843797</td>\n",
              "      <td>2.831462e+05</td>\n",
              "      <td>3.537942e+05</td>\n",
              "      <td>15186.49738</td>\n",
              "      <td>56.995698</td>\n",
              "      <td>0.474136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.676210e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.917650e+04</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>502.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.311437e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>4.482476e+05</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.001901e+05</td>\n",
              "      <td>1.471856e+05</td>\n",
              "      <td>10893.75000</td>\n",
              "      <td>704.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.743223e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>17.950000</td>\n",
              "      <td>7.670910e+05</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.743412e+05</td>\n",
              "      <td>2.547930e+05</td>\n",
              "      <td>20160.00000</td>\n",
              "      <td>756.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.447664e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>24.100000</td>\n",
              "      <td>1.147283e+06</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.919079e+05</td>\n",
              "      <td>4.749180e+05</td>\n",
              "      <td>30647.25000</td>\n",
              "      <td>793.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.722975e+07</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>51.700000</td>\n",
              "      <td>2.323233e+07</td>\n",
              "      <td>7.00000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.373613e+06</td>\n",
              "      <td>3.946300e+06</td>\n",
              "      <td>153574.50000</td>\n",
              "      <td>825.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d7e2f6e-e345-496b-ae3e-001704126c0f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d7e2f6e-e345-496b-ae3e-001704126c0f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d7e2f6e-e345-496b-ae3e-001704126c0f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e173a17f-1f34-4c33-97d1-04f4507f937b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e173a17f-1f34-4c33-97d1-04f4507f937b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e173a17f-1f34-4c33-97d1-04f4507f937b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# \\ubc18\\uba74 \\uc2e0\\uc6a9 \\uac70\\ub798 \\uc5f0\\uc218\\uc640 \\uc5f0\\uac04 \\uc18c\\ub4dd max \\uac00 \\uc9c0\\ub098\\uce58\\uac8c \\ud290,//\\uc2e0\\uc6a9 \\ubb38\\uc81c \\ubc1c\\uc0dd \\ud69f\\uc218\\uc640 \\uac1c\\uc778 \\ud30c\\uc0b0 \\ud69f\\uc218\\ub294 \\uc624\\ubc84 \\uc0d8\\ud50c\\ub9c1 \\uace0\\ub824\\ud574\\ubcf4\\uae30\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"\\uc5f0\\uac04 \\uc18c\\ub4dd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5681136.928411874,\n        \"min\": 10000.0,\n        \"max\": 17229747.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2163958.88415,\n          1743222.75,\n          10000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uccb4\\ub0a9 \\uc138\\uae08 \\uc555\\ub958 \\ud69f\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3535.135028967563,\n        \"min\": 0.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.1993,\n          7.0,\n          0.7143042300402054\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac1c\\uc124\\ub41c \\uc2e0\\uc6a9\\uacc4\\uc88c \\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3531.008903587309,\n        \"min\": 2.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          12.2489,\n          12.0,\n          10000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc2e0\\uc6a9 \\uac70\\ub798 \\uc5f0\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3528.418940467638,\n        \"min\": 6.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          19.879360000000002,\n          17.95,\n          10000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ucd5c\\ub300 \\uc2e0\\uc6a9\\ud55c\\ub3c4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7973996.220889643,\n        \"min\": 0.0,\n        \"max\": 23232333.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1175264.7378,\n          767091.0,\n          10000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc2e0\\uc6a9 \\ubb38\\uc81c \\ubc1c\\uc0dd \\ud69f\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3535.0366493554147,\n        \"min\": 0.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          10000.0,\n          0.6262,\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9c8\\uc9c0\\ub9c9 \\uc5f0\\uccb4 \\uc774\\ud6c4 \\uacbd\\uacfc \\uac1c\\uc6d4 \\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3524.4219933312197,\n        \"min\": 0.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          30.8892,\n          28.0,\n          10000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac1c\\uc778 \\ud30c\\uc0b0 \\ud69f\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3535.321063142793,\n        \"min\": 0.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3732,\n          3.0,\n          0.8437967523615031\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud604\\uc7ac \\ub300\\ucd9c \\uc794\\uc561\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 430579.7247137403,\n        \"min\": 10000.0,\n        \"max\": 1373613.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          506120.0004,\n          474341.25,\n          10000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud604\\uc7ac \\ubbf8\\uc0c1\\ud658 \\uc2e0\\uc6a9\\uc561\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1325081.9237097146,\n        \"min\": 0.0,\n        \"max\": 3946300.5,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          364912.6176,\n          254793.0,\n          10000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc6d4 \\uc0c1\\ud658 \\ubd80\\ucc44\\uc561\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49635.099393186814,\n        \"min\": 0.0,\n        \"max\": 153574.5,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          22367.28075,\n          20160.0,\n          10000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc2e0\\uc6a9 \\uc810\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3323.795847095799,\n        \"min\": 56.99569831103578,\n        \"max\": 10000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          744.215,\n          756.0,\n          10000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ucc44\\ubb34 \\ubd88\\uc774\\ud589 \\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3535.3917344113756,\n        \"min\": 0.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3412,\n          1.0,\n          0.4741360991361718\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['채무 불이행 여부'].value_counts() # 채무 불이행 여부 6588개로 오버 샘플링 하기? 안하기 둘다 비교\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# SMOTE 적용 (소수 클래스(1) 데이터 합성 생성)\n",
        "#smote = SMOTE(sampling_strategy=1.0, random_state=42)  # 1:1 비율로 맞춤\n",
        "#X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "39k3eCFCx-0b",
        "outputId": "21a258ca-1a2e-4418-d422-b840074cbce4"
      },
      "id": "39k3eCFCx-0b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6588\n",
              "1    3412\n",
              "Name: 채무 불이행 여부, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>채무 불이행 여부</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold1 = train_df['연간 소득'].quantile(0.99)\n",
        "threshold2 = train_df['연간 소득'].quantile(0.999)\n",
        "# 상위 1%,0.1% 값만 필터링\n",
        "top_1_percent = train_df[train_df['연간 소득'] > threshold1]\n",
        "top_0p1_percent = train_df[train_df['연간 소득'] > threshold2]"
      ],
      "metadata": {
        "id": "-vnSDsaoySc8"
      },
      "id": "-vnSDsaoySc8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(top_1_percent.shape[0])\n",
        "print(top_1_percent['연간 소득'].mean())\n",
        "print(top_1_percent['연간 소득'].min())\n",
        "print(top_1_percent['연간 소득'].max())\n",
        "print(top_0p1_percent.shape[0])\n",
        "print(top_0p1_percent['연간 소득'].mean())\n",
        "print(top_0p1_percent['연간 소득'].min())\n",
        "print(top_0p1_percent['연간 소득'].max())\n",
        "print(top_0p1_percent['연간 소득'].sort_values(ascending=False)) # 증가폭은 높은 편이나 이상치 급으로 튀지는 않음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjDw6TQZysxJ",
        "outputId": "7fb8c9e7-bc1c-40cb-ec4a-e04786a79ad3"
      },
      "id": "xjDw6TQZysxJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "10106717.715\n",
            "7605937.5\n",
            "17229747.0\n",
            "10\n",
            "14587826.85\n",
            "12979972.5\n",
            "17229747.0\n",
            "8386    17229747.0\n",
            "6790    16497990.0\n",
            "1518    16246152.0\n",
            "4013    15618802.5\n",
            "3995    14082696.0\n",
            "5934    13552071.0\n",
            "559     13243704.0\n",
            "2577    13219294.5\n",
            "1413    13207839.0\n",
            "7836    12979972.5\n",
            "Name: 연간 소득, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "annual_income = train_df['연간 소득'].sort_values(ascending=False).reset_index(drop=True)\n",
        "plt.hist(annual_income)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "t5JnwMD6wFqi",
        "outputId": "bd318f18-e9e4-4fa0-fe15-cb1e859d6e46"
      },
      "id": "t5JnwMD6wFqi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([5.932e+03, 2.889e+03, 8.400e+02, 2.110e+02, 6.000e+01, 3.400e+01,\n",
              "        1.700e+01, 1.200e+01, 1.000e+00, 4.000e+00]),\n",
              " array([  267621. ,  1963833.6,  3660046.2,  5356258.8,  7052471.4,\n",
              "         8748684. , 10444896.6, 12141109.2, 13837321.8, 15533534.4,\n",
              "        17229747. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 4000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe(include = \"O\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "SlWBvssXvqoe",
        "outputId": "c315c34b-a6fe-4b8b-cc9b-fec4de2325d3"
      },
      "id": "SlWBvssXvqoe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        주거 형태 현재 직장 근속 연수  대출 목적 대출 상환 기간\n",
              "count   10000       10000  10000    10000\n",
              "unique      4          11     14        2\n",
              "top        월세      10년 이상  부채 통합    단기 상환\n",
              "freq     4050        3828   7294     6975"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad8e9476-d275-4950-9aa5-29e59d4033e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>주거 형태</th>\n",
              "      <th>현재 직장 근속 연수</th>\n",
              "      <th>대출 목적</th>\n",
              "      <th>대출 상환 기간</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>월세</td>\n",
              "      <td>10년 이상</td>\n",
              "      <td>부채 통합</td>\n",
              "      <td>단기 상환</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>4050</td>\n",
              "      <td>3828</td>\n",
              "      <td>7294</td>\n",
              "      <td>6975</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad8e9476-d275-4950-9aa5-29e59d4033e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad8e9476-d275-4950-9aa5-29e59d4033e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad8e9476-d275-4950-9aa5-29e59d4033e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f449dfc2-41fe-4f9a-9ab8-a392cef89271\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f449dfc2-41fe-4f9a-9ab8-a392cef89271')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f449dfc2-41fe-4f9a-9ab8-a392cef89271 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"\\uc8fc\\uac70 \\ud615\\ud0dc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          \"4050\",\n          \"10000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud604\\uc7ac \\uc9c1\\uc7a5 \\uadfc\\uc18d \\uc5f0\\uc218\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          11,\n          \"3828\",\n          \"10000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub300\\ucd9c \\ubaa9\\uc801\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          14,\n          \"7294\",\n          \"10000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub300\\ucd9c \\uc0c1\\ud658 \\uae30\\uac04\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          \"6975\",\n          \"10000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.groupby('대출 상환 기간')['채무 불이행 여부'].value_counts() # 장기 상환자의 채무 불이행률이 더 높다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "sIL0f0lYC0Le",
        "outputId": "6eddd07a-4495-4e0d-a753-2641f0a7d5bd"
      },
      "id": "sIL0f0lYC0Le",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "대출 상환 기간  채무 불이행 여부\n",
              "단기 상환     0            4842\n",
              "          1            2133\n",
              "장기 상환     0            1746\n",
              "          1            1279\n",
              "Name: 채무 불이행 여부, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>채무 불이행 여부</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>대출 상환 기간</th>\n",
              "      <th>채무 불이행 여부</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">단기 상환</th>\n",
              "      <th>0</th>\n",
              "      <td>4842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">장기 상환</th>\n",
              "      <th>0</th>\n",
              "      <td>1746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1279</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 피처 엔지니어링 변형부분만\n"
      ],
      "metadata": {
        "id": "Wb4rMsutGpd4"
      },
      "id": "Wb4rMsutGpd4"
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['대출 상환 기간']"
      ],
      "metadata": {
        "id": "h-CfXLhNGvXN"
      },
      "id": "h-CfXLhNGvXN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_default = train_df[train_df['채무 불이행 여부'] == 0].groupby('대출 목적')['채무 불이행 여부'].count()\n",
        "default = train_df[train_df['채무 불이행 여부'] == 1].groupby('대출 목적')['채무 불이행 여부'].count()\n",
        "all_purposes = train_df['대출 목적'].unique()\n",
        "\n",
        "# 인덱스를 통일하기 위해 reindex 사용\n",
        "non_default = non_default.reindex(all_purposes, fill_value=0)\n",
        "default = default.reindex(all_purposes, fill_value=0)\n",
        "\n",
        "# 같은 인덱스끼리 나누기\n",
        "print(default / (non_default.replace(0, np.nan)+1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cSX8V-tLjsa",
        "outputId": "ca50f58a-a8ae-4f7c-c4f1-104bafdb7240"
      },
      "id": "9cSX8V-tLjsa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "대출 목적\n",
            "부채 통합        0.662489\n",
            "자동차 구매       0.156627\n",
            "기타           0.277632\n",
            "사업 대출        0.225962\n",
            "주택 개보수       0.211718\n",
            "여행 자금        0.191781\n",
            "소규모 사업 자금    0.000000\n",
            "교육비          0.000000\n",
            "의료비          0.242188\n",
            "고액 구매        0.131148\n",
            "결혼 자금        0.153846\n",
            "휴가 비용        0.400000\n",
            "주택 구매        0.173913\n",
            "이사 비용        0.000000\n",
            "Name: 채무 불이행 여부, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_a=default / (non_default.replace(0, np.nan)+1)\n",
        "purpose_ratio=data_a.to_dict()\n",
        "purpose_ratio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTJN8FgIF_x9",
        "outputId": "6557409e-5540-4c12-f81e-a82f4b302b65"
      },
      "id": "jTJN8FgIF_x9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'부채 통합': 0.6624886052871468,\n",
              " '자동차 구매': 0.1566265060240964,\n",
              " '기타': 0.2776315789473684,\n",
              " '사업 대출': 0.22596153846153846,\n",
              " '주택 개보수': 0.21171770972037285,\n",
              " '여행 자금': 0.1917808219178082,\n",
              " '소규모 사업 자금': 0.0,\n",
              " '교육비': 0.0,\n",
              " '의료비': 0.2421875,\n",
              " '고액 구매': 0.13114754098360656,\n",
              " '결혼 자금': 0.15384615384615385,\n",
              " '휴가 비용': 0.4,\n",
              " '주택 구매': 0.17391304347826086,\n",
              " '이사 비용': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['대출 목적 비율'] = train_df['대출 목적'].map(purpose_ratio)\n",
        "test_df['대출 목적 비율'] = test_df['대출 목적'].map(purpose_ratio)"
      ],
      "metadata": {
        "id": "Op1La7CMfToy"
      },
      "id": "Op1La7CMfToy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=train_df.drop(columns=['대출 목적'])\n",
        "test_df=test_df.drop(columns=['대출 목적'])"
      ],
      "metadata": {
        "id": "dFXp0DFV1xQF"
      },
      "id": "dFXp0DFV1xQF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['최대 신용한도 대비 미상환율'] = train_df['현재 미상환 신용액'] / (train_df['최대 신용한도']+1)\n",
        "test_df['최대 신용한도 대비 미상환율'] = test_df['현재 미상환 신용액'] / (test_df['최대 신용한도']+1)"
      ],
      "metadata": {
        "id": "dF4GouxURiVG"
      },
      "id": "dF4GouxURiVG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['신용 거래 연수 그룹'] = pd.cut(train_df['신용 거래 연수'], bins=[5, 10, 15, 20, 50], labels=[0, 1, 2, 3])\n",
        "test_df['신용 거래 연수 그룹'] = pd.cut(test_df['신용 거래 연수'], bins=[5, 10, 15, 20, 50], labels=[0, 1, 2, 3])"
      ],
      "metadata": {
        "id": "qfirkV_sKPiH"
      },
      "id": "qfirkV_sKPiH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop(columns=['신용 거래 연수'])\n",
        "test_df = test_df.drop(columns=['신용 거래 연수'])"
      ],
      "metadata": {
        "id": "H4I8WiKI02un"
      },
      "id": "H4I8WiKI02un",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['최근 연체 여부'] = train_df['마지막 연체 이후 경과 개월 수'].apply(lambda x: 1 if x < 28 else 0)\n",
        "test_df['최근 연체 여부'] = test_df['마지막 연체 이후 경과 개월 수'].apply(lambda x: 1 if x < 28 else 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "3h4Dqe0GLjbZ",
        "outputId": "2aa9b83e-2fa1-47fd-cd69-1b63e99e6cca"
      },
      "id": "3h4Dqe0GLjbZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'마지막 연체 이후 경과 개월 수'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '마지막 연체 이후 경과 개월 수'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-db9a21b60fac>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'최근 연체 여부'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'마지막 연체 이후 경과 개월 수'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m28\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'최근 연체 여부'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'마지막 연체 이후 경과 개월 수'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m28\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '마지막 연체 이후 경과 개월 수'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=train_df.drop(columns= ['마지막 연체 이후 경과 개월 수'])\n",
        "test_df = test_df.drop(columns= ['마지막 연체 이후 경과 개월 수'])"
      ],
      "metadata": {
        "id": "cebCyozn1EYV"
      },
      "id": "cebCyozn1EYV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['근속 연수 7년이상'] = train_df['현재 직장 근속 연수'].apply(\n",
        "    lambda x: 1 if x in ['7년', '8년', '9년', '10년 이상'] else 0\n",
        ")\n",
        "test_df['근속 연수 7년이상'] = test_df['현재 직장 근속 연수'].apply(\n",
        "    lambda x: 1 if x in ['7년', '8년', '9년', '10년 이상'] else 0\n",
        ")"
      ],
      "metadata": {
        "id": "t2MxGwqGQxT_"
      },
      "id": "t2MxGwqGQxT_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.drop(columns=['현재 직장 근속 연수'], inplace=True)\n",
        "test_df.drop(columns=['현재 직장 근속 연수'], inplace=True)"
      ],
      "metadata": {
        "id": "ydgEK5fN1R5T"
      },
      "id": "ydgEK5fN1R5T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['대출 상환 기간'] = train_df['대출 상환 기간'].map({'장기 상환': 1, '단기 상환': 0})\n",
        "test_df['대출 상환 기간'] = test_df['대출 상환 기간'].map({'장기 상환': 1, '단기 상환': 0})"
      ],
      "metadata": {
        "id": "kXUK06NQRD9m"
      },
      "id": "kXUK06NQRD9m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IQR을 활용한 이상치 제거 함수\n",
        "def remove_outliers(df, column):\n",
        "    Q1 = df[column].quantile(0.001)\n",
        "    Q3 = df[column].quantile(0.999)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.3 * IQR\n",
        "    upper_bound = Q3 + 1.3 * IQR\n",
        "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "    return df\n",
        "\n",
        "outlier_features = ['체납 세금 압류 횟수', '개설된 신용계좌 수', '신용 문제 발생 횟수', '개인 파산 횟수']\n",
        "for col in outlier_features:\n",
        "    train_df = remove_outliers(train_df, col)"
      ],
      "metadata": {
        "id": "uut4JJ7zSDtk"
      },
      "id": "uut4JJ7zSDtk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "log_features = ['연간 소득', '최대 신용한도', '현재 대출 잔액', '현재 미상환 신용액', '월 상환 부채액']\n",
        "for col in log_features:\n",
        "    train_df[col] = np.log1p(train_df[col])\n",
        "    test_df[col] = np.log1p(test_df[col])"
      ],
      "metadata": {
        "id": "3bq34CsORvgn"
      },
      "id": "3bq34CsORvgn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_col = ['대출 목적']\n",
        "train_df['주거 형태'] = train_df['주거 형태'].map({'자가': 1, '주택 담보 대출 (거주 중)': 2, '월세':3, '주택 담보 대출 (비거주 중)': 4})\n",
        "test_df['주거 형태'] = test_df['주거 형태'].map({'자가': 1, '주택 담보 대출 (거주 중)': 2, '월세':3, '주택 담보 대출 (비거주 중)': 4})\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "\n",
        "# 훈련 데이터에 대해 인코더 학습\n",
        "encoder.fit(train_df[categorical_col])\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터 변환\n",
        "train_encoded = encoder.transform(train_df[categorical_col])\n",
        "test_encoded = encoder.transform(test_df[categorical_col])\n",
        "# One-hot encoding 결과를 데이터프레임으로 변환\n",
        "train_encoded_df = pd.DataFrame(train_encoded, columns=encoder.get_feature_names_out(categorical_col))\n",
        "test_encoded_df = pd.DataFrame(test_encoded, columns=encoder.get_feature_names_out(categorical_col))\n",
        "\n",
        "train_df = pd.concat([train_df.drop(columns=categorical_col).reset_index(drop=True), train_encoded_df], axis=1)\n",
        "test_df = pd.concat([test_df.drop(columns=categorical_col).reset_index(drop=True), test_encoded_df], axis=1)"
      ],
      "metadata": {
        "id": "R4zevy3IR5rM"
      },
      "id": "R4zevy3IR5rM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e3b0e69a-f09c-42d3-a263-72bde2fa77e0",
      "metadata": {
        "id": "e3b0e69a-f09c-42d3-a263-72bde2fa77e0"
      },
      "source": [
        "## 3. Pre-processing (전처리)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c070741-4532-4b3a-afc9-62ff99d2c3cc",
      "metadata": {
        "id": "7c070741-4532-4b3a-afc9-62ff99d2c3cc"
      },
      "outputs": [],
      "source": [
        "#categorical_col = [\n",
        "#    '현재 직장 근속 연수'\n",
        "#]\n",
        "#train_df['근속 연수 8년 이상 여부'] = train_df['현재 직장 근속 연수'].map(\n",
        "#    lambda x: 1 if x in ['8년', '9년', '10년 이상'] else 0\n",
        "#)\n",
        "#test_df['근속 연수 8년 이상 여부'] = test_df['현재 직장 근속 연수'].map(\n",
        "#    lambda x: 1 if x in ['8년', '9년', '10년 이상'] else 0\n",
        "#)\n",
        "train_df['주거 형태'] = train_df['주거 형태'].map({'자가': 1, '주택 담보 대출 (거주 중)': 2, '월세':3, '주택 담보 대출 (비거주 중)': 4})\n",
        "test_df['주거 형태'] = test_df['주거 형태'].map({'자가': 1, '주택 담보 대출 (거주 중)': 2, '월세':3, '주택 담보 대출 (비거주 중)': 4})\n",
        "#train_df['대출 상환 기간'] = train_df['대출 상환 기간'].map({'장기 상환': 1, '단기 상환': 0})\n",
        "#test_df['대출 상환 기간'] = test_df['대출 상환 기간'].map({'장기 상환': 1, '단기 상환': 0})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_df.drop(columns=['현재 직장 근속 연수','주거 형태'], inplace=True)\n",
        "#test_df.drop(columns=['현재 직장 근속 연수','주거 형태'], inplace=True)"
      ],
      "metadata": {
        "id": "0Qp6SfdbUfI-"
      },
      "id": "0Qp6SfdbUfI-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWgLzEXqVBdD",
        "outputId": "0b865be4-11f1-4e32-90cf-c3a2e918f684"
      },
      "id": "BWgLzEXqVBdD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['주거 형태', '연간 소득', '체납 세금 압류 횟수', '개설된 신용계좌 수', '최대 신용한도', '신용 문제 발생 횟수',\n",
              "       '개인 파산 횟수', '대출 상환 기간', '현재 대출 잔액', '현재 미상환 신용액', '월 상환 부채액', '신용 점수',\n",
              "       '채무 불이행 여부', '대출 목적 비율', '최대 신용한도 대비 미상환율', '신용 거래 연수 그룹',\n",
              "       '근속 연수 7년이상'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a121283-3c59-4ac8-992a-5b9745882556",
      "metadata": {
        "id": "1a121283-3c59-4ac8-992a-5b9745882556"
      },
      "source": [
        "## 4. Train / Validation Split (학습 데이터 분할)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df=train_df.dropna()"
      ],
      "metadata": {
        "id": "L8KvP1RxTnDN"
      },
      "id": "L8KvP1RxTnDN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns = train_df.columns.str.replace(\" \", \"_\")\n",
        "test_df.columns = test_df.columns.str.replace(\" \", \"_\")"
      ],
      "metadata": {
        "id": "SBTfbo07fhZK"
      },
      "id": "SBTfbo07fhZK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=train_df.drop(columns=['채무_불이행_여부'])\n",
        "y=train_df['채무_불이행_여부']"
      ],
      "metadata": {
        "id": "V9CXyHW632Xo"
      },
      "id": "V9CXyHW632Xo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    train_df.drop(columns=['채무_불이행_여부']),\n",
        "    train_df['채무_불이행_여부'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "DQsLsB-U3vSp"
      },
      "id": "DQsLsB-U3vSp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40e2ec54-eedc-4c0a-a919-95cfa384f0a4",
      "metadata": {
        "id": "40e2ec54-eedc-4c0a-a919-95cfa384f0a4"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    train_df.drop(columns=['채무_불이행_여부']),\n",
        "    train_df['채무_불이행_여부'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(sampling_strategy=1.0, random_state=42)  # 1:1 비율로 맞춤\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "7WbRtEKVSrVw"
      },
      "id": "7WbRtEKVSrVw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(sampling_strategy=1.0, random_state=42)  # 1:1 비율로 맞춤\n",
        "X_smote, y_smote = smote.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "cZuGPM-96A2O"
      },
      "id": "cZuGPM-96A2O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "Y06pRCruUxge",
        "outputId": "78dcbb55-5f46-48a9-9166-1c963e5138cb"
      },
      "id": "Y06pRCruUxge",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "주거_형태              0\n",
              "연간_소득              0\n",
              "체납_세금_압류_횟수        0\n",
              "개설된_신용계좌_수         0\n",
              "최대_신용한도            0\n",
              "신용_문제_발생_횟수        0\n",
              "개인_파산_횟수           0\n",
              "대출_상환_기간           0\n",
              "현재_대출_잔액           0\n",
              "현재_미상환_신용액         0\n",
              "월_상환_부채액           0\n",
              "신용_점수              0\n",
              "대출_목적_비율           0\n",
              "최대_신용한도_대비_미상환율    0\n",
              "신용_거래_연수_그룹        0\n",
              "근속_연수_7년이상         0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>주거_형태</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>연간_소득</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>체납_세금_압류_횟수</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>개설된_신용계좌_수</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>최대_신용한도</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>신용_문제_발생_횟수</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>개인_파산_횟수</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>대출_상환_기간</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>현재_대출_잔액</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>현재_미상환_신용액</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>월_상환_부채액</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>신용_점수</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>대출_목적_비율</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>최대_신용한도_대비_미상환율</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>신용_거래_연수_그룹</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>근속_연수_7년이상</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy4pD8jAcrTl",
        "outputId": "053dadb6-fa4f-444f-9a98-4d3e25ee1e4e"
      },
      "id": "Qy4pD8jAcrTl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7999, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_smote.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmHQOK4Qcx84",
        "outputId": "ceb6d7c7-c5e9-4412-ab92-12e857f85b21"
      },
      "id": "ZmHQOK4Qcx84",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9690, 44)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOyS8B2PUhso",
        "outputId": "933eb93e-2ff6-401a-f7aa-d6c03069cd86"
      },
      "id": "oOyS8B2PUhso",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2062, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87d5fe91-12bd-4467-81eb-530347ab14f2",
      "metadata": {
        "id": "87d5fe91-12bd-4467-81eb-530347ab14f2"
      },
      "source": [
        "## 5. Model Training (모델 학습)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(lgb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR-xmUtPnPm7",
        "outputId": "302f249e-06dc-4f47-8b2f-fc5f94f262c3"
      },
      "id": "uR-xmUtPnPm7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on package lightgbm:\n",
            "\n",
            "NAME\n",
            "    lightgbm - LightGBM, Light Gradient Boosting Machine.\n",
            "\n",
            "DESCRIPTION\n",
            "    Contributors: https://github.com/microsoft/LightGBM/graphs/contributors.\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    basic\n",
            "    callback\n",
            "    compat\n",
            "    dask\n",
            "    engine\n",
            "    libpath\n",
            "    plotting\n",
            "    sklearn\n",
            "\n",
            "CLASSES\n",
            "    abc.ABC(builtins.object)\n",
            "        lightgbm.basic.Sequence\n",
            "    builtins.Exception(builtins.BaseException)\n",
            "        lightgbm.callback.EarlyStopException\n",
            "    builtins.object\n",
            "        lightgbm.basic.Booster\n",
            "        lightgbm.basic.Dataset\n",
            "        lightgbm.engine.CVBooster\n",
            "    sklearn.base.BaseEstimator(sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin, sklearn.utils._metadata_requests._MetadataRequester)\n",
            "        lightgbm.sklearn.LGBMModel\n",
            "            lightgbm.sklearn.LGBMClassifier(sklearn.base.ClassifierMixin, lightgbm.sklearn.LGBMModel)\n",
            "                lightgbm.dask.DaskLGBMClassifier(lightgbm.sklearn.LGBMClassifier, lightgbm.dask._DaskLGBMModel)\n",
            "            lightgbm.sklearn.LGBMRanker\n",
            "                lightgbm.dask.DaskLGBMRanker(lightgbm.sklearn.LGBMRanker, lightgbm.dask._DaskLGBMModel)\n",
            "            lightgbm.sklearn.LGBMRegressor(sklearn.base.RegressorMixin, lightgbm.sklearn.LGBMModel)\n",
            "                lightgbm.dask.DaskLGBMRegressor(lightgbm.sklearn.LGBMRegressor, lightgbm.dask._DaskLGBMModel)\n",
            "    sklearn.base.ClassifierMixin(builtins.object)\n",
            "        lightgbm.sklearn.LGBMClassifier(sklearn.base.ClassifierMixin, lightgbm.sklearn.LGBMModel)\n",
            "            lightgbm.dask.DaskLGBMClassifier(lightgbm.sklearn.LGBMClassifier, lightgbm.dask._DaskLGBMModel)\n",
            "    sklearn.base.RegressorMixin(builtins.object)\n",
            "        lightgbm.sklearn.LGBMRegressor(sklearn.base.RegressorMixin, lightgbm.sklearn.LGBMModel)\n",
            "            lightgbm.dask.DaskLGBMRegressor(lightgbm.sklearn.LGBMRegressor, lightgbm.dask._DaskLGBMModel)\n",
            "    \n",
            "    class Booster(builtins.object)\n",
            "     |  Booster(params: Optional[Dict[str, Any]] = None, train_set: Optional[lightgbm.basic.Dataset] = None, model_file: Union[str, pathlib.Path, NoneType] = None, model_str: Optional[str] = None)\n",
            "     |  \n",
            "     |  Booster in LightGBM.\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __copy__(self) -> 'Booster'\n",
            "     |  \n",
            "     |  __deepcopy__(self, *args: Any, **kwargs: Any) -> 'Booster'\n",
            "     |  \n",
            "     |  __del__(self) -> None\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __init__(self, params: Optional[Dict[str, Any]] = None, train_set: Optional[lightgbm.basic.Dataset] = None, model_file: Union[str, pathlib.Path, NoneType] = None, model_str: Optional[str] = None)\n",
            "     |      Initialize the Booster.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      params : dict or None, optional (default=None)\n",
            "     |          Parameters for Booster.\n",
            "     |      train_set : Dataset or None, optional (default=None)\n",
            "     |          Training dataset.\n",
            "     |      model_file : str, pathlib.Path or None, optional (default=None)\n",
            "     |          Path to the model file.\n",
            "     |      model_str : str or None, optional (default=None)\n",
            "     |          Model will be loaded from this string.\n",
            "     |  \n",
            "     |  __setstate__(self, state: Dict[str, Any]) -> None\n",
            "     |  \n",
            "     |  add_valid(self, data: lightgbm.basic.Dataset, name: str) -> 'Booster'\n",
            "     |      Add validation data.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      data : Dataset\n",
            "     |          Validation data.\n",
            "     |      name : str\n",
            "     |          Name of validation data.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Booster\n",
            "     |          Booster with set validation data.\n",
            "     |  \n",
            "     |  current_iteration(self) -> int\n",
            "     |      Get the index of the current iteration.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      cur_iter : int\n",
            "     |          The index of the current iteration.\n",
            "     |  \n",
            "     |  dump_model(self, num_iteration: Optional[int] = None, start_iteration: int = 0, importance_type: str = 'split', object_hook: Optional[Callable[[Dict[str, Any]], Dict[str, Any]]] = None) -> Dict[str, Any]\n",
            "     |      Dump Booster to JSON format.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      num_iteration : int or None, optional (default=None)\n",
            "     |          Index of the iteration that should be dumped.\n",
            "     |          If None, if the best iteration exists, it is dumped; otherwise, all iterations are dumped.\n",
            "     |          If <= 0, all iterations are dumped.\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          Start index of the iteration that should be dumped.\n",
            "     |      importance_type : str, optional (default=\"split\")\n",
            "     |          What type of feature importance should be dumped.\n",
            "     |          If \"split\", result contains numbers of times the feature is used in a model.\n",
            "     |          If \"gain\", result contains total gains of splits which use the feature.\n",
            "     |      object_hook : callable or None, optional (default=None)\n",
            "     |          If not None, ``object_hook`` is a function called while parsing the json\n",
            "     |          string returned by the C API. It may be used to alter the json, to store\n",
            "     |          specific values while building the json structure. It avoids\n",
            "     |          walking through the structure again. It saves a significant amount\n",
            "     |          of time if the number of trees is huge.\n",
            "     |          Signature is ``def object_hook(node: dict) -> dict``.\n",
            "     |          None is equivalent to ``lambda node: node``.\n",
            "     |          See documentation of ``json.loads()`` for further details.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      json_repr : dict\n",
            "     |          JSON format of Booster.\n",
            "     |  \n",
            "     |  eval(self, data: lightgbm.basic.Dataset, name: str, feval: Union[Callable[[numpy.ndarray, lightgbm.basic.Dataset], Tuple[str, float, bool]], Callable[[numpy.ndarray, lightgbm.basic.Dataset], List[Tuple[str, float, bool]]], List[Union[Callable[[numpy.ndarray, lightgbm.basic.Dataset], Tuple[str, float, bool]], Callable[[numpy.ndarray, lightgbm.basic.Dataset], List[Tuple[str, float, bool]]]]], NoneType] = None) -> List[Tuple[str, str, float, bool]]\n",
            "     |      Evaluate for data.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      data : Dataset\n",
            "     |          Data for the evaluating.\n",
            "     |      name : str\n",
            "     |          Name of the data.\n",
            "     |      feval : callable, list of callable, or None, optional (default=None)\n",
            "     |          Customized evaluation function.\n",
            "     |          Each evaluation function should accept two parameters: preds, eval_data,\n",
            "     |          and return (eval_name, eval_result, is_higher_better) or list of such tuples.\n",
            "     |      \n",
            "     |              preds : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
            "     |                  The predicted values.\n",
            "     |                  For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes].\n",
            "     |                  If custom objective function is used, predicted values are returned before any transformation,\n",
            "     |                  e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
            "     |              eval_data : Dataset\n",
            "     |                  A ``Dataset`` to evaluate.\n",
            "     |              eval_name : str\n",
            "     |                  The name of evaluation function (without whitespace).\n",
            "     |              eval_result : float\n",
            "     |                  The eval result.\n",
            "     |              is_higher_better : bool\n",
            "     |                  Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      result : list\n",
            "     |          List with (dataset_name, eval_name, eval_result, is_higher_better) tuples.\n",
            "     |  \n",
            "     |  eval_train(self, feval: Union[Callable[[numpy.ndarray, lightgbm.basic.Dataset], Tuple[str, float, bool]], Callable[[numpy.ndarray, lightgbm.basic.Dataset], List[Tuple[str, float, bool]]], List[Union[Callable[[numpy.ndarray, lightgbm.basic.Dataset], Tuple[str, float, bool]], Callable[[numpy.ndarray, lightgbm.basic.Dataset], List[Tuple[str, float, bool]]]]], NoneType] = None) -> List[Tuple[str, str, float, bool]]\n",
            "     |      Evaluate for training data.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      feval : callable, list of callable, or None, optional (default=None)\n",
            "     |          Customized evaluation function.\n",
            "     |          Each evaluation function should accept two parameters: preds, eval_data,\n",
            "     |          and return (eval_name, eval_result, is_higher_better) or list of such tuples.\n",
            "     |      \n",
            "     |              preds : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
            "     |                  The predicted values.\n",
            "     |                  For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes].\n",
            "     |                  If custom objective function is used, predicted values are returned before any transformation,\n",
            "     |                  e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
            "     |              eval_data : Dataset\n",
            "     |                  The training dataset.\n",
            "     |              eval_name : str\n",
            "     |                  The name of evaluation function (without whitespace).\n",
            "     |              eval_result : float\n",
            "     |                  The eval result.\n",
            "     |              is_higher_better : bool\n",
            "     |                  Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      result : list\n",
            "     |          List with (train_dataset_name, eval_name, eval_result, is_higher_better) tuples.\n",
            "     |  \n",
            "     |  eval_valid(self, feval: Union[Callable[[numpy.ndarray, lightgbm.basic.Dataset], Tuple[str, float, bool]], Callable[[numpy.ndarray, lightgbm.basic.Dataset], List[Tuple[str, float, bool]]], List[Union[Callable[[numpy.ndarray, lightgbm.basic.Dataset], Tuple[str, float, bool]], Callable[[numpy.ndarray, lightgbm.basic.Dataset], List[Tuple[str, float, bool]]]]], NoneType] = None) -> List[Tuple[str, str, float, bool]]\n",
            "     |      Evaluate for validation data.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      feval : callable, list of callable, or None, optional (default=None)\n",
            "     |          Customized evaluation function.\n",
            "     |          Each evaluation function should accept two parameters: preds, eval_data,\n",
            "     |          and return (eval_name, eval_result, is_higher_better) or list of such tuples.\n",
            "     |      \n",
            "     |              preds : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
            "     |                  The predicted values.\n",
            "     |                  For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes].\n",
            "     |                  If custom objective function is used, predicted values are returned before any transformation,\n",
            "     |                  e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
            "     |              eval_data : Dataset\n",
            "     |                  The validation dataset.\n",
            "     |              eval_name : str\n",
            "     |                  The name of evaluation function (without whitespace).\n",
            "     |              eval_result : float\n",
            "     |                  The eval result.\n",
            "     |              is_higher_better : bool\n",
            "     |                  Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      result : list\n",
            "     |          List with (validation_dataset_name, eval_name, eval_result, is_higher_better) tuples.\n",
            "     |  \n",
            "     |  feature_importance(self, importance_type: str = 'split', iteration: Optional[int] = None) -> numpy.ndarray\n",
            "     |      Get feature importances.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      importance_type : str, optional (default=\"split\")\n",
            "     |          How the importance is calculated.\n",
            "     |          If \"split\", result contains numbers of times the feature is used in a model.\n",
            "     |          If \"gain\", result contains total gains of splits which use the feature.\n",
            "     |      iteration : int or None, optional (default=None)\n",
            "     |          Limit number of iterations in the feature importance calculation.\n",
            "     |          If None, if the best iteration exists, it is used; otherwise, all trees are used.\n",
            "     |          If <= 0, all trees are used (no limits).\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      result : numpy array\n",
            "     |          Array with feature importances.\n",
            "     |  \n",
            "     |  feature_name(self) -> List[str]\n",
            "     |      Get names of features.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      result : list of str\n",
            "     |          List with names of features.\n",
            "     |  \n",
            "     |  free_dataset(self) -> 'Booster'\n",
            "     |      Free Booster's Datasets.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Booster\n",
            "     |          Booster without Datasets.\n",
            "     |  \n",
            "     |  free_network(self) -> 'Booster'\n",
            "     |      Free Booster's network.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Booster\n",
            "     |          Booster with freed network.\n",
            "     |  \n",
            "     |  get_leaf_output(self, tree_id: int, leaf_id: int) -> float\n",
            "     |      Get the output of a leaf.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      tree_id : int\n",
            "     |          The index of the tree.\n",
            "     |      leaf_id : int\n",
            "     |          The index of the leaf in the tree.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      result : float\n",
            "     |          The output of the leaf.\n",
            "     |  \n",
            "     |  get_split_value_histogram(self, feature: Union[int, str], bins: Union[int, str, NoneType] = None, xgboost_style: bool = False) -> Union[Tuple[numpy.ndarray, numpy.ndarray], numpy.ndarray, pandas.core.frame.DataFrame]\n",
            "     |      Get split value histogram for the specified feature.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      feature : int or str\n",
            "     |          The feature name or index the histogram is calculated for.\n",
            "     |          If int, interpreted as index.\n",
            "     |          If str, interpreted as name.\n",
            "     |      \n",
            "     |          .. warning::\n",
            "     |      \n",
            "     |              Categorical features are not supported.\n",
            "     |      \n",
            "     |      bins : int, str or None, optional (default=None)\n",
            "     |          The maximum number of bins.\n",
            "     |          If None, or int and > number of unique split values and ``xgboost_style=True``,\n",
            "     |          the number of bins equals number of unique split values.\n",
            "     |          If str, it should be one from the list of the supported values by ``numpy.histogram()`` function.\n",
            "     |      xgboost_style : bool, optional (default=False)\n",
            "     |          Whether the returned result should be in the same form as it is in XGBoost.\n",
            "     |          If False, the returned value is tuple of 2 numpy arrays as it is in ``numpy.histogram()`` function.\n",
            "     |          If True, the returned value is matrix, in which the first column is the right edges of non-empty bins\n",
            "     |          and the second one is the histogram values.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      result_tuple : tuple of 2 numpy arrays\n",
            "     |          If ``xgboost_style=False``, the values of the histogram of used splitting values for the specified feature\n",
            "     |          and the bin edges.\n",
            "     |      result_array_like : numpy array or pandas DataFrame (if pandas is installed)\n",
            "     |          If ``xgboost_style=True``, the histogram of used splitting values for the specified feature.\n",
            "     |  \n",
            "     |  lower_bound(self) -> float\n",
            "     |      Get lower bound value of a model.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      lower_bound : float\n",
            "     |          Lower bound value of the model.\n",
            "     |  \n",
            "     |  model_from_string(self, model_str: str) -> 'Booster'\n",
            "     |      Load Booster from a string.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      model_str : str\n",
            "     |          Model will be loaded from this string.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Booster\n",
            "     |          Loaded Booster object.\n",
            "     |  \n",
            "     |  model_to_string(self, num_iteration: Optional[int] = None, start_iteration: int = 0, importance_type: str = 'split') -> str\n",
            "     |      Save Booster to string.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      num_iteration : int or None, optional (default=None)\n",
            "     |          Index of the iteration that should be saved.\n",
            "     |          If None, if the best iteration exists, it is saved; otherwise, all iterations are saved.\n",
            "     |          If <= 0, all iterations are saved.\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          Start index of the iteration that should be saved.\n",
            "     |      importance_type : str, optional (default=\"split\")\n",
            "     |          What type of feature importance should be saved.\n",
            "     |          If \"split\", result contains numbers of times the feature is used in a model.\n",
            "     |          If \"gain\", result contains total gains of splits which use the feature.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      str_repr : str\n",
            "     |          String representation of Booster.\n",
            "     |  \n",
            "     |  num_feature(self) -> int\n",
            "     |      Get number of features.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      num_feature : int\n",
            "     |          The number of features.\n",
            "     |  \n",
            "     |  num_model_per_iteration(self) -> int\n",
            "     |      Get number of models per iteration.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      model_per_iter : int\n",
            "     |          The number of models per iteration.\n",
            "     |  \n",
            "     |  num_trees(self) -> int\n",
            "     |      Get number of weak sub-models.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      num_trees : int\n",
            "     |          The number of weak sub-models.\n",
            "     |  \n",
            "     |  predict(self, data: Union[str, pathlib.Path, numpy.ndarray, pandas.core.frame.DataFrame, lightgbm.compat.dt_DataTable, scipy.sparse._matrix.spmatrix, pyarrow.lib.Table], start_iteration: int = 0, num_iteration: Optional[int] = None, raw_score: bool = False, pred_leaf: bool = False, pred_contrib: bool = False, data_has_header: bool = False, validate_features: bool = False, **kwargs: Any) -> Union[numpy.ndarray, scipy.sparse._matrix.spmatrix, List[scipy.sparse._matrix.spmatrix]]\n",
            "     |      Make a prediction.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      data : str, pathlib.Path, numpy array, pandas DataFrame, pyarrow Table, H2O DataTable's Frame or scipy.sparse\n",
            "     |          Data source for prediction.\n",
            "     |          If str or pathlib.Path, it represents the path to a text file (CSV, TSV, or LibSVM).\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          Start index of the iteration to predict.\n",
            "     |          If <= 0, starts from the first iteration.\n",
            "     |      num_iteration : int or None, optional (default=None)\n",
            "     |          Total number of iterations used in the prediction.\n",
            "     |          If None, if the best iteration exists and start_iteration <= 0, the best iteration is used;\n",
            "     |          otherwise, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |          If <= 0, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |      raw_score : bool, optional (default=False)\n",
            "     |          Whether to predict raw scores.\n",
            "     |      pred_leaf : bool, optional (default=False)\n",
            "     |          Whether to predict leaf index.\n",
            "     |      pred_contrib : bool, optional (default=False)\n",
            "     |          Whether to predict feature contributions.\n",
            "     |      \n",
            "     |          .. note::\n",
            "     |      \n",
            "     |              If you want to get more explanations for your model's predictions using SHAP values,\n",
            "     |              like SHAP interaction values,\n",
            "     |              you can install the shap package (https://github.com/slundberg/shap).\n",
            "     |              Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n",
            "     |              column, where the last column is the expected value.\n",
            "     |      \n",
            "     |      data_has_header : bool, optional (default=False)\n",
            "     |          Whether the data has header.\n",
            "     |          Used only if data is str.\n",
            "     |      validate_features : bool, optional (default=False)\n",
            "     |          If True, ensure that the features used to predict match the ones used to train.\n",
            "     |          Used only if data is pandas DataFrame.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the prediction.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      result : numpy array, scipy.sparse or list of scipy.sparse\n",
            "     |          Prediction result.\n",
            "     |          Can be sparse or a list of sparse objects (each element represents predictions for one class) for feature contributions (when ``pred_contrib=True``).\n",
            "     |  \n",
            "     |  refit(self, data: Union[str, pathlib.Path, numpy.ndarray, pandas.core.frame.DataFrame, lightgbm.compat.dt_DataTable, scipy.sparse._matrix.spmatrix, ForwardRef('Sequence'), List[ForwardRef('Sequence')], List[numpy.ndarray], pyarrow.lib.Table], label: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray], decay_rate: float = 0.9, reference: Optional[lightgbm.basic.Dataset] = None, weight: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, group: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, init_score: Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, feature_name: Union[List[str], ForwardRef(\"Literal['auto']\")] = 'auto', categorical_feature: Union[List[str], List[int], ForwardRef(\"Literal['auto']\")] = 'auto', dataset_params: Optional[Dict[str, Any]] = None, free_raw_data: bool = True, validate_features: bool = False, **kwargs: Any) -> 'Booster'\n",
            "     |      Refit the existing Booster by new data.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      data : str, pathlib.Path, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse, Sequence, list of Sequence or list of numpy array\n",
            "     |          Data source for refit.\n",
            "     |          If str or pathlib.Path, it represents the path to a text file (CSV, TSV, or LibSVM).\n",
            "     |      label : list, numpy 1-D array, pandas Series / one-column DataFrame, pyarrow Array or pyarrow ChunkedArray\n",
            "     |          Label for refit.\n",
            "     |      decay_rate : float, optional (default=0.9)\n",
            "     |          Decay rate of refit,\n",
            "     |          will use ``leaf_output = decay_rate * old_leaf_output + (1.0 - decay_rate) * new_leaf_output`` to refit trees.\n",
            "     |      reference : Dataset or None, optional (default=None)\n",
            "     |          Reference for ``data``.\n",
            "     |      \n",
            "     |          .. versionadded:: 4.0.0\n",
            "     |      \n",
            "     |      weight : list, numpy 1-D array, pandas Series, pyarrow Array, pyarrow ChunkedArray or None, optional (default=None)\n",
            "     |          Weight for each ``data`` instance. Weights should be non-negative.\n",
            "     |      \n",
            "     |          .. versionadded:: 4.0.0\n",
            "     |      \n",
            "     |      group : list, numpy 1-D array, pandas Series, pyarrow Array, pyarrow ChunkedArray or None, optional (default=None)\n",
            "     |          Group/query size for ``data``.\n",
            "     |          Only used in the learning-to-rank task.\n",
            "     |          sum(group) = n_samples.\n",
            "     |          For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |          where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |      \n",
            "     |          .. versionadded:: 4.0.0\n",
            "     |      \n",
            "     |      init_score : list, list of lists (for multi-class task), numpy array, pandas Series, pandas DataFrame (for multi-class task), pyarrow Array, pyarrow ChunkedArray, pyarrow Table (for multi-class task) or None, optional (default=None)\n",
            "     |          Init score for ``data``.\n",
            "     |      \n",
            "     |          .. versionadded:: 4.0.0\n",
            "     |      \n",
            "     |      feature_name : list of str, or 'auto', optional (default=\"auto\")\n",
            "     |          Feature names for ``data``.\n",
            "     |          If 'auto' and data is pandas DataFrame, data columns names are used.\n",
            "     |      \n",
            "     |          .. versionadded:: 4.0.0\n",
            "     |      \n",
            "     |      categorical_feature : list of str or int, or 'auto', optional (default=\"auto\")\n",
            "     |          Categorical features for ``data``.\n",
            "     |          If list of int, interpreted as indices.\n",
            "     |          If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
            "     |          If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
            "     |          All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
            "     |          Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
            "     |          All negative values in categorical features will be treated as missing values.\n",
            "     |          The output cannot be monotonically constrained with respect to a categorical feature.\n",
            "     |          Floating point numbers in categorical features will be rounded towards 0.\n",
            "     |      \n",
            "     |          .. versionadded:: 4.0.0\n",
            "     |      \n",
            "     |      dataset_params : dict or None, optional (default=None)\n",
            "     |          Other parameters for Dataset ``data``.\n",
            "     |      \n",
            "     |          .. versionadded:: 4.0.0\n",
            "     |      \n",
            "     |      free_raw_data : bool, optional (default=True)\n",
            "     |          If True, raw data is freed after constructing inner Dataset for ``data``.\n",
            "     |      \n",
            "     |          .. versionadded:: 4.0.0\n",
            "     |      \n",
            "     |      validate_features : bool, optional (default=False)\n",
            "     |          If True, ensure that the features used to refit the model match the original ones.\n",
            "     |          Used only if data is pandas DataFrame.\n",
            "     |      \n",
            "     |          .. versionadded:: 4.0.0\n",
            "     |      \n",
            "     |      **kwargs\n",
            "     |          Other parameters for refit.\n",
            "     |          These parameters will be passed to ``predict`` method.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      result : Booster\n",
            "     |          Refitted Booster.\n",
            "     |  \n",
            "     |  reset_parameter(self, params: Dict[str, Any]) -> 'Booster'\n",
            "     |      Reset parameters of Booster.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      params : dict\n",
            "     |          New parameters for Booster.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Booster\n",
            "     |          Booster with new parameters.\n",
            "     |  \n",
            "     |  rollback_one_iter(self) -> 'Booster'\n",
            "     |      Rollback one iteration.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Booster\n",
            "     |          Booster with rolled back one iteration.\n",
            "     |  \n",
            "     |  save_model(self, filename: Union[str, pathlib.Path], num_iteration: Optional[int] = None, start_iteration: int = 0, importance_type: str = 'split') -> 'Booster'\n",
            "     |      Save Booster to file.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      filename : str or pathlib.Path\n",
            "     |          Filename to save Booster.\n",
            "     |      num_iteration : int or None, optional (default=None)\n",
            "     |          Index of the iteration that should be saved.\n",
            "     |          If None, if the best iteration exists, it is saved; otherwise, all iterations are saved.\n",
            "     |          If <= 0, all iterations are saved.\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          Start index of the iteration that should be saved.\n",
            "     |      importance_type : str, optional (default=\"split\")\n",
            "     |          What type of feature importance should be saved.\n",
            "     |          If \"split\", result contains numbers of times the feature is used in a model.\n",
            "     |          If \"gain\", result contains total gains of splits which use the feature.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Booster\n",
            "     |          Returns self.\n",
            "     |  \n",
            "     |  set_leaf_output(self, tree_id: int, leaf_id: int, value: float) -> 'Booster'\n",
            "     |      Set the output of a leaf.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      tree_id : int\n",
            "     |          The index of the tree.\n",
            "     |      leaf_id : int\n",
            "     |          The index of the leaf in the tree.\n",
            "     |      value : float\n",
            "     |          Value to set as the output of the leaf.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Booster\n",
            "     |          Booster with the leaf output set.\n",
            "     |  \n",
            "     |  set_network(self, machines: Union[List[str], Set[str], str], local_listen_port: int = 12400, listen_time_out: int = 120, num_machines: int = 1) -> 'Booster'\n",
            "     |      Set the network configuration.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      machines : list, set or str\n",
            "     |          Names of machines.\n",
            "     |      local_listen_port : int, optional (default=12400)\n",
            "     |          TCP listen port for local machines.\n",
            "     |      listen_time_out : int, optional (default=120)\n",
            "     |          Socket time-out in minutes.\n",
            "     |      num_machines : int, optional (default=1)\n",
            "     |          The number of machines for distributed learning application.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Booster\n",
            "     |          Booster with set network.\n",
            "     |  \n",
            "     |  set_train_data_name(self, name: str) -> 'Booster'\n",
            "     |      Set the name to the training Dataset.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      name : str\n",
            "     |          Name for the training Dataset.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Booster\n",
            "     |          Booster with set training Dataset name.\n",
            "     |  \n",
            "     |  shuffle_models(self, start_iteration: int = 0, end_iteration: int = -1) -> 'Booster'\n",
            "     |      Shuffle models.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          The first iteration that will be shuffled.\n",
            "     |      end_iteration : int, optional (default=-1)\n",
            "     |          The last iteration that will be shuffled.\n",
            "     |          If <= 0, means the last available iteration.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Booster\n",
            "     |          Booster with shuffled models.\n",
            "     |  \n",
            "     |  trees_to_dataframe(self) -> pandas.core.frame.DataFrame\n",
            "     |      Parse the fitted model and return in an easy-to-read pandas DataFrame.\n",
            "     |      \n",
            "     |      The returned DataFrame has the following columns.\n",
            "     |      \n",
            "     |          - ``tree_index`` : int64, which tree a node belongs to. 0-based, so a value of ``6``, for example, means \"this node is in the 7th tree\".\n",
            "     |          - ``node_depth`` : int64, how far a node is from the root of the tree. The root node has a value of ``1``, its direct children are ``2``, etc.\n",
            "     |          - ``node_index`` : str, unique identifier for a node.\n",
            "     |          - ``left_child`` : str, ``node_index`` of the child node to the left of a split. ``None`` for leaf nodes.\n",
            "     |          - ``right_child`` : str, ``node_index`` of the child node to the right of a split. ``None`` for leaf nodes.\n",
            "     |          - ``parent_index`` : str, ``node_index`` of this node's parent. ``None`` for the root node.\n",
            "     |          - ``split_feature`` : str, name of the feature used for splitting. ``None`` for leaf nodes.\n",
            "     |          - ``split_gain`` : float64, gain from adding this split to the tree. ``NaN`` for leaf nodes.\n",
            "     |          - ``threshold`` : float64, value of the feature used to decide which side of the split a record will go down. ``NaN`` for leaf nodes.\n",
            "     |          - ``decision_type`` : str, logical operator describing how to compare a value to ``threshold``.\n",
            "     |            For example, ``split_feature = \"Column_10\", threshold = 15, decision_type = \"<=\"`` means that\n",
            "     |            records where ``Column_10 <= 15`` follow the left side of the split, otherwise follows the right side of the split. ``None`` for leaf nodes.\n",
            "     |          - ``missing_direction`` : str, split direction that missing values should go to. ``None`` for leaf nodes.\n",
            "     |          - ``missing_type`` : str, describes what types of values are treated as missing.\n",
            "     |          - ``value`` : float64, predicted value for this leaf node, multiplied by the learning rate.\n",
            "     |          - ``weight`` : float64 or int64, sum of Hessian (second-order derivative of objective), summed over observations that fall in this node.\n",
            "     |          - ``count`` : int64, number of records in the training data that fall into this node.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      result : pandas DataFrame\n",
            "     |          Returns a pandas DataFrame of the parsed model.\n",
            "     |  \n",
            "     |  update(self, train_set: Optional[lightgbm.basic.Dataset] = None, fobj: Optional[Callable[[numpy.ndarray, lightgbm.basic.Dataset], Tuple[numpy.ndarray, numpy.ndarray]]] = None) -> bool\n",
            "     |      Update Booster for one iteration.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      train_set : Dataset or None, optional (default=None)\n",
            "     |          Training data.\n",
            "     |          If None, last training data is used.\n",
            "     |      fobj : callable or None, optional (default=None)\n",
            "     |          Customized objective function.\n",
            "     |          Should accept two parameters: preds, train_data,\n",
            "     |          and return (grad, hess).\n",
            "     |      \n",
            "     |              preds : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
            "     |                  The predicted values.\n",
            "     |                  Predicted values are returned before any transformation,\n",
            "     |                  e.g. they are raw margin instead of probability of positive class for binary task.\n",
            "     |              train_data : Dataset\n",
            "     |                  The training dataset.\n",
            "     |              grad : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
            "     |                  The value of the first order derivative (gradient) of the loss\n",
            "     |                  with respect to the elements of preds for each sample point.\n",
            "     |              hess : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
            "     |                  The value of the second order derivative (Hessian) of the loss\n",
            "     |                  with respect to the elements of preds for each sample point.\n",
            "     |      \n",
            "     |          For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes],\n",
            "     |          and grad and hess should be returned in the same format.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      is_finished : bool\n",
            "     |          Whether the update was successfully finished.\n",
            "     |  \n",
            "     |  upper_bound(self) -> float\n",
            "     |      Get upper bound value of a model.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      upper_bound : float\n",
            "     |          Upper bound value of the model.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "    \n",
            "    class CVBooster(builtins.object)\n",
            "     |  CVBooster(model_file: Union[str, pathlib.Path, NoneType] = None)\n",
            "     |  \n",
            "     |  CVBooster in LightGBM.\n",
            "     |  \n",
            "     |  Auxiliary data structure to hold and redirect all boosters of ``cv()`` function.\n",
            "     |  This class has the same methods as Booster class.\n",
            "     |  All method calls, except for the following methods, are actually performed for underlying Boosters and\n",
            "     |  then all returned results are returned in a list.\n",
            "     |  \n",
            "     |  - ``model_from_string()``\n",
            "     |  - ``model_to_string()``\n",
            "     |  - ``save_model()``\n",
            "     |  \n",
            "     |  Attributes\n",
            "     |  ----------\n",
            "     |  boosters : list of Booster\n",
            "     |      The list of underlying fitted models.\n",
            "     |  best_iteration : int\n",
            "     |      The best iteration of fitted model.\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __getattr__(self, name: str) -> Callable[[Any, Any], List[Any]]\n",
            "     |      Redirect methods call of CVBooster.\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __init__(self, model_file: Union[str, pathlib.Path, NoneType] = None)\n",
            "     |      Initialize the CVBooster.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      model_file : str, pathlib.Path or None, optional (default=None)\n",
            "     |          Path to the CVBooster model file.\n",
            "     |  \n",
            "     |  __setstate__(self, state: Dict[str, Any]) -> None\n",
            "     |  \n",
            "     |  model_from_string(self, model_str: str) -> 'CVBooster'\n",
            "     |      Load CVBooster from a string.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      model_str : str\n",
            "     |          Model will be loaded from this string.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : CVBooster\n",
            "     |          Loaded CVBooster object.\n",
            "     |  \n",
            "     |  model_to_string(self, num_iteration: Optional[int] = None, start_iteration: int = 0, importance_type: str = 'split') -> str\n",
            "     |      Save CVBooster to JSON string.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      num_iteration : int or None, optional (default=None)\n",
            "     |          Index of the iteration that should be saved.\n",
            "     |          If None, if the best iteration exists, it is saved; otherwise, all iterations are saved.\n",
            "     |          If <= 0, all iterations are saved.\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          Start index of the iteration that should be saved.\n",
            "     |      importance_type : str, optional (default=\"split\")\n",
            "     |          What type of feature importance should be saved.\n",
            "     |          If \"split\", result contains numbers of times the feature is used in a model.\n",
            "     |          If \"gain\", result contains total gains of splits which use the feature.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      str_repr : str\n",
            "     |          JSON string representation of CVBooster.\n",
            "     |  \n",
            "     |  save_model(self, filename: Union[str, pathlib.Path], num_iteration: Optional[int] = None, start_iteration: int = 0, importance_type: str = 'split') -> 'CVBooster'\n",
            "     |      Save CVBooster to a file as JSON text.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      filename : str or pathlib.Path\n",
            "     |          Filename to save CVBooster.\n",
            "     |      num_iteration : int or None, optional (default=None)\n",
            "     |          Index of the iteration that should be saved.\n",
            "     |          If None, if the best iteration exists, it is saved; otherwise, all iterations are saved.\n",
            "     |          If <= 0, all iterations are saved.\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          Start index of the iteration that should be saved.\n",
            "     |      importance_type : str, optional (default=\"split\")\n",
            "     |          What type of feature importance should be saved.\n",
            "     |          If \"split\", result contains numbers of times the feature is used in a model.\n",
            "     |          If \"gain\", result contains total gains of splits which use the feature.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : CVBooster\n",
            "     |          Returns self.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "    \n",
            "    class DaskLGBMClassifier(lightgbm.sklearn.LGBMClassifier, _DaskLGBMModel)\n",
            "     |  DaskLGBMClassifier(boosting_type: str = 'gbdt', num_leaves: int = 31, max_depth: int = -1, learning_rate: float = 0.1, n_estimators: int = 100, subsample_for_bin: int = 200000, objective: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, class_weight: Union[dict, str, NoneType] = None, min_split_gain: float = 0.0, min_child_weight: float = 0.001, min_child_samples: int = 20, subsample: float = 1.0, subsample_freq: int = 0, colsample_bytree: float = 1.0, reg_alpha: float = 0.0, reg_lambda: float = 0.0, random_state: Union[int, numpy.random.mtrand.RandomState, ForwardRef('np.random.Generator'), NoneType] = None, n_jobs: Optional[int] = None, importance_type: str = 'split', client: Optional[lightgbm.compat.Client] = None, **kwargs: Any)\n",
            "     |  \n",
            "     |  Distributed version of lightgbm.LGBMClassifier.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      DaskLGBMClassifier\n",
            "     |      lightgbm.sklearn.LGBMClassifier\n",
            "     |      sklearn.base.ClassifierMixin\n",
            "     |      lightgbm.sklearn.LGBMModel\n",
            "     |      sklearn.base.BaseEstimator\n",
            "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
            "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
            "     |      _DaskLGBMModel\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[Any, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __init__(self, boosting_type: str = 'gbdt', num_leaves: int = 31, max_depth: int = -1, learning_rate: float = 0.1, n_estimators: int = 100, subsample_for_bin: int = 200000, objective: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, class_weight: Union[dict, str, NoneType] = None, min_split_gain: float = 0.0, min_child_weight: float = 0.001, min_child_samples: int = 20, subsample: float = 1.0, subsample_freq: int = 0, colsample_bytree: float = 1.0, reg_alpha: float = 0.0, reg_lambda: float = 0.0, random_state: Union[int, numpy.random.mtrand.RandomState, ForwardRef('np.random.Generator'), NoneType] = None, n_jobs: Optional[int] = None, importance_type: str = 'split', client: Optional[lightgbm.compat.Client] = None, **kwargs: Any)\n",
            "     |      Construct a gradient boosting model.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      boosting_type : str, optional (default='gbdt')\n",
            "     |          'gbdt', traditional Gradient Boosting Decision Tree.\n",
            "     |          'dart', Dropouts meet Multiple Additive Regression Trees.\n",
            "     |          'rf', Random Forest.\n",
            "     |      num_leaves : int, optional (default=31)\n",
            "     |          Maximum tree leaves for base learners.\n",
            "     |      max_depth : int, optional (default=-1)\n",
            "     |          Maximum tree depth for base learners, <=0 means no limit.\n",
            "     |          If setting this to a positive value, consider also changing ``num_leaves`` to ``<= 2^max_depth``.\n",
            "     |      learning_rate : float, optional (default=0.1)\n",
            "     |          Boosting learning rate.\n",
            "     |          You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n",
            "     |          in training using ``reset_parameter`` callback.\n",
            "     |          Note, that this will ignore the ``learning_rate`` argument in training.\n",
            "     |      n_estimators : int, optional (default=100)\n",
            "     |          Number of boosted trees to fit.\n",
            "     |      subsample_for_bin : int, optional (default=200000)\n",
            "     |          Number of samples for constructing bins.\n",
            "     |      objective : str, callable or None, optional (default=None)\n",
            "     |          Specify the learning task and the corresponding learning objective or\n",
            "     |          a custom objective function to be used (see note below).\n",
            "     |          Default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
            "     |      class_weight : dict, 'balanced' or None, optional (default=None)\n",
            "     |          Weights associated with classes in the form ``{class_label: weight}``.\n",
            "     |          Use this parameter only for multi-class classification task;\n",
            "     |          for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n",
            "     |          Note, that the usage of all these parameters will result in poor estimates of the individual class probabilities.\n",
            "     |          You may want to consider performing probability calibration\n",
            "     |          (https://scikit-learn.org/stable/modules/calibration.html) of your model.\n",
            "     |          The 'balanced' mode uses the values of y to automatically adjust weights\n",
            "     |          inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n",
            "     |          If None, all classes are supposed to have weight one.\n",
            "     |          Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)\n",
            "     |          if ``sample_weight`` is specified.\n",
            "     |      min_split_gain : float, optional (default=0.)\n",
            "     |          Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
            "     |      min_child_weight : float, optional (default=1e-3)\n",
            "     |          Minimum sum of instance weight (Hessian) needed in a child (leaf).\n",
            "     |      min_child_samples : int, optional (default=20)\n",
            "     |          Minimum number of data needed in a child (leaf).\n",
            "     |      subsample : float, optional (default=1.)\n",
            "     |          Subsample ratio of the training instance.\n",
            "     |      subsample_freq : int, optional (default=0)\n",
            "     |          Frequency of subsample, <=0 means no enable.\n",
            "     |      colsample_bytree : float, optional (default=1.)\n",
            "     |          Subsample ratio of columns when constructing each tree.\n",
            "     |      reg_alpha : float, optional (default=0.)\n",
            "     |          L1 regularization term on weights.\n",
            "     |      reg_lambda : float, optional (default=0.)\n",
            "     |          L2 regularization term on weights.\n",
            "     |      random_state : int, RandomState object or None, optional (default=None)\n",
            "     |          Random number seed.\n",
            "     |          If int, this number is used to seed the C++ code.\n",
            "     |          If RandomState or Generator object (numpy), a random integer is picked based on its state to seed the C++ code.\n",
            "     |          If None, default seeds in C++ code are used.\n",
            "     |      n_jobs : int or None, optional (default=None)\n",
            "     |          Number of parallel threads to use for training (can be changed at prediction time by\n",
            "     |          passing it as an extra keyword argument).\n",
            "     |      \n",
            "     |          For better performance, it is recommended to set this to the number of physical cores\n",
            "     |          in the CPU.\n",
            "     |      \n",
            "     |          Negative integers are interpreted as following joblib's formula (n_cpus + 1 + n_jobs), just like\n",
            "     |          scikit-learn (so e.g. -1 means using all threads). A value of zero corresponds the default number of\n",
            "     |          threads configured for OpenMP in the system. A value of ``None`` (the default) corresponds\n",
            "     |          to using the number of physical cores in the system (its correct detection requires\n",
            "     |          either the ``joblib`` or the ``psutil`` util libraries to be installed).\n",
            "     |      \n",
            "     |          .. versionchanged:: 4.0.0\n",
            "     |      \n",
            "     |      importance_type : str, optional (default='split')\n",
            "     |          The type of feature importance to be filled into ``feature_importances_``.\n",
            "     |          If 'split', result contains numbers of times the feature is used in a model.\n",
            "     |          If 'gain', result contains total gains of splits which use the feature.\n",
            "     |      client : dask.distributed.Client or None, optional (default=None)\n",
            "     |          Dask client. If ``None``, ``distributed.default_client()`` will be used at runtime. The Dask client used by this class will not be saved if the model object is pickled.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the model.\n",
            "     |          Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
            "     |      \n",
            "     |          .. warning::\n",
            "     |      \n",
            "     |              \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
            "     |      \n",
            "     |      Note\n",
            "     |      ----\n",
            "     |      A custom objective function can be provided for the ``objective`` parameter.\n",
            "     |      In this case, it should have the signature\n",
            "     |      ``objective(y_true, y_pred) -> grad, hess``,\n",
            "     |      ``objective(y_true, y_pred, weight) -> grad, hess``\n",
            "     |      or ``objective(y_true, y_pred, weight, group) -> grad, hess``:\n",
            "     |      \n",
            "     |          y_true : numpy 1-D array of shape = [n_samples]\n",
            "     |              The target values.\n",
            "     |          y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The predicted values.\n",
            "     |              Predicted values are returned before any transformation,\n",
            "     |              e.g. they are raw margin instead of probability of positive class for binary task.\n",
            "     |          weight : numpy 1-D array of shape = [n_samples]\n",
            "     |              The weight of samples. Weights should be non-negative.\n",
            "     |          group : numpy 1-D array\n",
            "     |              Group/query data.\n",
            "     |              Only used in the learning-to-rank task.\n",
            "     |              sum(group) = n_samples.\n",
            "     |              For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |              where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |          grad : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The value of the first order derivative (gradient) of the loss\n",
            "     |              with respect to the elements of y_pred for each sample point.\n",
            "     |          hess : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The value of the second order derivative (Hessian) of the loss\n",
            "     |              with respect to the elements of y_pred for each sample point.\n",
            "     |      \n",
            "     |      For multi-class task, y_pred is a numpy 2-D array of shape = [n_samples, n_classes],\n",
            "     |      and grad and hess should be returned in the same format.\n",
            "     |  \n",
            "     |  fit(self, X: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame], y: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame, lightgbm.compat.dask_Series], sample_weight: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_Series, NoneType] = None, init_score: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame, lightgbm.compat.dask_Series, NoneType] = None, eval_set: Optional[List[Tuple[Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame], Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame, lightgbm.compat.dask_Series]]]] = None, eval_names: Optional[List[str]] = None, eval_sample_weight: Optional[List[Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_Series]]] = None, eval_class_weight: Optional[List[Union[dict, str]]] = None, eval_init_score: Optional[List[Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame, lightgbm.compat.dask_Series]]] = None, eval_metric: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], List[Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]]]], NoneType] = None, **kwargs: Any) -> 'DaskLGBMClassifier'\n",
            "     |      Build a gradient boosting model from the training set (X, y).\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : Dask Array or Dask DataFrame of shape = [n_samples, n_features]\n",
            "     |          Input feature matrix.\n",
            "     |      y : Dask Array, Dask DataFrame or Dask Series of shape = [n_samples]\n",
            "     |          The target values (class labels in classification, real numbers in regression).\n",
            "     |      sample_weight : Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)\n",
            "     |          Weights of training data. Weights should be non-negative.\n",
            "     |      init_score : Dask Array or Dask Series of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task), or Dask Array or Dask DataFrame of shape = [n_samples, n_classes] (for multi-class task), or None, optional (default=None)\n",
            "     |          Init score of training data.\n",
            "     |      eval_set : list or None, optional (default=None)\n",
            "     |          A list of (X, y) tuple pairs to use as validation sets.\n",
            "     |      eval_names : list of str, or None, optional (default=None)\n",
            "     |          Names of eval_set.\n",
            "     |      eval_sample_weight : list of Dask Array or Dask Series, or None, optional (default=None)\n",
            "     |          Weights of eval data. Weights should be non-negative.\n",
            "     |      eval_class_weight : list or None, optional (default=None)\n",
            "     |          Class weights of eval data.\n",
            "     |      eval_init_score : list of Dask Array, Dask Series or Dask DataFrame (for multi-class task), or None, optional (default=None)\n",
            "     |          Init score of eval data.\n",
            "     |      eval_metric : str, callable, list or None, optional (default=None)\n",
            "     |          If str, it should be a built-in evaluation metric to use.\n",
            "     |          If callable, it should be a custom evaluation metric, see note below for more details.\n",
            "     |          If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.\n",
            "     |          In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n",
            "     |          Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n",
            "     |      feature_name : list of str, or 'auto', optional (default='auto')\n",
            "     |          Feature names.\n",
            "     |          If 'auto' and data is pandas DataFrame, data columns names are used.\n",
            "     |      categorical_feature : list of str or int, or 'auto', optional (default='auto')\n",
            "     |          Categorical features.\n",
            "     |          If list of int, interpreted as indices.\n",
            "     |          If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
            "     |          If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
            "     |          All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
            "     |          Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
            "     |          All negative values in categorical features will be treated as missing values.\n",
            "     |          The output cannot be monotonically constrained with respect to a categorical feature.\n",
            "     |          Floating point numbers in categorical features will be rounded towards 0.\n",
            "     |      **kwargs\n",
            "     |          Other parameters passed through to ``LGBMClassifier.fit()``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : lightgbm.DaskLGBMClassifier\n",
            "     |          Returns self.\n",
            "     |      \n",
            "     |      \n",
            "     |      Note\n",
            "     |      ----\n",
            "     |      Custom eval function expects a callable with following signatures:\n",
            "     |      ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
            "     |      ``func(y_true, y_pred, weight, group)``\n",
            "     |      and returns (eval_name, eval_result, is_higher_better) or\n",
            "     |      list of (eval_name, eval_result, is_higher_better):\n",
            "     |      \n",
            "     |          y_true : numpy 1-D array of shape = [n_samples]\n",
            "     |              The target values.\n",
            "     |          y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The predicted values.\n",
            "     |              In case of custom ``objective``, predicted values are returned before any transformation,\n",
            "     |              e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
            "     |          weight : numpy 1-D array of shape = [n_samples]\n",
            "     |              The weight of samples. Weights should be non-negative.\n",
            "     |          group : numpy 1-D array\n",
            "     |              Group/query data.\n",
            "     |              Only used in the learning-to-rank task.\n",
            "     |              sum(group) = n_samples.\n",
            "     |              For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |              where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |          eval_name : str\n",
            "     |              The name of evaluation function (without whitespace).\n",
            "     |          eval_result : float\n",
            "     |              The eval result.\n",
            "     |          is_higher_better : bool\n",
            "     |              Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
            "     |  \n",
            "     |  predict(self, X: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame], raw_score: bool = False, start_iteration: int = 0, num_iteration: Optional[int] = None, pred_leaf: bool = False, pred_contrib: bool = False, validate_features: bool = False, **kwargs: Any) -> lightgbm.compat.dask_Array\n",
            "     |      Return the predicted value for each sample.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : Dask Array or Dask DataFrame of shape = [n_samples, n_features]\n",
            "     |          Input features matrix.\n",
            "     |      raw_score : bool, optional (default=False)\n",
            "     |          Whether to predict raw scores.\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          Start index of the iteration to predict.\n",
            "     |          If <= 0, starts from the first iteration.\n",
            "     |      num_iteration : int or None, optional (default=None)\n",
            "     |          Total number of iterations used in the prediction.\n",
            "     |          If None, if the best iteration exists and start_iteration <= 0, the best iteration is used;\n",
            "     |          otherwise, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |          If <= 0, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |      pred_leaf : bool, optional (default=False)\n",
            "     |          Whether to predict leaf index.\n",
            "     |      pred_contrib : bool, optional (default=False)\n",
            "     |          Whether to predict feature contributions.\n",
            "     |      \n",
            "     |          .. note::\n",
            "     |      \n",
            "     |              If you want to get more explanations for your model's predictions using SHAP values,\n",
            "     |              like SHAP interaction values,\n",
            "     |              you can install the shap package (https://github.com/slundberg/shap).\n",
            "     |              Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n",
            "     |              column, where the last column is the expected value.\n",
            "     |      \n",
            "     |      validate_features : bool, optional (default=False)\n",
            "     |          If True, ensure that the features used to predict match the ones used to train.\n",
            "     |          Used only if data is pandas DataFrame.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the prediction.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      predicted_result : Dask Array of shape = [n_samples] or shape = [n_samples, n_classes]\n",
            "     |          The predicted values.\n",
            "     |      X_leaves : Dask Array of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]\n",
            "     |          If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n",
            "     |      X_SHAP_values : Dask Array of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or (if multi-class and using sparse inputs) a list of ``n_classes`` Dask Arrays of shape = [n_samples, n_features + 1]\n",
            "     |          If ``pred_contrib=True``, the feature contributions for each sample.\n",
            "     |  \n",
            "     |  predict_proba(self, X: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame], raw_score: bool = False, start_iteration: int = 0, num_iteration: Optional[int] = None, pred_leaf: bool = False, pred_contrib: bool = False, validate_features: bool = False, **kwargs: Any) -> lightgbm.compat.dask_Array\n",
            "     |      Return the predicted probability for each class for each sample.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : Dask Array or Dask DataFrame of shape = [n_samples, n_features]\n",
            "     |          Input features matrix.\n",
            "     |      raw_score : bool, optional (default=False)\n",
            "     |          Whether to predict raw scores.\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          Start index of the iteration to predict.\n",
            "     |          If <= 0, starts from the first iteration.\n",
            "     |      num_iteration : int or None, optional (default=None)\n",
            "     |          Total number of iterations used in the prediction.\n",
            "     |          If None, if the best iteration exists and start_iteration <= 0, the best iteration is used;\n",
            "     |          otherwise, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |          If <= 0, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |      pred_leaf : bool, optional (default=False)\n",
            "     |          Whether to predict leaf index.\n",
            "     |      pred_contrib : bool, optional (default=False)\n",
            "     |          Whether to predict feature contributions.\n",
            "     |      \n",
            "     |          .. note::\n",
            "     |      \n",
            "     |              If you want to get more explanations for your model's predictions using SHAP values,\n",
            "     |              like SHAP interaction values,\n",
            "     |              you can install the shap package (https://github.com/slundberg/shap).\n",
            "     |              Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n",
            "     |              column, where the last column is the expected value.\n",
            "     |      \n",
            "     |      validate_features : bool, optional (default=False)\n",
            "     |          If True, ensure that the features used to predict match the ones used to train.\n",
            "     |          Used only if data is pandas DataFrame.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the prediction.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      predicted_probability : Dask Array of shape = [n_samples] or shape = [n_samples, n_classes]\n",
            "     |          The predicted values.\n",
            "     |      X_leaves : Dask Array of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]\n",
            "     |          If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n",
            "     |      X_SHAP_values : Dask Array of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or (if multi-class and using sparse inputs) a list of ``n_classes`` Dask Arrays of shape = [n_samples, n_features + 1]\n",
            "     |          If ``pred_contrib=True``, the feature contributions for each sample.\n",
            "     |  \n",
            "     |  set_fit_request(self: lightgbm.dask.DaskLGBMClassifier, *, eval_class_weight: Union[bool, NoneType, str] = '$UNCHANGED$', eval_init_score: Union[bool, NoneType, str] = '$UNCHANGED$', eval_metric: Union[bool, NoneType, str] = '$UNCHANGED$', eval_names: Union[bool, NoneType, str] = '$UNCHANGED$', eval_sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$', eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', init_score: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.dask.DaskLGBMClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``fit`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      eval_class_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_class_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_init_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_init_score`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_metric : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_metric`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_names : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_names`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_sample_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_set`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      init_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``init_score`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  set_predict_proba_request(self: lightgbm.dask.DaskLGBMClassifier, *, num_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', pred_contrib: Union[bool, NoneType, str] = '$UNCHANGED$', pred_leaf: Union[bool, NoneType, str] = '$UNCHANGED$', raw_score: Union[bool, NoneType, str] = '$UNCHANGED$', start_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.dask.DaskLGBMClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``predict_proba`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``predict_proba`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict_proba``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      num_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``num_iteration`` parameter in ``predict_proba``.\n",
            "     |      \n",
            "     |      pred_contrib : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_contrib`` parameter in ``predict_proba``.\n",
            "     |      \n",
            "     |      pred_leaf : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_leaf`` parameter in ``predict_proba``.\n",
            "     |      \n",
            "     |      raw_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``raw_score`` parameter in ``predict_proba``.\n",
            "     |      \n",
            "     |      start_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``start_iteration`` parameter in ``predict_proba``.\n",
            "     |      \n",
            "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``validate_features`` parameter in ``predict_proba``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  set_predict_request(self: lightgbm.dask.DaskLGBMClassifier, *, num_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', pred_contrib: Union[bool, NoneType, str] = '$UNCHANGED$', pred_leaf: Union[bool, NoneType, str] = '$UNCHANGED$', raw_score: Union[bool, NoneType, str] = '$UNCHANGED$', start_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.dask.DaskLGBMClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``predict`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      num_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``num_iteration`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      pred_contrib : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_contrib`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      pred_leaf : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_leaf`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      raw_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``raw_score`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      start_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``start_iteration`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``validate_features`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  set_score_request(self: lightgbm.dask.DaskLGBMClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.dask.DaskLGBMClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``score`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  to_local(self) -> lightgbm.sklearn.LGBMClassifier\n",
            "     |      Create regular version of lightgbm.LGBMClassifier from the distributed version.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      model : lightgbm.LGBMClassifier\n",
            "     |          Local underlying model.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties inherited from lightgbm.sklearn.LGBMClassifier:\n",
            "     |  \n",
            "     |  classes_\n",
            "     |      :obj:`array` of shape = [n_classes]: The class label array.\n",
            "     |  \n",
            "     |  n_classes_\n",
            "     |      :obj:`int`: The number of classes.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            "     |  \n",
            "     |  __sklearn_tags__(self)\n",
            "     |  \n",
            "     |  score(self, X, y, sample_weight=None)\n",
            "     |      Return the mean accuracy on the given test data and labels.\n",
            "     |      \n",
            "     |      In multi-label classification, this is the subset accuracy\n",
            "     |      which is a harsh metric since you require for each sample that\n",
            "     |      each label set be correctly predicted.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : array-like of shape (n_samples, n_features)\n",
            "     |          Test samples.\n",
            "     |      \n",
            "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            "     |          True labels for `X`.\n",
            "     |      \n",
            "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
            "     |          Sample weights.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      score : float\n",
            "     |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from lightgbm.sklearn.LGBMModel:\n",
            "     |  \n",
            "     |  __sklearn_is_fitted__(self) -> bool\n",
            "     |  \n",
            "     |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
            "     |      Get parameters for this estimator.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      deep : bool, optional (default=True)\n",
            "     |          If True, will return the parameters for this estimator and\n",
            "     |          contained subobjects that are estimators.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      params : dict\n",
            "     |          Parameter names mapped to their values.\n",
            "     |  \n",
            "     |  set_params(self, **params: Any) -> 'LGBMModel'\n",
            "     |      Set the parameters of this estimator.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      **params\n",
            "     |          Parameter names with their new values.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          Returns self.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties inherited from lightgbm.sklearn.LGBMModel:\n",
            "     |  \n",
            "     |  best_iteration_\n",
            "     |      :obj:`int`: The best iteration of fitted model if ``early_stopping()`` callback has been specified.\n",
            "     |  \n",
            "     |  best_score_\n",
            "     |      :obj:`dict`: The best score of fitted model.\n",
            "     |  \n",
            "     |  booster_\n",
            "     |      Booster: The underlying Booster of this model.\n",
            "     |  \n",
            "     |  evals_result_\n",
            "     |      :obj:`dict`: The evaluation results if validation sets have been specified.\n",
            "     |  \n",
            "     |  feature_importances_\n",
            "     |      :obj:`array` of shape = [n_features]: The feature importances (the higher, the more important).\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |      \n",
            "     |          ``importance_type`` attribute is passed to the function\n",
            "     |          to configure the type of importance values to be extracted.\n",
            "     |  \n",
            "     |  feature_name_\n",
            "     |      :obj:`list` of shape = [n_features]: The names of features.\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |      \n",
            "     |          If input does not contain feature names, they will be added during fitting in the format ``Column_0``, ``Column_1``, ..., ``Column_N``.\n",
            "     |  \n",
            "     |  feature_names_in_\n",
            "     |      :obj:`array` of shape = [n_features]: scikit-learn compatible version of ``.feature_name_``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.5.0\n",
            "     |  \n",
            "     |  n_estimators_\n",
            "     |      :obj:`int`: True number of boosting iterations performed.\n",
            "     |      \n",
            "     |      This might be less than parameter ``n_estimators`` if early stopping was enabled or\n",
            "     |      if boosting stopped early due to limits on complexity like ``min_gain_to_split``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |  \n",
            "     |  n_features_\n",
            "     |      :obj:`int`: The number of features of fitted model.\n",
            "     |  \n",
            "     |  n_features_in_\n",
            "     |      :obj:`int`: The number of features of fitted model.\n",
            "     |  \n",
            "     |  n_iter_\n",
            "     |      :obj:`int`: True number of boosting iterations performed.\n",
            "     |      \n",
            "     |      This might be less than parameter ``n_estimators`` if early stopping was enabled or\n",
            "     |      if boosting stopped early due to limits on complexity like ``min_gain_to_split``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |  \n",
            "     |  objective_\n",
            "     |      :obj:`str` or :obj:`callable`: The concrete objective used while fitting this model.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
            "     |  \n",
            "     |  __repr__(self, N_CHAR_MAX=700)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  __sklearn_clone__(self)\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            "     |  \n",
            "     |  get_metadata_routing(self)\n",
            "     |      Get metadata routing of this object.\n",
            "     |      \n",
            "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      routing : MetadataRequest\n",
            "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
            "     |          routing information.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            "     |  \n",
            "     |  __init_subclass__(**kwargs)\n",
            "     |      Set the ``set_{method}_request`` methods.\n",
            "     |      \n",
            "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
            "     |      looks for the information available in the set default values which are\n",
            "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
            "     |      from method signatures.\n",
            "     |      \n",
            "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
            "     |      does not explicitly accept a metadata through its arguments or if the\n",
            "     |      developer would like to specify a request value for those metadata\n",
            "     |      which are different from the default ``None``.\n",
            "     |      \n",
            "     |      References\n",
            "     |      ----------\n",
            "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties inherited from _DaskLGBMModel:\n",
            "     |  \n",
            "     |  client_\n",
            "     |      :obj:`dask.distributed.Client`: Dask client.\n",
            "     |      \n",
            "     |      This property can be passed in the constructor or updated\n",
            "     |      with ``model.set_params(client=client)``.\n",
            "    \n",
            "    class DaskLGBMRanker(lightgbm.sklearn.LGBMRanker, _DaskLGBMModel)\n",
            "     |  DaskLGBMRanker(boosting_type: str = 'gbdt', num_leaves: int = 31, max_depth: int = -1, learning_rate: float = 0.1, n_estimators: int = 100, subsample_for_bin: int = 200000, objective: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, class_weight: Union[dict, str, NoneType] = None, min_split_gain: float = 0.0, min_child_weight: float = 0.001, min_child_samples: int = 20, subsample: float = 1.0, subsample_freq: int = 0, colsample_bytree: float = 1.0, reg_alpha: float = 0.0, reg_lambda: float = 0.0, random_state: Union[int, numpy.random.mtrand.RandomState, ForwardRef('np.random.Generator'), NoneType] = None, n_jobs: Optional[int] = None, importance_type: str = 'split', client: Optional[lightgbm.compat.Client] = None, **kwargs: Any)\n",
            "     |  \n",
            "     |  Distributed version of lightgbm.LGBMRanker.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      DaskLGBMRanker\n",
            "     |      lightgbm.sklearn.LGBMRanker\n",
            "     |      lightgbm.sklearn.LGBMModel\n",
            "     |      sklearn.base.BaseEstimator\n",
            "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
            "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
            "     |      _DaskLGBMModel\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[Any, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __init__(self, boosting_type: str = 'gbdt', num_leaves: int = 31, max_depth: int = -1, learning_rate: float = 0.1, n_estimators: int = 100, subsample_for_bin: int = 200000, objective: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, class_weight: Union[dict, str, NoneType] = None, min_split_gain: float = 0.0, min_child_weight: float = 0.001, min_child_samples: int = 20, subsample: float = 1.0, subsample_freq: int = 0, colsample_bytree: float = 1.0, reg_alpha: float = 0.0, reg_lambda: float = 0.0, random_state: Union[int, numpy.random.mtrand.RandomState, ForwardRef('np.random.Generator'), NoneType] = None, n_jobs: Optional[int] = None, importance_type: str = 'split', client: Optional[lightgbm.compat.Client] = None, **kwargs: Any)\n",
            "     |      Construct a gradient boosting model.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      boosting_type : str, optional (default='gbdt')\n",
            "     |          'gbdt', traditional Gradient Boosting Decision Tree.\n",
            "     |          'dart', Dropouts meet Multiple Additive Regression Trees.\n",
            "     |          'rf', Random Forest.\n",
            "     |      num_leaves : int, optional (default=31)\n",
            "     |          Maximum tree leaves for base learners.\n",
            "     |      max_depth : int, optional (default=-1)\n",
            "     |          Maximum tree depth for base learners, <=0 means no limit.\n",
            "     |          If setting this to a positive value, consider also changing ``num_leaves`` to ``<= 2^max_depth``.\n",
            "     |      learning_rate : float, optional (default=0.1)\n",
            "     |          Boosting learning rate.\n",
            "     |          You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n",
            "     |          in training using ``reset_parameter`` callback.\n",
            "     |          Note, that this will ignore the ``learning_rate`` argument in training.\n",
            "     |      n_estimators : int, optional (default=100)\n",
            "     |          Number of boosted trees to fit.\n",
            "     |      subsample_for_bin : int, optional (default=200000)\n",
            "     |          Number of samples for constructing bins.\n",
            "     |      objective : str, callable or None, optional (default=None)\n",
            "     |          Specify the learning task and the corresponding learning objective or\n",
            "     |          a custom objective function to be used (see note below).\n",
            "     |          Default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
            "     |      class_weight : dict, 'balanced' or None, optional (default=None)\n",
            "     |          Weights associated with classes in the form ``{class_label: weight}``.\n",
            "     |          Use this parameter only for multi-class classification task;\n",
            "     |          for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n",
            "     |          Note, that the usage of all these parameters will result in poor estimates of the individual class probabilities.\n",
            "     |          You may want to consider performing probability calibration\n",
            "     |          (https://scikit-learn.org/stable/modules/calibration.html) of your model.\n",
            "     |          The 'balanced' mode uses the values of y to automatically adjust weights\n",
            "     |          inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n",
            "     |          If None, all classes are supposed to have weight one.\n",
            "     |          Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)\n",
            "     |          if ``sample_weight`` is specified.\n",
            "     |      min_split_gain : float, optional (default=0.)\n",
            "     |          Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
            "     |      min_child_weight : float, optional (default=1e-3)\n",
            "     |          Minimum sum of instance weight (Hessian) needed in a child (leaf).\n",
            "     |      min_child_samples : int, optional (default=20)\n",
            "     |          Minimum number of data needed in a child (leaf).\n",
            "     |      subsample : float, optional (default=1.)\n",
            "     |          Subsample ratio of the training instance.\n",
            "     |      subsample_freq : int, optional (default=0)\n",
            "     |          Frequency of subsample, <=0 means no enable.\n",
            "     |      colsample_bytree : float, optional (default=1.)\n",
            "     |          Subsample ratio of columns when constructing each tree.\n",
            "     |      reg_alpha : float, optional (default=0.)\n",
            "     |          L1 regularization term on weights.\n",
            "     |      reg_lambda : float, optional (default=0.)\n",
            "     |          L2 regularization term on weights.\n",
            "     |      random_state : int, RandomState object or None, optional (default=None)\n",
            "     |          Random number seed.\n",
            "     |          If int, this number is used to seed the C++ code.\n",
            "     |          If RandomState or Generator object (numpy), a random integer is picked based on its state to seed the C++ code.\n",
            "     |          If None, default seeds in C++ code are used.\n",
            "     |      n_jobs : int or None, optional (default=None)\n",
            "     |          Number of parallel threads to use for training (can be changed at prediction time by\n",
            "     |          passing it as an extra keyword argument).\n",
            "     |      \n",
            "     |          For better performance, it is recommended to set this to the number of physical cores\n",
            "     |          in the CPU.\n",
            "     |      \n",
            "     |          Negative integers are interpreted as following joblib's formula (n_cpus + 1 + n_jobs), just like\n",
            "     |          scikit-learn (so e.g. -1 means using all threads). A value of zero corresponds the default number of\n",
            "     |          threads configured for OpenMP in the system. A value of ``None`` (the default) corresponds\n",
            "     |          to using the number of physical cores in the system (its correct detection requires\n",
            "     |          either the ``joblib`` or the ``psutil`` util libraries to be installed).\n",
            "     |      \n",
            "     |          .. versionchanged:: 4.0.0\n",
            "     |      \n",
            "     |      importance_type : str, optional (default='split')\n",
            "     |          The type of feature importance to be filled into ``feature_importances_``.\n",
            "     |          If 'split', result contains numbers of times the feature is used in a model.\n",
            "     |          If 'gain', result contains total gains of splits which use the feature.\n",
            "     |      client : dask.distributed.Client or None, optional (default=None)\n",
            "     |          Dask client. If ``None``, ``distributed.default_client()`` will be used at runtime. The Dask client used by this class will not be saved if the model object is pickled.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the model.\n",
            "     |          Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
            "     |      \n",
            "     |          .. warning::\n",
            "     |      \n",
            "     |              \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
            "     |      \n",
            "     |      Note\n",
            "     |      ----\n",
            "     |      A custom objective function can be provided for the ``objective`` parameter.\n",
            "     |      In this case, it should have the signature\n",
            "     |      ``objective(y_true, y_pred) -> grad, hess``,\n",
            "     |      ``objective(y_true, y_pred, weight) -> grad, hess``\n",
            "     |      or ``objective(y_true, y_pred, weight, group) -> grad, hess``:\n",
            "     |      \n",
            "     |          y_true : numpy 1-D array of shape = [n_samples]\n",
            "     |              The target values.\n",
            "     |          y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The predicted values.\n",
            "     |              Predicted values are returned before any transformation,\n",
            "     |              e.g. they are raw margin instead of probability of positive class for binary task.\n",
            "     |          weight : numpy 1-D array of shape = [n_samples]\n",
            "     |              The weight of samples. Weights should be non-negative.\n",
            "     |          group : numpy 1-D array\n",
            "     |              Group/query data.\n",
            "     |              Only used in the learning-to-rank task.\n",
            "     |              sum(group) = n_samples.\n",
            "     |              For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |              where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |          grad : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The value of the first order derivative (gradient) of the loss\n",
            "     |              with respect to the elements of y_pred for each sample point.\n",
            "     |          hess : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The value of the second order derivative (Hessian) of the loss\n",
            "     |              with respect to the elements of y_pred for each sample point.\n",
            "     |      \n",
            "     |      For multi-class task, y_pred is a numpy 2-D array of shape = [n_samples, n_classes],\n",
            "     |      and grad and hess should be returned in the same format.\n",
            "     |  \n",
            "     |  fit(self, X: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame], y: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame, lightgbm.compat.dask_Series], sample_weight: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_Series, NoneType] = None, init_score: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_Series, NoneType] = None, group: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_Series, NoneType] = None, eval_set: Optional[List[Tuple[Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame], Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame, lightgbm.compat.dask_Series]]]] = None, eval_names: Optional[List[str]] = None, eval_sample_weight: Optional[List[Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_Series]]] = None, eval_init_score: Optional[List[Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_Series]]] = None, eval_group: Optional[List[Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_Series]]] = None, eval_metric: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], List[Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]]]], NoneType] = None, eval_at: Union[List[int], Tuple[int, ...]] = (1, 2, 3, 4, 5), **kwargs: Any) -> 'DaskLGBMRanker'\n",
            "     |      Build a gradient boosting model from the training set (X, y).\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : Dask Array or Dask DataFrame of shape = [n_samples, n_features]\n",
            "     |          Input feature matrix.\n",
            "     |      y : Dask Array, Dask DataFrame or Dask Series of shape = [n_samples]\n",
            "     |          The target values (class labels in classification, real numbers in regression).\n",
            "     |      sample_weight : Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)\n",
            "     |          Weights of training data. Weights should be non-negative.\n",
            "     |      init_score : Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)\n",
            "     |          Init score of training data.\n",
            "     |      group : Dask Array or Dask Series or None, optional (default=None)\n",
            "     |          Group/query data.\n",
            "     |          Only used in the learning-to-rank task.\n",
            "     |          sum(group) = n_samples.\n",
            "     |          For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |          where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |      eval_set : list or None, optional (default=None)\n",
            "     |          A list of (X, y) tuple pairs to use as validation sets.\n",
            "     |      eval_names : list of str, or None, optional (default=None)\n",
            "     |          Names of eval_set.\n",
            "     |      eval_sample_weight : list of Dask Array or Dask Series, or None, optional (default=None)\n",
            "     |          Weights of eval data. Weights should be non-negative.\n",
            "     |      eval_init_score : list of Dask Array or Dask Series, or None, optional (default=None)\n",
            "     |          Init score of eval data.\n",
            "     |      eval_group : list of Dask Array or Dask Series, or None, optional (default=None)\n",
            "     |          Group data of eval data.\n",
            "     |      eval_metric : str, callable, list or None, optional (default=None)\n",
            "     |          If str, it should be a built-in evaluation metric to use.\n",
            "     |          If callable, it should be a custom evaluation metric, see note below for more details.\n",
            "     |          If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.\n",
            "     |          In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n",
            "     |          Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n",
            "     |      eval_at : list or tuple of int, optional (default=(1, 2, 3, 4, 5))\n",
            "     |          The evaluation positions of the specified metric.\n",
            "     |      feature_name : list of str, or 'auto', optional (default='auto')\n",
            "     |          Feature names.\n",
            "     |          If 'auto' and data is pandas DataFrame, data columns names are used.\n",
            "     |      categorical_feature : list of str or int, or 'auto', optional (default='auto')\n",
            "     |          Categorical features.\n",
            "     |          If list of int, interpreted as indices.\n",
            "     |          If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
            "     |          If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
            "     |          All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
            "     |          Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
            "     |          All negative values in categorical features will be treated as missing values.\n",
            "     |          The output cannot be monotonically constrained with respect to a categorical feature.\n",
            "     |          Floating point numbers in categorical features will be rounded towards 0.\n",
            "     |      **kwargs\n",
            "     |          Other parameters passed through to ``LGBMRanker.fit()``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : lightgbm.DaskLGBMRanker\n",
            "     |          Returns self.\n",
            "     |      \n",
            "     |      \n",
            "     |      Note\n",
            "     |      ----\n",
            "     |      Custom eval function expects a callable with following signatures:\n",
            "     |      ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
            "     |      ``func(y_true, y_pred, weight, group)``\n",
            "     |      and returns (eval_name, eval_result, is_higher_better) or\n",
            "     |      list of (eval_name, eval_result, is_higher_better):\n",
            "     |      \n",
            "     |          y_true : numpy 1-D array of shape = [n_samples]\n",
            "     |              The target values.\n",
            "     |          y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The predicted values.\n",
            "     |              In case of custom ``objective``, predicted values are returned before any transformation,\n",
            "     |              e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
            "     |          weight : numpy 1-D array of shape = [n_samples]\n",
            "     |              The weight of samples. Weights should be non-negative.\n",
            "     |          group : numpy 1-D array\n",
            "     |              Group/query data.\n",
            "     |              Only used in the learning-to-rank task.\n",
            "     |              sum(group) = n_samples.\n",
            "     |              For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |              where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |          eval_name : str\n",
            "     |              The name of evaluation function (without whitespace).\n",
            "     |          eval_result : float\n",
            "     |              The eval result.\n",
            "     |          is_higher_better : bool\n",
            "     |              Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
            "     |  \n",
            "     |  predict(self, X: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame], raw_score: bool = False, start_iteration: int = 0, num_iteration: Optional[int] = None, pred_leaf: bool = False, pred_contrib: bool = False, validate_features: bool = False, **kwargs: Any) -> lightgbm.compat.dask_Array\n",
            "     |      Return the predicted value for each sample.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : Dask Array or Dask DataFrame of shape = [n_samples, n_features]\n",
            "     |          Input features matrix.\n",
            "     |      raw_score : bool, optional (default=False)\n",
            "     |          Whether to predict raw scores.\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          Start index of the iteration to predict.\n",
            "     |          If <= 0, starts from the first iteration.\n",
            "     |      num_iteration : int or None, optional (default=None)\n",
            "     |          Total number of iterations used in the prediction.\n",
            "     |          If None, if the best iteration exists and start_iteration <= 0, the best iteration is used;\n",
            "     |          otherwise, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |          If <= 0, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |      pred_leaf : bool, optional (default=False)\n",
            "     |          Whether to predict leaf index.\n",
            "     |      pred_contrib : bool, optional (default=False)\n",
            "     |          Whether to predict feature contributions.\n",
            "     |      \n",
            "     |          .. note::\n",
            "     |      \n",
            "     |              If you want to get more explanations for your model's predictions using SHAP values,\n",
            "     |              like SHAP interaction values,\n",
            "     |              you can install the shap package (https://github.com/slundberg/shap).\n",
            "     |              Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n",
            "     |              column, where the last column is the expected value.\n",
            "     |      \n",
            "     |      validate_features : bool, optional (default=False)\n",
            "     |          If True, ensure that the features used to predict match the ones used to train.\n",
            "     |          Used only if data is pandas DataFrame.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the prediction.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      predicted_result : Dask Array of shape = [n_samples]\n",
            "     |          The predicted values.\n",
            "     |      X_leaves : Dask Array of shape = [n_samples, n_trees]\n",
            "     |          If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n",
            "     |      X_SHAP_values : Dask Array of shape = [n_samples, n_features + 1]\n",
            "     |          If ``pred_contrib=True``, the feature contributions for each sample.\n",
            "     |  \n",
            "     |  set_fit_request(self: lightgbm.dask.DaskLGBMRanker, *, eval_at: Union[bool, NoneType, str] = '$UNCHANGED$', eval_group: Union[bool, NoneType, str] = '$UNCHANGED$', eval_init_score: Union[bool, NoneType, str] = '$UNCHANGED$', eval_metric: Union[bool, NoneType, str] = '$UNCHANGED$', eval_names: Union[bool, NoneType, str] = '$UNCHANGED$', eval_sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$', eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', group: Union[bool, NoneType, str] = '$UNCHANGED$', init_score: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.dask.DaskLGBMRanker from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``fit`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      eval_at : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_at`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_group : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_group`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_init_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_init_score`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_metric : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_metric`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_names : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_names`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_sample_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_set`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      group : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``group`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      init_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``init_score`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  set_predict_request(self: lightgbm.dask.DaskLGBMRanker, *, num_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', pred_contrib: Union[bool, NoneType, str] = '$UNCHANGED$', pred_leaf: Union[bool, NoneType, str] = '$UNCHANGED$', raw_score: Union[bool, NoneType, str] = '$UNCHANGED$', start_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.dask.DaskLGBMRanker from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``predict`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      num_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``num_iteration`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      pred_contrib : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_contrib`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      pred_leaf : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_leaf`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      raw_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``raw_score`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      start_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``start_iteration`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``validate_features`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  to_local(self) -> lightgbm.sklearn.LGBMRanker\n",
            "     |      Create regular version of lightgbm.LGBMRanker from the distributed version.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      model : lightgbm.LGBMRanker\n",
            "     |          Local underlying model.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from lightgbm.sklearn.LGBMModel:\n",
            "     |  \n",
            "     |  __sklearn_is_fitted__(self) -> bool\n",
            "     |  \n",
            "     |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
            "     |      Get parameters for this estimator.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      deep : bool, optional (default=True)\n",
            "     |          If True, will return the parameters for this estimator and\n",
            "     |          contained subobjects that are estimators.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      params : dict\n",
            "     |          Parameter names mapped to their values.\n",
            "     |  \n",
            "     |  set_params(self, **params: Any) -> 'LGBMModel'\n",
            "     |      Set the parameters of this estimator.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      **params\n",
            "     |          Parameter names with their new values.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          Returns self.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties inherited from lightgbm.sklearn.LGBMModel:\n",
            "     |  \n",
            "     |  best_iteration_\n",
            "     |      :obj:`int`: The best iteration of fitted model if ``early_stopping()`` callback has been specified.\n",
            "     |  \n",
            "     |  best_score_\n",
            "     |      :obj:`dict`: The best score of fitted model.\n",
            "     |  \n",
            "     |  booster_\n",
            "     |      Booster: The underlying Booster of this model.\n",
            "     |  \n",
            "     |  evals_result_\n",
            "     |      :obj:`dict`: The evaluation results if validation sets have been specified.\n",
            "     |  \n",
            "     |  feature_importances_\n",
            "     |      :obj:`array` of shape = [n_features]: The feature importances (the higher, the more important).\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |      \n",
            "     |          ``importance_type`` attribute is passed to the function\n",
            "     |          to configure the type of importance values to be extracted.\n",
            "     |  \n",
            "     |  feature_name_\n",
            "     |      :obj:`list` of shape = [n_features]: The names of features.\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |      \n",
            "     |          If input does not contain feature names, they will be added during fitting in the format ``Column_0``, ``Column_1``, ..., ``Column_N``.\n",
            "     |  \n",
            "     |  feature_names_in_\n",
            "     |      :obj:`array` of shape = [n_features]: scikit-learn compatible version of ``.feature_name_``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.5.0\n",
            "     |  \n",
            "     |  n_estimators_\n",
            "     |      :obj:`int`: True number of boosting iterations performed.\n",
            "     |      \n",
            "     |      This might be less than parameter ``n_estimators`` if early stopping was enabled or\n",
            "     |      if boosting stopped early due to limits on complexity like ``min_gain_to_split``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |  \n",
            "     |  n_features_\n",
            "     |      :obj:`int`: The number of features of fitted model.\n",
            "     |  \n",
            "     |  n_features_in_\n",
            "     |      :obj:`int`: The number of features of fitted model.\n",
            "     |  \n",
            "     |  n_iter_\n",
            "     |      :obj:`int`: True number of boosting iterations performed.\n",
            "     |      \n",
            "     |      This might be less than parameter ``n_estimators`` if early stopping was enabled or\n",
            "     |      if boosting stopped early due to limits on complexity like ``min_gain_to_split``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |  \n",
            "     |  objective_\n",
            "     |      :obj:`str` or :obj:`callable`: The concrete objective used while fitting this model.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
            "     |  \n",
            "     |  __repr__(self, N_CHAR_MAX=700)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  __sklearn_clone__(self)\n",
            "     |  \n",
            "     |  __sklearn_tags__(self)\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            "     |  \n",
            "     |  get_metadata_routing(self)\n",
            "     |      Get metadata routing of this object.\n",
            "     |      \n",
            "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      routing : MetadataRequest\n",
            "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
            "     |          routing information.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            "     |  \n",
            "     |  __init_subclass__(**kwargs)\n",
            "     |      Set the ``set_{method}_request`` methods.\n",
            "     |      \n",
            "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
            "     |      looks for the information available in the set default values which are\n",
            "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
            "     |      from method signatures.\n",
            "     |      \n",
            "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
            "     |      does not explicitly accept a metadata through its arguments or if the\n",
            "     |      developer would like to specify a request value for those metadata\n",
            "     |      which are different from the default ``None``.\n",
            "     |      \n",
            "     |      References\n",
            "     |      ----------\n",
            "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties inherited from _DaskLGBMModel:\n",
            "     |  \n",
            "     |  client_\n",
            "     |      :obj:`dask.distributed.Client`: Dask client.\n",
            "     |      \n",
            "     |      This property can be passed in the constructor or updated\n",
            "     |      with ``model.set_params(client=client)``.\n",
            "    \n",
            "    class DaskLGBMRegressor(lightgbm.sklearn.LGBMRegressor, _DaskLGBMModel)\n",
            "     |  DaskLGBMRegressor(boosting_type: str = 'gbdt', num_leaves: int = 31, max_depth: int = -1, learning_rate: float = 0.1, n_estimators: int = 100, subsample_for_bin: int = 200000, objective: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, class_weight: Union[dict, str, NoneType] = None, min_split_gain: float = 0.0, min_child_weight: float = 0.001, min_child_samples: int = 20, subsample: float = 1.0, subsample_freq: int = 0, colsample_bytree: float = 1.0, reg_alpha: float = 0.0, reg_lambda: float = 0.0, random_state: Union[int, numpy.random.mtrand.RandomState, ForwardRef('np.random.Generator'), NoneType] = None, n_jobs: Optional[int] = None, importance_type: str = 'split', client: Optional[lightgbm.compat.Client] = None, **kwargs: Any)\n",
            "     |  \n",
            "     |  Distributed version of lightgbm.LGBMRegressor.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      DaskLGBMRegressor\n",
            "     |      lightgbm.sklearn.LGBMRegressor\n",
            "     |      sklearn.base.RegressorMixin\n",
            "     |      lightgbm.sklearn.LGBMModel\n",
            "     |      sklearn.base.BaseEstimator\n",
            "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
            "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
            "     |      _DaskLGBMModel\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[Any, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __init__(self, boosting_type: str = 'gbdt', num_leaves: int = 31, max_depth: int = -1, learning_rate: float = 0.1, n_estimators: int = 100, subsample_for_bin: int = 200000, objective: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, class_weight: Union[dict, str, NoneType] = None, min_split_gain: float = 0.0, min_child_weight: float = 0.001, min_child_samples: int = 20, subsample: float = 1.0, subsample_freq: int = 0, colsample_bytree: float = 1.0, reg_alpha: float = 0.0, reg_lambda: float = 0.0, random_state: Union[int, numpy.random.mtrand.RandomState, ForwardRef('np.random.Generator'), NoneType] = None, n_jobs: Optional[int] = None, importance_type: str = 'split', client: Optional[lightgbm.compat.Client] = None, **kwargs: Any)\n",
            "     |      Construct a gradient boosting model.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      boosting_type : str, optional (default='gbdt')\n",
            "     |          'gbdt', traditional Gradient Boosting Decision Tree.\n",
            "     |          'dart', Dropouts meet Multiple Additive Regression Trees.\n",
            "     |          'rf', Random Forest.\n",
            "     |      num_leaves : int, optional (default=31)\n",
            "     |          Maximum tree leaves for base learners.\n",
            "     |      max_depth : int, optional (default=-1)\n",
            "     |          Maximum tree depth for base learners, <=0 means no limit.\n",
            "     |          If setting this to a positive value, consider also changing ``num_leaves`` to ``<= 2^max_depth``.\n",
            "     |      learning_rate : float, optional (default=0.1)\n",
            "     |          Boosting learning rate.\n",
            "     |          You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n",
            "     |          in training using ``reset_parameter`` callback.\n",
            "     |          Note, that this will ignore the ``learning_rate`` argument in training.\n",
            "     |      n_estimators : int, optional (default=100)\n",
            "     |          Number of boosted trees to fit.\n",
            "     |      subsample_for_bin : int, optional (default=200000)\n",
            "     |          Number of samples for constructing bins.\n",
            "     |      objective : str, callable or None, optional (default=None)\n",
            "     |          Specify the learning task and the corresponding learning objective or\n",
            "     |          a custom objective function to be used (see note below).\n",
            "     |          Default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
            "     |      class_weight : dict, 'balanced' or None, optional (default=None)\n",
            "     |          Weights associated with classes in the form ``{class_label: weight}``.\n",
            "     |          Use this parameter only for multi-class classification task;\n",
            "     |          for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n",
            "     |          Note, that the usage of all these parameters will result in poor estimates of the individual class probabilities.\n",
            "     |          You may want to consider performing probability calibration\n",
            "     |          (https://scikit-learn.org/stable/modules/calibration.html) of your model.\n",
            "     |          The 'balanced' mode uses the values of y to automatically adjust weights\n",
            "     |          inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n",
            "     |          If None, all classes are supposed to have weight one.\n",
            "     |          Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)\n",
            "     |          if ``sample_weight`` is specified.\n",
            "     |      min_split_gain : float, optional (default=0.)\n",
            "     |          Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
            "     |      min_child_weight : float, optional (default=1e-3)\n",
            "     |          Minimum sum of instance weight (Hessian) needed in a child (leaf).\n",
            "     |      min_child_samples : int, optional (default=20)\n",
            "     |          Minimum number of data needed in a child (leaf).\n",
            "     |      subsample : float, optional (default=1.)\n",
            "     |          Subsample ratio of the training instance.\n",
            "     |      subsample_freq : int, optional (default=0)\n",
            "     |          Frequency of subsample, <=0 means no enable.\n",
            "     |      colsample_bytree : float, optional (default=1.)\n",
            "     |          Subsample ratio of columns when constructing each tree.\n",
            "     |      reg_alpha : float, optional (default=0.)\n",
            "     |          L1 regularization term on weights.\n",
            "     |      reg_lambda : float, optional (default=0.)\n",
            "     |          L2 regularization term on weights.\n",
            "     |      random_state : int, RandomState object or None, optional (default=None)\n",
            "     |          Random number seed.\n",
            "     |          If int, this number is used to seed the C++ code.\n",
            "     |          If RandomState or Generator object (numpy), a random integer is picked based on its state to seed the C++ code.\n",
            "     |          If None, default seeds in C++ code are used.\n",
            "     |      n_jobs : int or None, optional (default=None)\n",
            "     |          Number of parallel threads to use for training (can be changed at prediction time by\n",
            "     |          passing it as an extra keyword argument).\n",
            "     |      \n",
            "     |          For better performance, it is recommended to set this to the number of physical cores\n",
            "     |          in the CPU.\n",
            "     |      \n",
            "     |          Negative integers are interpreted as following joblib's formula (n_cpus + 1 + n_jobs), just like\n",
            "     |          scikit-learn (so e.g. -1 means using all threads). A value of zero corresponds the default number of\n",
            "     |          threads configured for OpenMP in the system. A value of ``None`` (the default) corresponds\n",
            "     |          to using the number of physical cores in the system (its correct detection requires\n",
            "     |          either the ``joblib`` or the ``psutil`` util libraries to be installed).\n",
            "     |      \n",
            "     |          .. versionchanged:: 4.0.0\n",
            "     |      \n",
            "     |      importance_type : str, optional (default='split')\n",
            "     |          The type of feature importance to be filled into ``feature_importances_``.\n",
            "     |          If 'split', result contains numbers of times the feature is used in a model.\n",
            "     |          If 'gain', result contains total gains of splits which use the feature.\n",
            "     |      client : dask.distributed.Client or None, optional (default=None)\n",
            "     |          Dask client. If ``None``, ``distributed.default_client()`` will be used at runtime. The Dask client used by this class will not be saved if the model object is pickled.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the model.\n",
            "     |          Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
            "     |      \n",
            "     |          .. warning::\n",
            "     |      \n",
            "     |              \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
            "     |      \n",
            "     |      Note\n",
            "     |      ----\n",
            "     |      A custom objective function can be provided for the ``objective`` parameter.\n",
            "     |      In this case, it should have the signature\n",
            "     |      ``objective(y_true, y_pred) -> grad, hess``,\n",
            "     |      ``objective(y_true, y_pred, weight) -> grad, hess``\n",
            "     |      or ``objective(y_true, y_pred, weight, group) -> grad, hess``:\n",
            "     |      \n",
            "     |          y_true : numpy 1-D array of shape = [n_samples]\n",
            "     |              The target values.\n",
            "     |          y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The predicted values.\n",
            "     |              Predicted values are returned before any transformation,\n",
            "     |              e.g. they are raw margin instead of probability of positive class for binary task.\n",
            "     |          weight : numpy 1-D array of shape = [n_samples]\n",
            "     |              The weight of samples. Weights should be non-negative.\n",
            "     |          group : numpy 1-D array\n",
            "     |              Group/query data.\n",
            "     |              Only used in the learning-to-rank task.\n",
            "     |              sum(group) = n_samples.\n",
            "     |              For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |              where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |          grad : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The value of the first order derivative (gradient) of the loss\n",
            "     |              with respect to the elements of y_pred for each sample point.\n",
            "     |          hess : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The value of the second order derivative (Hessian) of the loss\n",
            "     |              with respect to the elements of y_pred for each sample point.\n",
            "     |      \n",
            "     |      For multi-class task, y_pred is a numpy 2-D array of shape = [n_samples, n_classes],\n",
            "     |      and grad and hess should be returned in the same format.\n",
            "     |  \n",
            "     |  fit(self, X: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame], y: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame, lightgbm.compat.dask_Series], sample_weight: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_Series, NoneType] = None, init_score: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_Series, NoneType] = None, eval_set: Optional[List[Tuple[Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame], Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame, lightgbm.compat.dask_Series]]]] = None, eval_names: Optional[List[str]] = None, eval_sample_weight: Optional[List[Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_Series]]] = None, eval_init_score: Optional[List[Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_Series]]] = None, eval_metric: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], List[Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]]]], NoneType] = None, **kwargs: Any) -> 'DaskLGBMRegressor'\n",
            "     |      Build a gradient boosting model from the training set (X, y).\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : Dask Array or Dask DataFrame of shape = [n_samples, n_features]\n",
            "     |          Input feature matrix.\n",
            "     |      y : Dask Array, Dask DataFrame or Dask Series of shape = [n_samples]\n",
            "     |          The target values (class labels in classification, real numbers in regression).\n",
            "     |      sample_weight : Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)\n",
            "     |          Weights of training data. Weights should be non-negative.\n",
            "     |      init_score : Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)\n",
            "     |          Init score of training data.\n",
            "     |      eval_set : list or None, optional (default=None)\n",
            "     |          A list of (X, y) tuple pairs to use as validation sets.\n",
            "     |      eval_names : list of str, or None, optional (default=None)\n",
            "     |          Names of eval_set.\n",
            "     |      eval_sample_weight : list of Dask Array or Dask Series, or None, optional (default=None)\n",
            "     |          Weights of eval data. Weights should be non-negative.\n",
            "     |      eval_init_score : list of Dask Array or Dask Series, or None, optional (default=None)\n",
            "     |          Init score of eval data.\n",
            "     |      eval_metric : str, callable, list or None, optional (default=None)\n",
            "     |          If str, it should be a built-in evaluation metric to use.\n",
            "     |          If callable, it should be a custom evaluation metric, see note below for more details.\n",
            "     |          If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.\n",
            "     |          In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n",
            "     |          Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n",
            "     |      feature_name : list of str, or 'auto', optional (default='auto')\n",
            "     |          Feature names.\n",
            "     |          If 'auto' and data is pandas DataFrame, data columns names are used.\n",
            "     |      categorical_feature : list of str or int, or 'auto', optional (default='auto')\n",
            "     |          Categorical features.\n",
            "     |          If list of int, interpreted as indices.\n",
            "     |          If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
            "     |          If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
            "     |          All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
            "     |          Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
            "     |          All negative values in categorical features will be treated as missing values.\n",
            "     |          The output cannot be monotonically constrained with respect to a categorical feature.\n",
            "     |          Floating point numbers in categorical features will be rounded towards 0.\n",
            "     |      **kwargs\n",
            "     |          Other parameters passed through to ``LGBMRegressor.fit()``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : lightgbm.DaskLGBMRegressor\n",
            "     |          Returns self.\n",
            "     |      \n",
            "     |      \n",
            "     |      Note\n",
            "     |      ----\n",
            "     |      Custom eval function expects a callable with following signatures:\n",
            "     |      ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
            "     |      ``func(y_true, y_pred, weight, group)``\n",
            "     |      and returns (eval_name, eval_result, is_higher_better) or\n",
            "     |      list of (eval_name, eval_result, is_higher_better):\n",
            "     |      \n",
            "     |          y_true : numpy 1-D array of shape = [n_samples]\n",
            "     |              The target values.\n",
            "     |          y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The predicted values.\n",
            "     |              In case of custom ``objective``, predicted values are returned before any transformation,\n",
            "     |              e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
            "     |          weight : numpy 1-D array of shape = [n_samples]\n",
            "     |              The weight of samples. Weights should be non-negative.\n",
            "     |          group : numpy 1-D array\n",
            "     |              Group/query data.\n",
            "     |              Only used in the learning-to-rank task.\n",
            "     |              sum(group) = n_samples.\n",
            "     |              For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |              where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |          eval_name : str\n",
            "     |              The name of evaluation function (without whitespace).\n",
            "     |          eval_result : float\n",
            "     |              The eval result.\n",
            "     |          is_higher_better : bool\n",
            "     |              Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
            "     |  \n",
            "     |  predict(self, X: Union[lightgbm.compat.dask_Array, lightgbm.compat.dask_DataFrame], raw_score: bool = False, start_iteration: int = 0, num_iteration: Optional[int] = None, pred_leaf: bool = False, pred_contrib: bool = False, validate_features: bool = False, **kwargs: Any) -> lightgbm.compat.dask_Array\n",
            "     |      Return the predicted value for each sample.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : Dask Array or Dask DataFrame of shape = [n_samples, n_features]\n",
            "     |          Input features matrix.\n",
            "     |      raw_score : bool, optional (default=False)\n",
            "     |          Whether to predict raw scores.\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          Start index of the iteration to predict.\n",
            "     |          If <= 0, starts from the first iteration.\n",
            "     |      num_iteration : int or None, optional (default=None)\n",
            "     |          Total number of iterations used in the prediction.\n",
            "     |          If None, if the best iteration exists and start_iteration <= 0, the best iteration is used;\n",
            "     |          otherwise, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |          If <= 0, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |      pred_leaf : bool, optional (default=False)\n",
            "     |          Whether to predict leaf index.\n",
            "     |      pred_contrib : bool, optional (default=False)\n",
            "     |          Whether to predict feature contributions.\n",
            "     |      \n",
            "     |          .. note::\n",
            "     |      \n",
            "     |              If you want to get more explanations for your model's predictions using SHAP values,\n",
            "     |              like SHAP interaction values,\n",
            "     |              you can install the shap package (https://github.com/slundberg/shap).\n",
            "     |              Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n",
            "     |              column, where the last column is the expected value.\n",
            "     |      \n",
            "     |      validate_features : bool, optional (default=False)\n",
            "     |          If True, ensure that the features used to predict match the ones used to train.\n",
            "     |          Used only if data is pandas DataFrame.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the prediction.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      predicted_result : Dask Array of shape = [n_samples]\n",
            "     |          The predicted values.\n",
            "     |      X_leaves : Dask Array of shape = [n_samples, n_trees]\n",
            "     |          If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n",
            "     |      X_SHAP_values : Dask Array of shape = [n_samples, n_features + 1]\n",
            "     |          If ``pred_contrib=True``, the feature contributions for each sample.\n",
            "     |  \n",
            "     |  set_fit_request(self: lightgbm.dask.DaskLGBMRegressor, *, eval_init_score: Union[bool, NoneType, str] = '$UNCHANGED$', eval_metric: Union[bool, NoneType, str] = '$UNCHANGED$', eval_names: Union[bool, NoneType, str] = '$UNCHANGED$', eval_sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$', eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', init_score: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.dask.DaskLGBMRegressor from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``fit`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      eval_init_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_init_score`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_metric : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_metric`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_names : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_names`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_sample_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_set`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      init_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``init_score`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  set_predict_request(self: lightgbm.dask.DaskLGBMRegressor, *, num_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', pred_contrib: Union[bool, NoneType, str] = '$UNCHANGED$', pred_leaf: Union[bool, NoneType, str] = '$UNCHANGED$', raw_score: Union[bool, NoneType, str] = '$UNCHANGED$', start_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.dask.DaskLGBMRegressor from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``predict`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      num_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``num_iteration`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      pred_contrib : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_contrib`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      pred_leaf : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_leaf`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      raw_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``raw_score`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      start_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``start_iteration`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``validate_features`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  set_score_request(self: lightgbm.dask.DaskLGBMRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.dask.DaskLGBMRegressor from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``score`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  to_local(self) -> lightgbm.sklearn.LGBMRegressor\n",
            "     |      Create regular version of lightgbm.LGBMRegressor from the distributed version.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      model : lightgbm.LGBMRegressor\n",
            "     |          Local underlying model.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
            "     |  \n",
            "     |  __sklearn_tags__(self)\n",
            "     |  \n",
            "     |  score(self, X, y, sample_weight=None)\n",
            "     |      Return the coefficient of determination of the prediction.\n",
            "     |      \n",
            "     |      The coefficient of determination :math:`R^2` is defined as\n",
            "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
            "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
            "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
            "     |      The best possible score is 1.0 and it can be negative (because the\n",
            "     |      model can be arbitrarily worse). A constant model that always predicts\n",
            "     |      the expected value of `y`, disregarding the input features, would get\n",
            "     |      a :math:`R^2` score of 0.0.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : array-like of shape (n_samples, n_features)\n",
            "     |          Test samples. For some estimators this may be a precomputed\n",
            "     |          kernel matrix or a list of generic objects instead with shape\n",
            "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
            "     |          is the number of samples used in the fitting for the estimator.\n",
            "     |      \n",
            "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            "     |          True values for `X`.\n",
            "     |      \n",
            "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
            "     |          Sample weights.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      score : float\n",
            "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
            "     |      \n",
            "     |      Notes\n",
            "     |      -----\n",
            "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
            "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
            "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
            "     |      This influences the ``score`` method of all the multioutput\n",
            "     |      regressors (except for\n",
            "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from lightgbm.sklearn.LGBMModel:\n",
            "     |  \n",
            "     |  __sklearn_is_fitted__(self) -> bool\n",
            "     |  \n",
            "     |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
            "     |      Get parameters for this estimator.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      deep : bool, optional (default=True)\n",
            "     |          If True, will return the parameters for this estimator and\n",
            "     |          contained subobjects that are estimators.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      params : dict\n",
            "     |          Parameter names mapped to their values.\n",
            "     |  \n",
            "     |  set_params(self, **params: Any) -> 'LGBMModel'\n",
            "     |      Set the parameters of this estimator.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      **params\n",
            "     |          Parameter names with their new values.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          Returns self.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties inherited from lightgbm.sklearn.LGBMModel:\n",
            "     |  \n",
            "     |  best_iteration_\n",
            "     |      :obj:`int`: The best iteration of fitted model if ``early_stopping()`` callback has been specified.\n",
            "     |  \n",
            "     |  best_score_\n",
            "     |      :obj:`dict`: The best score of fitted model.\n",
            "     |  \n",
            "     |  booster_\n",
            "     |      Booster: The underlying Booster of this model.\n",
            "     |  \n",
            "     |  evals_result_\n",
            "     |      :obj:`dict`: The evaluation results if validation sets have been specified.\n",
            "     |  \n",
            "     |  feature_importances_\n",
            "     |      :obj:`array` of shape = [n_features]: The feature importances (the higher, the more important).\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |      \n",
            "     |          ``importance_type`` attribute is passed to the function\n",
            "     |          to configure the type of importance values to be extracted.\n",
            "     |  \n",
            "     |  feature_name_\n",
            "     |      :obj:`list` of shape = [n_features]: The names of features.\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |      \n",
            "     |          If input does not contain feature names, they will be added during fitting in the format ``Column_0``, ``Column_1``, ..., ``Column_N``.\n",
            "     |  \n",
            "     |  feature_names_in_\n",
            "     |      :obj:`array` of shape = [n_features]: scikit-learn compatible version of ``.feature_name_``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.5.0\n",
            "     |  \n",
            "     |  n_estimators_\n",
            "     |      :obj:`int`: True number of boosting iterations performed.\n",
            "     |      \n",
            "     |      This might be less than parameter ``n_estimators`` if early stopping was enabled or\n",
            "     |      if boosting stopped early due to limits on complexity like ``min_gain_to_split``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |  \n",
            "     |  n_features_\n",
            "     |      :obj:`int`: The number of features of fitted model.\n",
            "     |  \n",
            "     |  n_features_in_\n",
            "     |      :obj:`int`: The number of features of fitted model.\n",
            "     |  \n",
            "     |  n_iter_\n",
            "     |      :obj:`int`: True number of boosting iterations performed.\n",
            "     |      \n",
            "     |      This might be less than parameter ``n_estimators`` if early stopping was enabled or\n",
            "     |      if boosting stopped early due to limits on complexity like ``min_gain_to_split``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |  \n",
            "     |  objective_\n",
            "     |      :obj:`str` or :obj:`callable`: The concrete objective used while fitting this model.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
            "     |  \n",
            "     |  __repr__(self, N_CHAR_MAX=700)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  __sklearn_clone__(self)\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            "     |  \n",
            "     |  get_metadata_routing(self)\n",
            "     |      Get metadata routing of this object.\n",
            "     |      \n",
            "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      routing : MetadataRequest\n",
            "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
            "     |          routing information.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            "     |  \n",
            "     |  __init_subclass__(**kwargs)\n",
            "     |      Set the ``set_{method}_request`` methods.\n",
            "     |      \n",
            "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
            "     |      looks for the information available in the set default values which are\n",
            "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
            "     |      from method signatures.\n",
            "     |      \n",
            "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
            "     |      does not explicitly accept a metadata through its arguments or if the\n",
            "     |      developer would like to specify a request value for those metadata\n",
            "     |      which are different from the default ``None``.\n",
            "     |      \n",
            "     |      References\n",
            "     |      ----------\n",
            "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties inherited from _DaskLGBMModel:\n",
            "     |  \n",
            "     |  client_\n",
            "     |      :obj:`dask.distributed.Client`: Dask client.\n",
            "     |      \n",
            "     |      This property can be passed in the constructor or updated\n",
            "     |      with ``model.set_params(client=client)``.\n",
            "    \n",
            "    class Dataset(builtins.object)\n",
            "     |  Dataset(data: Union[str, pathlib.Path, numpy.ndarray, pandas.core.frame.DataFrame, lightgbm.compat.dt_DataTable, scipy.sparse._matrix.spmatrix, ForwardRef('Sequence'), List[ForwardRef('Sequence')], List[numpy.ndarray], pyarrow.lib.Table], label: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, reference: Optional[ForwardRef('Dataset')] = None, weight: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, group: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, init_score: Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, feature_name: Union[List[str], ForwardRef(\"Literal['auto']\")] = 'auto', categorical_feature: Union[List[str], List[int], ForwardRef(\"Literal['auto']\")] = 'auto', params: Optional[Dict[str, Any]] = None, free_raw_data: bool = True, position: Union[numpy.ndarray, pandas.core.series.Series, NoneType] = None)\n",
            "     |  \n",
            "     |  Dataset in LightGBM.\n",
            "     |  \n",
            "     |  LightGBM does not train on raw data.\n",
            "     |  It discretizes continuous features into histogram bins, tries to combine categorical features,\n",
            "     |  and automatically handles missing and infinite values.\n",
            "     |  \n",
            "     |  This class handles that preprocessing, and holds that alternative representation of the input data.\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __del__(self) -> None\n",
            "     |  \n",
            "     |  __init__(self, data: Union[str, pathlib.Path, numpy.ndarray, pandas.core.frame.DataFrame, lightgbm.compat.dt_DataTable, scipy.sparse._matrix.spmatrix, ForwardRef('Sequence'), List[ForwardRef('Sequence')], List[numpy.ndarray], pyarrow.lib.Table], label: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, reference: Optional[ForwardRef('Dataset')] = None, weight: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, group: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, init_score: Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, feature_name: Union[List[str], ForwardRef(\"Literal['auto']\")] = 'auto', categorical_feature: Union[List[str], List[int], ForwardRef(\"Literal['auto']\")] = 'auto', params: Optional[Dict[str, Any]] = None, free_raw_data: bool = True, position: Union[numpy.ndarray, pandas.core.series.Series, NoneType] = None)\n",
            "     |      Initialize Dataset.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      data : str, pathlib.Path, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse, Sequence, list of Sequence, list of numpy array or pyarrow Table\n",
            "     |          Data source of Dataset.\n",
            "     |          If str or pathlib.Path, it represents the path to a text file (CSV, TSV, or LibSVM) or a LightGBM Dataset binary file.\n",
            "     |      label : list, numpy 1-D array, pandas Series / one-column DataFrame, pyarrow Array, pyarrow ChunkedArray or None, optional (default=None)\n",
            "     |          Label of the data.\n",
            "     |      reference : Dataset or None, optional (default=None)\n",
            "     |          If this is Dataset for validation, training data should be used as reference.\n",
            "     |      weight : list, numpy 1-D array, pandas Series, pyarrow Array, pyarrow ChunkedArray or None, optional (default=None)\n",
            "     |          Weight for each instance. Weights should be non-negative.\n",
            "     |      group : list, numpy 1-D array, pandas Series, pyarrow Array, pyarrow ChunkedArray or None, optional (default=None)\n",
            "     |          Group/query data.\n",
            "     |          Only used in the learning-to-rank task.\n",
            "     |          sum(group) = n_samples.\n",
            "     |          For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |          where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |      init_score : list, list of lists (for multi-class task), numpy array, pandas Series, pandas DataFrame (for multi-class task), pyarrow Array, pyarrow ChunkedArray, pyarrow Table (for multi-class task) or None, optional (default=None)\n",
            "     |          Init score for Dataset.\n",
            "     |      feature_name : list of str, or 'auto', optional (default=\"auto\")\n",
            "     |          Feature names.\n",
            "     |          If 'auto' and data is pandas DataFrame or pyarrow Table, data columns names are used.\n",
            "     |      categorical_feature : list of str or int, or 'auto', optional (default=\"auto\")\n",
            "     |          Categorical features.\n",
            "     |          If list of int, interpreted as indices.\n",
            "     |          If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
            "     |          If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
            "     |          All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
            "     |          Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
            "     |          All negative values in categorical features will be treated as missing values.\n",
            "     |          The output cannot be monotonically constrained with respect to a categorical feature.\n",
            "     |          Floating point numbers in categorical features will be rounded towards 0.\n",
            "     |      params : dict or None, optional (default=None)\n",
            "     |          Other parameters for Dataset.\n",
            "     |      free_raw_data : bool, optional (default=True)\n",
            "     |          If True, raw data is freed after constructing inner Dataset.\n",
            "     |      position : numpy 1-D array, pandas Series or None, optional (default=None)\n",
            "     |          Position of items used in unbiased learning-to-rank task.\n",
            "     |  \n",
            "     |  add_features_from(self, other: 'Dataset') -> 'Dataset'\n",
            "     |      Add features from other Dataset to the current Dataset.\n",
            "     |      \n",
            "     |      Both Datasets must be constructed before calling this method.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      other : Dataset\n",
            "     |          The Dataset to take features from.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Dataset\n",
            "     |          Dataset with the new features added.\n",
            "     |  \n",
            "     |  construct(self) -> 'Dataset'\n",
            "     |      Lazy init.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Dataset\n",
            "     |          Constructed Dataset object.\n",
            "     |  \n",
            "     |  create_valid(self, data: Union[str, pathlib.Path, numpy.ndarray, pandas.core.frame.DataFrame, lightgbm.compat.dt_DataTable, scipy.sparse._matrix.spmatrix, ForwardRef('Sequence'), List[ForwardRef('Sequence')], List[numpy.ndarray], pyarrow.lib.Table], label: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, weight: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, group: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, init_score: Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, params: Optional[Dict[str, Any]] = None, position: Union[numpy.ndarray, pandas.core.series.Series, NoneType] = None) -> 'Dataset'\n",
            "     |      Create validation data align with current Dataset.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      data : str, pathlib.Path, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse, Sequence, list of Sequence or list of numpy array\n",
            "     |          Data source of Dataset.\n",
            "     |          If str or pathlib.Path, it represents the path to a text file (CSV, TSV, or LibSVM) or a LightGBM Dataset binary file.\n",
            "     |      label : list, numpy 1-D array, pandas Series / one-column DataFrame, pyarrow Array, pyarrow ChunkedArray or None, optional (default=None)\n",
            "     |          Label of the data.\n",
            "     |      weight : list, numpy 1-D array, pandas Series, pyarrow Array, pyarrow ChunkedArray or None, optional (default=None)\n",
            "     |          Weight for each instance. Weights should be non-negative.\n",
            "     |      group : list, numpy 1-D array, pandas Series, pyarrow Array, pyarrow ChunkedArray or None, optional (default=None)\n",
            "     |          Group/query data.\n",
            "     |          Only used in the learning-to-rank task.\n",
            "     |          sum(group) = n_samples.\n",
            "     |          For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |          where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |      init_score : list, list of lists (for multi-class task), numpy array, pandas Series, pandas DataFrame (for multi-class task), pyarrow Array, pyarrow ChunkedArray, pyarrow Table (for multi-class task) or None, optional (default=None)\n",
            "     |          Init score for Dataset.\n",
            "     |      params : dict or None, optional (default=None)\n",
            "     |          Other parameters for validation Dataset.\n",
            "     |      position : numpy 1-D array, pandas Series or None, optional (default=None)\n",
            "     |          Position of items used in unbiased learning-to-rank task.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      valid : Dataset\n",
            "     |          Validation Dataset with reference to self.\n",
            "     |  \n",
            "     |  feature_num_bin(self, feature: Union[int, str]) -> int\n",
            "     |      Get the number of bins for a feature.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      feature : int or str\n",
            "     |          Index or name of the feature.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      number_of_bins : int\n",
            "     |          The number of constructed bins for the feature in the Dataset.\n",
            "     |  \n",
            "     |  get_data(self) -> Union[str, pathlib.Path, numpy.ndarray, pandas.core.frame.DataFrame, lightgbm.compat.dt_DataTable, scipy.sparse._matrix.spmatrix, ForwardRef('Sequence'), List[ForwardRef('Sequence')], List[numpy.ndarray], pyarrow.lib.Table, NoneType]\n",
            "     |      Get the raw data of the Dataset.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      data : str, pathlib.Path, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse, Sequence, list of Sequence or list of numpy array or None\n",
            "     |          Raw data used in the Dataset construction.\n",
            "     |  \n",
            "     |  get_feature_name(self) -> List[str]\n",
            "     |      Get the names of columns (features) in the Dataset.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      feature_names : list of str\n",
            "     |          The names of columns (features) in the Dataset.\n",
            "     |  \n",
            "     |  get_field(self, field_name: str) -> Optional[numpy.ndarray]\n",
            "     |      Get property from the Dataset.\n",
            "     |      \n",
            "     |      Can only be run on a constructed Dataset.\n",
            "     |      \n",
            "     |      Unlike ``get_group()``, ``get_init_score()``, ``get_label()``, ``get_position()``, and ``get_weight()``,\n",
            "     |      this method ignores any raw data passed into ``lgb.Dataset()`` on the Python side, and will only read\n",
            "     |      data from the constructed C++ ``Dataset`` object.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      field_name : str\n",
            "     |          The field name of the information.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      info : numpy array or None\n",
            "     |          A numpy array with information from the Dataset.\n",
            "     |  \n",
            "     |  get_group(self) -> Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType]\n",
            "     |      Get the group of the Dataset.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      group : list, numpy 1-D array, pandas Series or None\n",
            "     |          Group/query data.\n",
            "     |          Only used in the learning-to-rank task.\n",
            "     |          sum(group) = n_samples.\n",
            "     |          For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |          where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |          For a constructed ``Dataset``, this will only return ``None`` or a numpy array.\n",
            "     |  \n",
            "     |  get_init_score(self) -> Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType]\n",
            "     |      Get the initial score of the Dataset.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      init_score : list, list of lists (for multi-class task), numpy array, pandas Series, pandas DataFrame (for multi-class task), or None\n",
            "     |          Init score of Booster.\n",
            "     |          For a constructed ``Dataset``, this will only return ``None`` or a numpy array.\n",
            "     |  \n",
            "     |  get_label(self) -> Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType]\n",
            "     |      Get the label of the Dataset.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      label : list, numpy 1-D array, pandas Series / one-column DataFrame or None\n",
            "     |          The label information from the Dataset.\n",
            "     |          For a constructed ``Dataset``, this will only return a numpy array.\n",
            "     |  \n",
            "     |  get_params(self) -> Dict[str, Any]\n",
            "     |      Get the used parameters in the Dataset.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      params : dict\n",
            "     |          The used parameters in this Dataset object.\n",
            "     |  \n",
            "     |  get_position(self) -> Union[numpy.ndarray, pandas.core.series.Series, NoneType]\n",
            "     |      Get the position of the Dataset.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      position : numpy 1-D array, pandas Series or None\n",
            "     |          Position of items used in unbiased learning-to-rank task.\n",
            "     |          For a constructed ``Dataset``, this will only return ``None`` or a numpy array.\n",
            "     |  \n",
            "     |  get_ref_chain(self, ref_limit: int = 100) -> Set[ForwardRef('Dataset')]\n",
            "     |      Get a chain of Dataset objects.\n",
            "     |      \n",
            "     |      Starts with r, then goes to r.reference (if exists),\n",
            "     |      then to r.reference.reference, etc.\n",
            "     |      until we hit ``ref_limit`` or a reference loop.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      ref_limit : int, optional (default=100)\n",
            "     |          The limit number of references.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      ref_chain : set of Dataset\n",
            "     |          Chain of references of the Datasets.\n",
            "     |  \n",
            "     |  get_weight(self) -> Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType]\n",
            "     |      Get the weight of the Dataset.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      weight : list, numpy 1-D array, pandas Series or None\n",
            "     |          Weight for each data point from the Dataset. Weights should be non-negative.\n",
            "     |          For a constructed ``Dataset``, this will only return ``None`` or a numpy array.\n",
            "     |  \n",
            "     |  num_data(self) -> int\n",
            "     |      Get the number of rows in the Dataset.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      number_of_rows : int\n",
            "     |          The number of rows in the Dataset.\n",
            "     |  \n",
            "     |  num_feature(self) -> int\n",
            "     |      Get the number of columns (features) in the Dataset.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      number_of_columns : int\n",
            "     |          The number of columns (features) in the Dataset.\n",
            "     |  \n",
            "     |  save_binary(self, filename: Union[str, pathlib.Path]) -> 'Dataset'\n",
            "     |      Save Dataset to a binary file.\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |      \n",
            "     |          Please note that `init_score` is not saved in binary file.\n",
            "     |          If you need it, please set it again after loading Dataset.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      filename : str or pathlib.Path\n",
            "     |          Name of the output file.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Dataset\n",
            "     |          Returns self.\n",
            "     |  \n",
            "     |  set_categorical_feature(self, categorical_feature: Union[List[str], List[int], ForwardRef(\"Literal['auto']\")]) -> 'Dataset'\n",
            "     |      Set categorical features.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      categorical_feature : list of str or int, or 'auto'\n",
            "     |          Names or indices of categorical features.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Dataset\n",
            "     |          Dataset with set categorical features.\n",
            "     |  \n",
            "     |  set_feature_name(self, feature_name: Union[List[str], ForwardRef(\"Literal['auto']\")]) -> 'Dataset'\n",
            "     |      Set feature name.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      feature_name : list of str\n",
            "     |          Feature names.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Dataset\n",
            "     |          Dataset with set feature name.\n",
            "     |  \n",
            "     |  set_field(self, field_name: str, data: Union[List[List[float]], List[List[int]], List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType]) -> 'Dataset'\n",
            "     |      Set property into the Dataset.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      field_name : str\n",
            "     |          The field name of the information.\n",
            "     |      data : list, list of lists (for multi-class task), numpy array, pandas Series, pandas DataFrame (for multi-class task), pyarrow Array, pyarrow ChunkedArray or None\n",
            "     |          The data to be set.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Dataset\n",
            "     |          Dataset with set property.\n",
            "     |  \n",
            "     |  set_group(self, group: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType]) -> 'Dataset'\n",
            "     |      Set group size of Dataset (used for ranking).\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      group : list, numpy 1-D array, pandas Series, pyarrow Array, pyarrow ChunkedArray or None\n",
            "     |          Group/query data.\n",
            "     |          Only used in the learning-to-rank task.\n",
            "     |          sum(group) = n_samples.\n",
            "     |          For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |          where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Dataset\n",
            "     |          Dataset with set group.\n",
            "     |  \n",
            "     |  set_init_score(self, init_score: Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType]) -> 'Dataset'\n",
            "     |      Set init score of Booster to start from.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      init_score : list, list of lists (for multi-class task), numpy array, pandas Series, pandas DataFrame (for multi-class task), pyarrow Array, pyarrow ChunkedArray, pyarrow Table (for multi-class task) or None\n",
            "     |          Init score for Booster.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Dataset\n",
            "     |          Dataset with set init score.\n",
            "     |  \n",
            "     |  set_label(self, label: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType]) -> 'Dataset'\n",
            "     |      Set label of Dataset.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      label : list, numpy 1-D array, pandas Series / one-column DataFrame, pyarrow Array, pyarrow ChunkedArray or None\n",
            "     |          The label information to be set into Dataset.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Dataset\n",
            "     |          Dataset with set label.\n",
            "     |  \n",
            "     |  set_position(self, position: Union[numpy.ndarray, pandas.core.series.Series, NoneType]) -> 'Dataset'\n",
            "     |      Set position of Dataset (used for ranking).\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      position : numpy 1-D array, pandas Series or None, optional (default=None)\n",
            "     |          Position of items used in unbiased learning-to-rank task.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Dataset\n",
            "     |          Dataset with set position.\n",
            "     |  \n",
            "     |  set_reference(self, reference: 'Dataset') -> 'Dataset'\n",
            "     |      Set reference Dataset.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      reference : Dataset\n",
            "     |          Reference that is used as a template to construct the current Dataset.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Dataset\n",
            "     |          Dataset with set reference.\n",
            "     |  \n",
            "     |  set_weight(self, weight: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType]) -> 'Dataset'\n",
            "     |      Set weight of each instance.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      weight : list, numpy 1-D array, pandas Series, pyarrow Array, pyarrow ChunkedArray or None\n",
            "     |          Weight to be set for each data point. Weights should be non-negative.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : Dataset\n",
            "     |          Dataset with set weight.\n",
            "     |  \n",
            "     |  subset(self, used_indices: List[int], params: Optional[Dict[str, Any]] = None) -> 'Dataset'\n",
            "     |      Get subset of current Dataset.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      used_indices : list of int\n",
            "     |          Indices used to create the subset.\n",
            "     |      params : dict or None, optional (default=None)\n",
            "     |          These parameters will be passed to Dataset constructor.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      subset : Dataset\n",
            "     |          Subset of the current Dataset.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "    \n",
            "    class EarlyStopException(builtins.Exception)\n",
            "     |  EarlyStopException(best_iteration: int, best_score: Union[List[Tuple[str, str, float, bool]], List[Tuple[str, str, float, bool, float]]]) -> None\n",
            "     |  \n",
            "     |  Exception of early stopping.\n",
            "     |  \n",
            "     |  Raise this from a callback passed in via keyword argument ``callbacks``\n",
            "     |  in ``cv()`` or ``train()`` to trigger early stopping.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      EarlyStopException\n",
            "     |      builtins.Exception\n",
            "     |      builtins.BaseException\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, best_iteration: int, best_score: Union[List[Tuple[str, str, float, bool]], List[Tuple[str, str, float, bool, float]]]) -> None\n",
            "     |      Create early stopping exception.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      best_iteration : int\n",
            "     |          The best iteration stopped.\n",
            "     |          0-based... pass ``best_iteration=2`` to indicate that the third iteration was the best one.\n",
            "     |      best_score : list of (eval_name, metric_name, eval_result, is_higher_better) tuple or (eval_name, metric_name, eval_result, is_higher_better, stdv) tuple\n",
            "     |          Scores for each metric, on each validation set, as of the best iteration.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from builtins.Exception:\n",
            "     |  \n",
            "     |  __new__(*args, **kwargs) class method of builtins.Exception\n",
            "     |      Create and return a new object.  See help(type) for accurate signature.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from builtins.BaseException:\n",
            "     |  \n",
            "     |  __delattr__(self, name, /)\n",
            "     |      Implement delattr(self, name).\n",
            "     |  \n",
            "     |  __getattribute__(self, name, /)\n",
            "     |      Return getattr(self, name).\n",
            "     |  \n",
            "     |  __reduce__(...)\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self, /)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __setattr__(self, name, value, /)\n",
            "     |      Implement setattr(self, name, value).\n",
            "     |  \n",
            "     |  __setstate__(...)\n",
            "     |  \n",
            "     |  __str__(self, /)\n",
            "     |      Return str(self).\n",
            "     |  \n",
            "     |  add_note(...)\n",
            "     |      Exception.add_note(note) --\n",
            "     |      add a note to the exception\n",
            "     |  \n",
            "     |  with_traceback(...)\n",
            "     |      Exception.with_traceback(tb) --\n",
            "     |      set self.__traceback__ to tb and return self.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from builtins.BaseException:\n",
            "     |  \n",
            "     |  __cause__\n",
            "     |      exception cause\n",
            "     |  \n",
            "     |  __context__\n",
            "     |      exception context\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |  \n",
            "     |  __suppress_context__\n",
            "     |  \n",
            "     |  __traceback__\n",
            "     |  \n",
            "     |  args\n",
            "    \n",
            "    class LGBMClassifier(sklearn.base.ClassifierMixin, LGBMModel)\n",
            "     |  LGBMClassifier(boosting_type: str = 'gbdt', num_leaves: int = 31, max_depth: int = -1, learning_rate: float = 0.1, n_estimators: int = 100, subsample_for_bin: int = 200000, objective: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, class_weight: Union[Dict, str, NoneType] = None, min_split_gain: float = 0.0, min_child_weight: float = 0.001, min_child_samples: int = 20, subsample: float = 1.0, subsample_freq: int = 0, colsample_bytree: float = 1.0, reg_alpha: float = 0.0, reg_lambda: float = 0.0, random_state: Union[int, numpy.random.mtrand.RandomState, numpy.random._generator.Generator, NoneType] = None, n_jobs: Optional[int] = None, importance_type: str = 'split', **kwargs: Any)\n",
            "     |  \n",
            "     |  LightGBM classifier.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      LGBMClassifier\n",
            "     |      sklearn.base.ClassifierMixin\n",
            "     |      LGBMModel\n",
            "     |      sklearn.base.BaseEstimator\n",
            "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
            "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  fit(self, X: Union[lightgbm.compat.dt_DataTable, List[Union[List[float], List[int]]], numpy.ndarray, pandas.core.frame.DataFrame, scipy.sparse._matrix.spmatrix], y: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray], sample_weight: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, init_score: Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, eval_set: Optional[List[Tuple[Union[lightgbm.compat.dt_DataTable, List[Union[List[float], List[int]]], numpy.ndarray, pandas.core.frame.DataFrame, scipy.sparse._matrix.spmatrix], Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]]] = None, eval_names: Optional[List[str]] = None, eval_sample_weight: Optional[List[Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]] = None, eval_class_weight: Optional[List[float]] = None, eval_init_score: Optional[List[Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]] = None, eval_metric: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], List[Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]]]], NoneType] = None, feature_name: Union[List[str], ForwardRef(\"Literal['auto']\")] = 'auto', categorical_feature: Union[List[str], List[int], ForwardRef(\"Literal['auto']\")] = 'auto', callbacks: Optional[List[Callable]] = None, init_model: Union[str, pathlib.Path, lightgbm.basic.Booster, lightgbm.sklearn.LGBMModel, NoneType] = None) -> 'LGBMClassifier'\n",
            "     |      Build a gradient boosting model from the training set (X, y).\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : numpy array, pandas DataFrame, H2O DataTable's Frame , scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]\n",
            "     |          Input feature matrix.\n",
            "     |      y : numpy array, pandas DataFrame, pandas Series, list of int or float of shape = [n_samples]\n",
            "     |          The target values (class labels in classification, real numbers in regression).\n",
            "     |      sample_weight : numpy array, pandas Series, list of int or float of shape = [n_samples] or None, optional (default=None)\n",
            "     |          Weights of training data. Weights should be non-negative.\n",
            "     |      init_score : numpy array, pandas DataFrame, pandas Series, list of int or float of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task) or shape = [n_samples, n_classes] (for multi-class task) or None, optional (default=None)\n",
            "     |          Init score of training data.\n",
            "     |      eval_set : list or None, optional (default=None)\n",
            "     |          A list of (X, y) tuple pairs to use as validation sets.\n",
            "     |      eval_names : list of str, or None, optional (default=None)\n",
            "     |          Names of eval_set.\n",
            "     |      eval_sample_weight : list of array (same types as ``sample_weight`` supports), or None, optional (default=None)\n",
            "     |          Weights of eval data. Weights should be non-negative.\n",
            "     |      eval_class_weight : list or None, optional (default=None)\n",
            "     |          Class weights of eval data.\n",
            "     |      eval_init_score : list of array (same types as ``init_score`` supports), or None, optional (default=None)\n",
            "     |          Init score of eval data.\n",
            "     |      eval_metric : str, callable, list or None, optional (default=None)\n",
            "     |          If str, it should be a built-in evaluation metric to use.\n",
            "     |          If callable, it should be a custom evaluation metric, see note below for more details.\n",
            "     |          If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.\n",
            "     |          In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n",
            "     |          Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n",
            "     |      feature_name : list of str, or 'auto', optional (default='auto')\n",
            "     |          Feature names.\n",
            "     |          If 'auto' and data is pandas DataFrame, data columns names are used.\n",
            "     |      categorical_feature : list of str or int, or 'auto', optional (default='auto')\n",
            "     |          Categorical features.\n",
            "     |          If list of int, interpreted as indices.\n",
            "     |          If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
            "     |          If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
            "     |          All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
            "     |          Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
            "     |          All negative values in categorical features will be treated as missing values.\n",
            "     |          The output cannot be monotonically constrained with respect to a categorical feature.\n",
            "     |          Floating point numbers in categorical features will be rounded towards 0.\n",
            "     |      callbacks : list of callable, or None, optional (default=None)\n",
            "     |          List of callback functions that are applied at each iteration.\n",
            "     |          See Callbacks in Python API for more information.\n",
            "     |      init_model : str, pathlib.Path, Booster, LGBMModel or None, optional (default=None)\n",
            "     |          Filename of LightGBM model, Booster instance or LGBMModel instance used for continue training.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : LGBMClassifier\n",
            "     |          Returns self.\n",
            "     |      \n",
            "     |      \n",
            "     |      \n",
            "     |      Note\n",
            "     |      ----\n",
            "     |      Custom eval function expects a callable with following signatures:\n",
            "     |      ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
            "     |      ``func(y_true, y_pred, weight, group)``\n",
            "     |      and returns (eval_name, eval_result, is_higher_better) or\n",
            "     |      list of (eval_name, eval_result, is_higher_better):\n",
            "     |      \n",
            "     |          y_true : numpy 1-D array of shape = [n_samples]\n",
            "     |              The target values.\n",
            "     |          y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The predicted values.\n",
            "     |              In case of custom ``objective``, predicted values are returned before any transformation,\n",
            "     |              e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
            "     |          weight : numpy 1-D array of shape = [n_samples]\n",
            "     |              The weight of samples. Weights should be non-negative.\n",
            "     |          group : numpy 1-D array\n",
            "     |              Group/query data.\n",
            "     |              Only used in the learning-to-rank task.\n",
            "     |              sum(group) = n_samples.\n",
            "     |              For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |              where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |          eval_name : str\n",
            "     |              The name of evaluation function (without whitespace).\n",
            "     |          eval_result : float\n",
            "     |              The eval result.\n",
            "     |          is_higher_better : bool\n",
            "     |              Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
            "     |  \n",
            "     |  predict(self, X: Union[lightgbm.compat.dt_DataTable, List[Union[List[float], List[int]]], numpy.ndarray, pandas.core.frame.DataFrame, scipy.sparse._matrix.spmatrix], raw_score: bool = False, start_iteration: int = 0, num_iteration: Optional[int] = None, pred_leaf: bool = False, pred_contrib: bool = False, validate_features: bool = False, **kwargs: Any)\n",
            "     |      Return the predicted value for each sample.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : numpy array, pandas DataFrame, H2O DataTable's Frame , scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]\n",
            "     |          Input features matrix.\n",
            "     |      raw_score : bool, optional (default=False)\n",
            "     |          Whether to predict raw scores.\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          Start index of the iteration to predict.\n",
            "     |          If <= 0, starts from the first iteration.\n",
            "     |      num_iteration : int or None, optional (default=None)\n",
            "     |          Total number of iterations used in the prediction.\n",
            "     |          If None, if the best iteration exists and start_iteration <= 0, the best iteration is used;\n",
            "     |          otherwise, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |          If <= 0, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |      pred_leaf : bool, optional (default=False)\n",
            "     |          Whether to predict leaf index.\n",
            "     |      pred_contrib : bool, optional (default=False)\n",
            "     |          Whether to predict feature contributions.\n",
            "     |      \n",
            "     |          .. note::\n",
            "     |      \n",
            "     |              If you want to get more explanations for your model's predictions using SHAP values,\n",
            "     |              like SHAP interaction values,\n",
            "     |              you can install the shap package (https://github.com/slundberg/shap).\n",
            "     |              Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n",
            "     |              column, where the last column is the expected value.\n",
            "     |      \n",
            "     |      validate_features : bool, optional (default=False)\n",
            "     |          If True, ensure that the features used to predict match the ones used to train.\n",
            "     |          Used only if data is pandas DataFrame.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the prediction.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      predicted_result : array-like of shape = [n_samples] or shape = [n_samples, n_classes]\n",
            "     |          The predicted values.\n",
            "     |      X_leaves : array-like of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]\n",
            "     |          If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n",
            "     |      X_SHAP_values : array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or list with n_classes length of such objects\n",
            "     |          If ``pred_contrib=True``, the feature contributions for each sample.\n",
            "     |  \n",
            "     |  predict_proba(self, X: Union[lightgbm.compat.dt_DataTable, List[Union[List[float], List[int]]], numpy.ndarray, pandas.core.frame.DataFrame, scipy.sparse._matrix.spmatrix], raw_score: bool = False, start_iteration: int = 0, num_iteration: Optional[int] = None, pred_leaf: bool = False, pred_contrib: bool = False, validate_features: bool = False, **kwargs: Any)\n",
            "     |      Return the predicted probability for each class for each sample.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : numpy array, pandas DataFrame, H2O DataTable's Frame , scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]\n",
            "     |          Input features matrix.\n",
            "     |      raw_score : bool, optional (default=False)\n",
            "     |          Whether to predict raw scores.\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          Start index of the iteration to predict.\n",
            "     |          If <= 0, starts from the first iteration.\n",
            "     |      num_iteration : int or None, optional (default=None)\n",
            "     |          Total number of iterations used in the prediction.\n",
            "     |          If None, if the best iteration exists and start_iteration <= 0, the best iteration is used;\n",
            "     |          otherwise, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |          If <= 0, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |      pred_leaf : bool, optional (default=False)\n",
            "     |          Whether to predict leaf index.\n",
            "     |      pred_contrib : bool, optional (default=False)\n",
            "     |          Whether to predict feature contributions.\n",
            "     |      \n",
            "     |          .. note::\n",
            "     |      \n",
            "     |              If you want to get more explanations for your model's predictions using SHAP values,\n",
            "     |              like SHAP interaction values,\n",
            "     |              you can install the shap package (https://github.com/slundberg/shap).\n",
            "     |              Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n",
            "     |              column, where the last column is the expected value.\n",
            "     |      \n",
            "     |      validate_features : bool, optional (default=False)\n",
            "     |          If True, ensure that the features used to predict match the ones used to train.\n",
            "     |          Used only if data is pandas DataFrame.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the prediction.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      predicted_probability : array-like of shape = [n_samples] or shape = [n_samples, n_classes]\n",
            "     |          The predicted values.\n",
            "     |      X_leaves : array-like of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]\n",
            "     |          If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n",
            "     |      X_SHAP_values : array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or list with n_classes length of such objects\n",
            "     |          If ``pred_contrib=True``, the feature contributions for each sample.\n",
            "     |  \n",
            "     |  set_fit_request(self: lightgbm.sklearn.LGBMClassifier, *, callbacks: Union[bool, NoneType, str] = '$UNCHANGED$', categorical_feature: Union[bool, NoneType, str] = '$UNCHANGED$', eval_class_weight: Union[bool, NoneType, str] = '$UNCHANGED$', eval_init_score: Union[bool, NoneType, str] = '$UNCHANGED$', eval_metric: Union[bool, NoneType, str] = '$UNCHANGED$', eval_names: Union[bool, NoneType, str] = '$UNCHANGED$', eval_sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$', eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', feature_name: Union[bool, NoneType, str] = '$UNCHANGED$', init_model: Union[bool, NoneType, str] = '$UNCHANGED$', init_score: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.sklearn.LGBMClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``fit`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      callbacks : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``callbacks`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      categorical_feature : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``categorical_feature`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_class_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_class_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_init_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_init_score`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_metric : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_metric`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_names : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_names`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_sample_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_set`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      feature_name : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``feature_name`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      init_model : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``init_model`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      init_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``init_score`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  set_predict_proba_request(self: lightgbm.sklearn.LGBMClassifier, *, num_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', pred_contrib: Union[bool, NoneType, str] = '$UNCHANGED$', pred_leaf: Union[bool, NoneType, str] = '$UNCHANGED$', raw_score: Union[bool, NoneType, str] = '$UNCHANGED$', start_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.sklearn.LGBMClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``predict_proba`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``predict_proba`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict_proba``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      num_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``num_iteration`` parameter in ``predict_proba``.\n",
            "     |      \n",
            "     |      pred_contrib : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_contrib`` parameter in ``predict_proba``.\n",
            "     |      \n",
            "     |      pred_leaf : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_leaf`` parameter in ``predict_proba``.\n",
            "     |      \n",
            "     |      raw_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``raw_score`` parameter in ``predict_proba``.\n",
            "     |      \n",
            "     |      start_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``start_iteration`` parameter in ``predict_proba``.\n",
            "     |      \n",
            "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``validate_features`` parameter in ``predict_proba``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  set_predict_request(self: lightgbm.sklearn.LGBMClassifier, *, num_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', pred_contrib: Union[bool, NoneType, str] = '$UNCHANGED$', pred_leaf: Union[bool, NoneType, str] = '$UNCHANGED$', raw_score: Union[bool, NoneType, str] = '$UNCHANGED$', start_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.sklearn.LGBMClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``predict`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      num_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``num_iteration`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      pred_contrib : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_contrib`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      pred_leaf : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_leaf`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      raw_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``raw_score`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      start_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``start_iteration`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``validate_features`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  set_score_request(self: lightgbm.sklearn.LGBMClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.sklearn.LGBMClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``score`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties defined here:\n",
            "     |  \n",
            "     |  classes_\n",
            "     |      :obj:`array` of shape = [n_classes]: The class label array.\n",
            "     |  \n",
            "     |  n_classes_\n",
            "     |      :obj:`int`: The number of classes.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            "     |  \n",
            "     |  __sklearn_tags__(self)\n",
            "     |  \n",
            "     |  score(self, X, y, sample_weight=None)\n",
            "     |      Return the mean accuracy on the given test data and labels.\n",
            "     |      \n",
            "     |      In multi-label classification, this is the subset accuracy\n",
            "     |      which is a harsh metric since you require for each sample that\n",
            "     |      each label set be correctly predicted.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : array-like of shape (n_samples, n_features)\n",
            "     |          Test samples.\n",
            "     |      \n",
            "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            "     |          True labels for `X`.\n",
            "     |      \n",
            "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
            "     |          Sample weights.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      score : float\n",
            "     |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from LGBMModel:\n",
            "     |  \n",
            "     |  __init__(self, boosting_type: str = 'gbdt', num_leaves: int = 31, max_depth: int = -1, learning_rate: float = 0.1, n_estimators: int = 100, subsample_for_bin: int = 200000, objective: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, class_weight: Union[Dict, str, NoneType] = None, min_split_gain: float = 0.0, min_child_weight: float = 0.001, min_child_samples: int = 20, subsample: float = 1.0, subsample_freq: int = 0, colsample_bytree: float = 1.0, reg_alpha: float = 0.0, reg_lambda: float = 0.0, random_state: Union[int, numpy.random.mtrand.RandomState, numpy.random._generator.Generator, NoneType] = None, n_jobs: Optional[int] = None, importance_type: str = 'split', **kwargs: Any)\n",
            "     |      Construct a gradient boosting model.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      boosting_type : str, optional (default='gbdt')\n",
            "     |          'gbdt', traditional Gradient Boosting Decision Tree.\n",
            "     |          'dart', Dropouts meet Multiple Additive Regression Trees.\n",
            "     |          'rf', Random Forest.\n",
            "     |      num_leaves : int, optional (default=31)\n",
            "     |          Maximum tree leaves for base learners.\n",
            "     |      max_depth : int, optional (default=-1)\n",
            "     |          Maximum tree depth for base learners, <=0 means no limit.\n",
            "     |          If setting this to a positive value, consider also changing ``num_leaves`` to ``<= 2^max_depth``.\n",
            "     |      learning_rate : float, optional (default=0.1)\n",
            "     |          Boosting learning rate.\n",
            "     |          You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n",
            "     |          in training using ``reset_parameter`` callback.\n",
            "     |          Note, that this will ignore the ``learning_rate`` argument in training.\n",
            "     |      n_estimators : int, optional (default=100)\n",
            "     |          Number of boosted trees to fit.\n",
            "     |      subsample_for_bin : int, optional (default=200000)\n",
            "     |          Number of samples for constructing bins.\n",
            "     |      objective : str, callable or None, optional (default=None)\n",
            "     |          Specify the learning task and the corresponding learning objective or\n",
            "     |          a custom objective function to be used (see note below).\n",
            "     |          Default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
            "     |      class_weight : dict, 'balanced' or None, optional (default=None)\n",
            "     |          Weights associated with classes in the form ``{class_label: weight}``.\n",
            "     |          Use this parameter only for multi-class classification task;\n",
            "     |          for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n",
            "     |          Note, that the usage of all these parameters will result in poor estimates of the individual class probabilities.\n",
            "     |          You may want to consider performing probability calibration\n",
            "     |          (https://scikit-learn.org/stable/modules/calibration.html) of your model.\n",
            "     |          The 'balanced' mode uses the values of y to automatically adjust weights\n",
            "     |          inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n",
            "     |          If None, all classes are supposed to have weight one.\n",
            "     |          Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)\n",
            "     |          if ``sample_weight`` is specified.\n",
            "     |      min_split_gain : float, optional (default=0.)\n",
            "     |          Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
            "     |      min_child_weight : float, optional (default=1e-3)\n",
            "     |          Minimum sum of instance weight (Hessian) needed in a child (leaf).\n",
            "     |      min_child_samples : int, optional (default=20)\n",
            "     |          Minimum number of data needed in a child (leaf).\n",
            "     |      subsample : float, optional (default=1.)\n",
            "     |          Subsample ratio of the training instance.\n",
            "     |      subsample_freq : int, optional (default=0)\n",
            "     |          Frequency of subsample, <=0 means no enable.\n",
            "     |      colsample_bytree : float, optional (default=1.)\n",
            "     |          Subsample ratio of columns when constructing each tree.\n",
            "     |      reg_alpha : float, optional (default=0.)\n",
            "     |          L1 regularization term on weights.\n",
            "     |      reg_lambda : float, optional (default=0.)\n",
            "     |          L2 regularization term on weights.\n",
            "     |      random_state : int, RandomState object or None, optional (default=None)\n",
            "     |          Random number seed.\n",
            "     |          If int, this number is used to seed the C++ code.\n",
            "     |          If RandomState or Generator object (numpy), a random integer is picked based on its state to seed the C++ code.\n",
            "     |          If None, default seeds in C++ code are used.\n",
            "     |      n_jobs : int or None, optional (default=None)\n",
            "     |          Number of parallel threads to use for training (can be changed at prediction time by\n",
            "     |          passing it as an extra keyword argument).\n",
            "     |      \n",
            "     |          For better performance, it is recommended to set this to the number of physical cores\n",
            "     |          in the CPU.\n",
            "     |      \n",
            "     |          Negative integers are interpreted as following joblib's formula (n_cpus + 1 + n_jobs), just like\n",
            "     |          scikit-learn (so e.g. -1 means using all threads). A value of zero corresponds the default number of\n",
            "     |          threads configured for OpenMP in the system. A value of ``None`` (the default) corresponds\n",
            "     |          to using the number of physical cores in the system (its correct detection requires\n",
            "     |          either the ``joblib`` or the ``psutil`` util libraries to be installed).\n",
            "     |      \n",
            "     |          .. versionchanged:: 4.0.0\n",
            "     |      \n",
            "     |      importance_type : str, optional (default='split')\n",
            "     |          The type of feature importance to be filled into ``feature_importances_``.\n",
            "     |          If 'split', result contains numbers of times the feature is used in a model.\n",
            "     |          If 'gain', result contains total gains of splits which use the feature.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the model.\n",
            "     |          Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
            "     |      \n",
            "     |          .. warning::\n",
            "     |      \n",
            "     |              \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
            "     |      \n",
            "     |      Note\n",
            "     |      ----\n",
            "     |      A custom objective function can be provided for the ``objective`` parameter.\n",
            "     |      In this case, it should have the signature\n",
            "     |      ``objective(y_true, y_pred) -> grad, hess``,\n",
            "     |      ``objective(y_true, y_pred, weight) -> grad, hess``\n",
            "     |      or ``objective(y_true, y_pred, weight, group) -> grad, hess``:\n",
            "     |      \n",
            "     |          y_true : numpy 1-D array of shape = [n_samples]\n",
            "     |              The target values.\n",
            "     |          y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The predicted values.\n",
            "     |              Predicted values are returned before any transformation,\n",
            "     |              e.g. they are raw margin instead of probability of positive class for binary task.\n",
            "     |          weight : numpy 1-D array of shape = [n_samples]\n",
            "     |              The weight of samples. Weights should be non-negative.\n",
            "     |          group : numpy 1-D array\n",
            "     |              Group/query data.\n",
            "     |              Only used in the learning-to-rank task.\n",
            "     |              sum(group) = n_samples.\n",
            "     |              For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |              where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |          grad : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The value of the first order derivative (gradient) of the loss\n",
            "     |              with respect to the elements of y_pred for each sample point.\n",
            "     |          hess : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The value of the second order derivative (Hessian) of the loss\n",
            "     |              with respect to the elements of y_pred for each sample point.\n",
            "     |      \n",
            "     |      For multi-class task, y_pred is a numpy 2-D array of shape = [n_samples, n_classes],\n",
            "     |      and grad and hess should be returned in the same format.\n",
            "     |  \n",
            "     |  __sklearn_is_fitted__(self) -> bool\n",
            "     |  \n",
            "     |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
            "     |      Get parameters for this estimator.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      deep : bool, optional (default=True)\n",
            "     |          If True, will return the parameters for this estimator and\n",
            "     |          contained subobjects that are estimators.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      params : dict\n",
            "     |          Parameter names mapped to their values.\n",
            "     |  \n",
            "     |  set_params(self, **params: Any) -> 'LGBMModel'\n",
            "     |      Set the parameters of this estimator.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      **params\n",
            "     |          Parameter names with their new values.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          Returns self.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties inherited from LGBMModel:\n",
            "     |  \n",
            "     |  best_iteration_\n",
            "     |      :obj:`int`: The best iteration of fitted model if ``early_stopping()`` callback has been specified.\n",
            "     |  \n",
            "     |  best_score_\n",
            "     |      :obj:`dict`: The best score of fitted model.\n",
            "     |  \n",
            "     |  booster_\n",
            "     |      Booster: The underlying Booster of this model.\n",
            "     |  \n",
            "     |  evals_result_\n",
            "     |      :obj:`dict`: The evaluation results if validation sets have been specified.\n",
            "     |  \n",
            "     |  feature_importances_\n",
            "     |      :obj:`array` of shape = [n_features]: The feature importances (the higher, the more important).\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |      \n",
            "     |          ``importance_type`` attribute is passed to the function\n",
            "     |          to configure the type of importance values to be extracted.\n",
            "     |  \n",
            "     |  feature_name_\n",
            "     |      :obj:`list` of shape = [n_features]: The names of features.\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |      \n",
            "     |          If input does not contain feature names, they will be added during fitting in the format ``Column_0``, ``Column_1``, ..., ``Column_N``.\n",
            "     |  \n",
            "     |  feature_names_in_\n",
            "     |      :obj:`array` of shape = [n_features]: scikit-learn compatible version of ``.feature_name_``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.5.0\n",
            "     |  \n",
            "     |  n_estimators_\n",
            "     |      :obj:`int`: True number of boosting iterations performed.\n",
            "     |      \n",
            "     |      This might be less than parameter ``n_estimators`` if early stopping was enabled or\n",
            "     |      if boosting stopped early due to limits on complexity like ``min_gain_to_split``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |  \n",
            "     |  n_features_\n",
            "     |      :obj:`int`: The number of features of fitted model.\n",
            "     |  \n",
            "     |  n_features_in_\n",
            "     |      :obj:`int`: The number of features of fitted model.\n",
            "     |  \n",
            "     |  n_iter_\n",
            "     |      :obj:`int`: True number of boosting iterations performed.\n",
            "     |      \n",
            "     |      This might be less than parameter ``n_estimators`` if early stopping was enabled or\n",
            "     |      if boosting stopped early due to limits on complexity like ``min_gain_to_split``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |  \n",
            "     |  objective_\n",
            "     |      :obj:`str` or :obj:`callable`: The concrete objective used while fitting this model.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
            "     |  \n",
            "     |  __getstate__(self)\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self, N_CHAR_MAX=700)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  __sklearn_clone__(self)\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            "     |  \n",
            "     |  get_metadata_routing(self)\n",
            "     |      Get metadata routing of this object.\n",
            "     |      \n",
            "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      routing : MetadataRequest\n",
            "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
            "     |          routing information.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            "     |  \n",
            "     |  __init_subclass__(**kwargs)\n",
            "     |      Set the ``set_{method}_request`` methods.\n",
            "     |      \n",
            "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
            "     |      looks for the information available in the set default values which are\n",
            "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
            "     |      from method signatures.\n",
            "     |      \n",
            "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
            "     |      does not explicitly accept a metadata through its arguments or if the\n",
            "     |      developer would like to specify a request value for those metadata\n",
            "     |      which are different from the default ``None``.\n",
            "     |      \n",
            "     |      References\n",
            "     |      ----------\n",
            "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
            "    \n",
            "    class LGBMModel(sklearn.base.BaseEstimator)\n",
            "     |  LGBMModel(boosting_type: str = 'gbdt', num_leaves: int = 31, max_depth: int = -1, learning_rate: float = 0.1, n_estimators: int = 100, subsample_for_bin: int = 200000, objective: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, class_weight: Union[Dict, str, NoneType] = None, min_split_gain: float = 0.0, min_child_weight: float = 0.001, min_child_samples: int = 20, subsample: float = 1.0, subsample_freq: int = 0, colsample_bytree: float = 1.0, reg_alpha: float = 0.0, reg_lambda: float = 0.0, random_state: Union[int, numpy.random.mtrand.RandomState, numpy.random._generator.Generator, NoneType] = None, n_jobs: Optional[int] = None, importance_type: str = 'split', **kwargs: Any)\n",
            "     |  \n",
            "     |  Implementation of the scikit-learn API for LightGBM.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      LGBMModel\n",
            "     |      sklearn.base.BaseEstimator\n",
            "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
            "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, boosting_type: str = 'gbdt', num_leaves: int = 31, max_depth: int = -1, learning_rate: float = 0.1, n_estimators: int = 100, subsample_for_bin: int = 200000, objective: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, class_weight: Union[Dict, str, NoneType] = None, min_split_gain: float = 0.0, min_child_weight: float = 0.001, min_child_samples: int = 20, subsample: float = 1.0, subsample_freq: int = 0, colsample_bytree: float = 1.0, reg_alpha: float = 0.0, reg_lambda: float = 0.0, random_state: Union[int, numpy.random.mtrand.RandomState, numpy.random._generator.Generator, NoneType] = None, n_jobs: Optional[int] = None, importance_type: str = 'split', **kwargs: Any)\n",
            "     |      Construct a gradient boosting model.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      boosting_type : str, optional (default='gbdt')\n",
            "     |          'gbdt', traditional Gradient Boosting Decision Tree.\n",
            "     |          'dart', Dropouts meet Multiple Additive Regression Trees.\n",
            "     |          'rf', Random Forest.\n",
            "     |      num_leaves : int, optional (default=31)\n",
            "     |          Maximum tree leaves for base learners.\n",
            "     |      max_depth : int, optional (default=-1)\n",
            "     |          Maximum tree depth for base learners, <=0 means no limit.\n",
            "     |          If setting this to a positive value, consider also changing ``num_leaves`` to ``<= 2^max_depth``.\n",
            "     |      learning_rate : float, optional (default=0.1)\n",
            "     |          Boosting learning rate.\n",
            "     |          You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n",
            "     |          in training using ``reset_parameter`` callback.\n",
            "     |          Note, that this will ignore the ``learning_rate`` argument in training.\n",
            "     |      n_estimators : int, optional (default=100)\n",
            "     |          Number of boosted trees to fit.\n",
            "     |      subsample_for_bin : int, optional (default=200000)\n",
            "     |          Number of samples for constructing bins.\n",
            "     |      objective : str, callable or None, optional (default=None)\n",
            "     |          Specify the learning task and the corresponding learning objective or\n",
            "     |          a custom objective function to be used (see note below).\n",
            "     |          Default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
            "     |      class_weight : dict, 'balanced' or None, optional (default=None)\n",
            "     |          Weights associated with classes in the form ``{class_label: weight}``.\n",
            "     |          Use this parameter only for multi-class classification task;\n",
            "     |          for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n",
            "     |          Note, that the usage of all these parameters will result in poor estimates of the individual class probabilities.\n",
            "     |          You may want to consider performing probability calibration\n",
            "     |          (https://scikit-learn.org/stable/modules/calibration.html) of your model.\n",
            "     |          The 'balanced' mode uses the values of y to automatically adjust weights\n",
            "     |          inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n",
            "     |          If None, all classes are supposed to have weight one.\n",
            "     |          Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)\n",
            "     |          if ``sample_weight`` is specified.\n",
            "     |      min_split_gain : float, optional (default=0.)\n",
            "     |          Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
            "     |      min_child_weight : float, optional (default=1e-3)\n",
            "     |          Minimum sum of instance weight (Hessian) needed in a child (leaf).\n",
            "     |      min_child_samples : int, optional (default=20)\n",
            "     |          Minimum number of data needed in a child (leaf).\n",
            "     |      subsample : float, optional (default=1.)\n",
            "     |          Subsample ratio of the training instance.\n",
            "     |      subsample_freq : int, optional (default=0)\n",
            "     |          Frequency of subsample, <=0 means no enable.\n",
            "     |      colsample_bytree : float, optional (default=1.)\n",
            "     |          Subsample ratio of columns when constructing each tree.\n",
            "     |      reg_alpha : float, optional (default=0.)\n",
            "     |          L1 regularization term on weights.\n",
            "     |      reg_lambda : float, optional (default=0.)\n",
            "     |          L2 regularization term on weights.\n",
            "     |      random_state : int, RandomState object or None, optional (default=None)\n",
            "     |          Random number seed.\n",
            "     |          If int, this number is used to seed the C++ code.\n",
            "     |          If RandomState or Generator object (numpy), a random integer is picked based on its state to seed the C++ code.\n",
            "     |          If None, default seeds in C++ code are used.\n",
            "     |      n_jobs : int or None, optional (default=None)\n",
            "     |          Number of parallel threads to use for training (can be changed at prediction time by\n",
            "     |          passing it as an extra keyword argument).\n",
            "     |      \n",
            "     |          For better performance, it is recommended to set this to the number of physical cores\n",
            "     |          in the CPU.\n",
            "     |      \n",
            "     |          Negative integers are interpreted as following joblib's formula (n_cpus + 1 + n_jobs), just like\n",
            "     |          scikit-learn (so e.g. -1 means using all threads). A value of zero corresponds the default number of\n",
            "     |          threads configured for OpenMP in the system. A value of ``None`` (the default) corresponds\n",
            "     |          to using the number of physical cores in the system (its correct detection requires\n",
            "     |          either the ``joblib`` or the ``psutil`` util libraries to be installed).\n",
            "     |      \n",
            "     |          .. versionchanged:: 4.0.0\n",
            "     |      \n",
            "     |      importance_type : str, optional (default='split')\n",
            "     |          The type of feature importance to be filled into ``feature_importances_``.\n",
            "     |          If 'split', result contains numbers of times the feature is used in a model.\n",
            "     |          If 'gain', result contains total gains of splits which use the feature.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the model.\n",
            "     |          Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
            "     |      \n",
            "     |          .. warning::\n",
            "     |      \n",
            "     |              \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
            "     |      \n",
            "     |      Note\n",
            "     |      ----\n",
            "     |      A custom objective function can be provided for the ``objective`` parameter.\n",
            "     |      In this case, it should have the signature\n",
            "     |      ``objective(y_true, y_pred) -> grad, hess``,\n",
            "     |      ``objective(y_true, y_pred, weight) -> grad, hess``\n",
            "     |      or ``objective(y_true, y_pred, weight, group) -> grad, hess``:\n",
            "     |      \n",
            "     |          y_true : numpy 1-D array of shape = [n_samples]\n",
            "     |              The target values.\n",
            "     |          y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The predicted values.\n",
            "     |              Predicted values are returned before any transformation,\n",
            "     |              e.g. they are raw margin instead of probability of positive class for binary task.\n",
            "     |          weight : numpy 1-D array of shape = [n_samples]\n",
            "     |              The weight of samples. Weights should be non-negative.\n",
            "     |          group : numpy 1-D array\n",
            "     |              Group/query data.\n",
            "     |              Only used in the learning-to-rank task.\n",
            "     |              sum(group) = n_samples.\n",
            "     |              For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |              where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |          grad : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The value of the first order derivative (gradient) of the loss\n",
            "     |              with respect to the elements of y_pred for each sample point.\n",
            "     |          hess : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The value of the second order derivative (Hessian) of the loss\n",
            "     |              with respect to the elements of y_pred for each sample point.\n",
            "     |      \n",
            "     |      For multi-class task, y_pred is a numpy 2-D array of shape = [n_samples, n_classes],\n",
            "     |      and grad and hess should be returned in the same format.\n",
            "     |  \n",
            "     |  __sklearn_is_fitted__(self) -> bool\n",
            "     |  \n",
            "     |  fit(self, X: Union[lightgbm.compat.dt_DataTable, List[Union[List[float], List[int]]], numpy.ndarray, pandas.core.frame.DataFrame, scipy.sparse._matrix.spmatrix], y: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray], sample_weight: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, init_score: Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, group: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, eval_set: Optional[List[Tuple[Union[lightgbm.compat.dt_DataTable, List[Union[List[float], List[int]]], numpy.ndarray, pandas.core.frame.DataFrame, scipy.sparse._matrix.spmatrix], Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]]] = None, eval_names: Optional[List[str]] = None, eval_sample_weight: Optional[List[Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]] = None, eval_class_weight: Optional[List[float]] = None, eval_init_score: Optional[List[Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]] = None, eval_group: Optional[List[Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]] = None, eval_metric: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], List[Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]]]], NoneType] = None, feature_name: Union[List[str], ForwardRef(\"Literal['auto']\")] = 'auto', categorical_feature: Union[List[str], List[int], ForwardRef(\"Literal['auto']\")] = 'auto', callbacks: Optional[List[Callable]] = None, init_model: Union[str, pathlib.Path, lightgbm.basic.Booster, ForwardRef('LGBMModel'), NoneType] = None) -> 'LGBMModel'\n",
            "     |      Build a gradient boosting model from the training set (X, y).\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : numpy array, pandas DataFrame, H2O DataTable's Frame , scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]\n",
            "     |          Input feature matrix.\n",
            "     |      y : numpy array, pandas DataFrame, pandas Series, list of int or float of shape = [n_samples]\n",
            "     |          The target values (class labels in classification, real numbers in regression).\n",
            "     |      sample_weight : numpy array, pandas Series, list of int or float of shape = [n_samples] or None, optional (default=None)\n",
            "     |          Weights of training data. Weights should be non-negative.\n",
            "     |      init_score : numpy array, pandas DataFrame, pandas Series, list of int or float of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task) or shape = [n_samples, n_classes] (for multi-class task) or None, optional (default=None)\n",
            "     |          Init score of training data.\n",
            "     |      group : numpy array, pandas Series, list of int or float, or None, optional (default=None)\n",
            "     |          Group/query data.\n",
            "     |          Only used in the learning-to-rank task.\n",
            "     |          sum(group) = n_samples.\n",
            "     |          For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |          where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |      eval_set : list or None, optional (default=None)\n",
            "     |          A list of (X, y) tuple pairs to use as validation sets.\n",
            "     |      eval_names : list of str, or None, optional (default=None)\n",
            "     |          Names of eval_set.\n",
            "     |      eval_sample_weight : list of array (same types as ``sample_weight`` supports), or None, optional (default=None)\n",
            "     |          Weights of eval data. Weights should be non-negative.\n",
            "     |      eval_class_weight : list or None, optional (default=None)\n",
            "     |          Class weights of eval data.\n",
            "     |      eval_init_score : list of array (same types as ``init_score`` supports), or None, optional (default=None)\n",
            "     |          Init score of eval data.\n",
            "     |      eval_group : list of array (same types as ``group`` supports), or None, optional (default=None)\n",
            "     |          Group data of eval data.\n",
            "     |      eval_metric : str, callable, list or None, optional (default=None)\n",
            "     |          If str, it should be a built-in evaluation metric to use.\n",
            "     |          If callable, it should be a custom evaluation metric, see note below for more details.\n",
            "     |          If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.\n",
            "     |          In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n",
            "     |          Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n",
            "     |      feature_name : list of str, or 'auto', optional (default='auto')\n",
            "     |          Feature names.\n",
            "     |          If 'auto' and data is pandas DataFrame, data columns names are used.\n",
            "     |      categorical_feature : list of str or int, or 'auto', optional (default='auto')\n",
            "     |          Categorical features.\n",
            "     |          If list of int, interpreted as indices.\n",
            "     |          If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
            "     |          If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
            "     |          All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
            "     |          Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
            "     |          All negative values in categorical features will be treated as missing values.\n",
            "     |          The output cannot be monotonically constrained with respect to a categorical feature.\n",
            "     |          Floating point numbers in categorical features will be rounded towards 0.\n",
            "     |      callbacks : list of callable, or None, optional (default=None)\n",
            "     |          List of callback functions that are applied at each iteration.\n",
            "     |          See Callbacks in Python API for more information.\n",
            "     |      init_model : str, pathlib.Path, Booster, LGBMModel or None, optional (default=None)\n",
            "     |          Filename of LightGBM model, Booster instance or LGBMModel instance used for continue training.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : LGBMModel\n",
            "     |          Returns self.\n",
            "     |      \n",
            "     |      \n",
            "     |      \n",
            "     |      Note\n",
            "     |      ----\n",
            "     |      Custom eval function expects a callable with following signatures:\n",
            "     |      ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
            "     |      ``func(y_true, y_pred, weight, group)``\n",
            "     |      and returns (eval_name, eval_result, is_higher_better) or\n",
            "     |      list of (eval_name, eval_result, is_higher_better):\n",
            "     |      \n",
            "     |          y_true : numpy 1-D array of shape = [n_samples]\n",
            "     |              The target values.\n",
            "     |          y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The predicted values.\n",
            "     |              In case of custom ``objective``, predicted values are returned before any transformation,\n",
            "     |              e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
            "     |          weight : numpy 1-D array of shape = [n_samples]\n",
            "     |              The weight of samples. Weights should be non-negative.\n",
            "     |          group : numpy 1-D array\n",
            "     |              Group/query data.\n",
            "     |              Only used in the learning-to-rank task.\n",
            "     |              sum(group) = n_samples.\n",
            "     |              For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |              where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |          eval_name : str\n",
            "     |              The name of evaluation function (without whitespace).\n",
            "     |          eval_result : float\n",
            "     |              The eval result.\n",
            "     |          is_higher_better : bool\n",
            "     |              Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
            "     |  \n",
            "     |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
            "     |      Get parameters for this estimator.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      deep : bool, optional (default=True)\n",
            "     |          If True, will return the parameters for this estimator and\n",
            "     |          contained subobjects that are estimators.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      params : dict\n",
            "     |          Parameter names mapped to their values.\n",
            "     |  \n",
            "     |  predict(self, X: Union[lightgbm.compat.dt_DataTable, List[Union[List[float], List[int]]], numpy.ndarray, pandas.core.frame.DataFrame, scipy.sparse._matrix.spmatrix], raw_score: bool = False, start_iteration: int = 0, num_iteration: Optional[int] = None, pred_leaf: bool = False, pred_contrib: bool = False, validate_features: bool = False, **kwargs: Any)\n",
            "     |      Return the predicted value for each sample.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : numpy array, pandas DataFrame, H2O DataTable's Frame , scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]\n",
            "     |          Input features matrix.\n",
            "     |      raw_score : bool, optional (default=False)\n",
            "     |          Whether to predict raw scores.\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          Start index of the iteration to predict.\n",
            "     |          If <= 0, starts from the first iteration.\n",
            "     |      num_iteration : int or None, optional (default=None)\n",
            "     |          Total number of iterations used in the prediction.\n",
            "     |          If None, if the best iteration exists and start_iteration <= 0, the best iteration is used;\n",
            "     |          otherwise, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |          If <= 0, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |      pred_leaf : bool, optional (default=False)\n",
            "     |          Whether to predict leaf index.\n",
            "     |      pred_contrib : bool, optional (default=False)\n",
            "     |          Whether to predict feature contributions.\n",
            "     |      \n",
            "     |          .. note::\n",
            "     |      \n",
            "     |              If you want to get more explanations for your model's predictions using SHAP values,\n",
            "     |              like SHAP interaction values,\n",
            "     |              you can install the shap package (https://github.com/slundberg/shap).\n",
            "     |              Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n",
            "     |              column, where the last column is the expected value.\n",
            "     |      \n",
            "     |      validate_features : bool, optional (default=False)\n",
            "     |          If True, ensure that the features used to predict match the ones used to train.\n",
            "     |          Used only if data is pandas DataFrame.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the prediction.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      predicted_result : array-like of shape = [n_samples] or shape = [n_samples, n_classes]\n",
            "     |          The predicted values.\n",
            "     |      X_leaves : array-like of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]\n",
            "     |          If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n",
            "     |      X_SHAP_values : array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or list with n_classes length of such objects\n",
            "     |          If ``pred_contrib=True``, the feature contributions for each sample.\n",
            "     |  \n",
            "     |  set_fit_request(self: lightgbm.sklearn.LGBMModel, *, callbacks: Union[bool, NoneType, str] = '$UNCHANGED$', categorical_feature: Union[bool, NoneType, str] = '$UNCHANGED$', eval_class_weight: Union[bool, NoneType, str] = '$UNCHANGED$', eval_group: Union[bool, NoneType, str] = '$UNCHANGED$', eval_init_score: Union[bool, NoneType, str] = '$UNCHANGED$', eval_metric: Union[bool, NoneType, str] = '$UNCHANGED$', eval_names: Union[bool, NoneType, str] = '$UNCHANGED$', eval_sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$', eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', feature_name: Union[bool, NoneType, str] = '$UNCHANGED$', group: Union[bool, NoneType, str] = '$UNCHANGED$', init_model: Union[bool, NoneType, str] = '$UNCHANGED$', init_score: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.sklearn.LGBMModel from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``fit`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      callbacks : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``callbacks`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      categorical_feature : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``categorical_feature`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_class_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_class_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_group : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_group`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_init_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_init_score`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_metric : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_metric`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_names : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_names`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_sample_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_set`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      feature_name : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``feature_name`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      group : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``group`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      init_model : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``init_model`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      init_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``init_score`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  set_params(self, **params: Any) -> 'LGBMModel'\n",
            "     |      Set the parameters of this estimator.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      **params\n",
            "     |          Parameter names with their new values.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          Returns self.\n",
            "     |  \n",
            "     |  set_predict_request(self: lightgbm.sklearn.LGBMModel, *, num_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', pred_contrib: Union[bool, NoneType, str] = '$UNCHANGED$', pred_leaf: Union[bool, NoneType, str] = '$UNCHANGED$', raw_score: Union[bool, NoneType, str] = '$UNCHANGED$', start_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.sklearn.LGBMModel from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``predict`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      num_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``num_iteration`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      pred_contrib : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_contrib`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      pred_leaf : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_leaf`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      raw_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``raw_score`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      start_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``start_iteration`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``validate_features`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties defined here:\n",
            "     |  \n",
            "     |  best_iteration_\n",
            "     |      :obj:`int`: The best iteration of fitted model if ``early_stopping()`` callback has been specified.\n",
            "     |  \n",
            "     |  best_score_\n",
            "     |      :obj:`dict`: The best score of fitted model.\n",
            "     |  \n",
            "     |  booster_\n",
            "     |      Booster: The underlying Booster of this model.\n",
            "     |  \n",
            "     |  evals_result_\n",
            "     |      :obj:`dict`: The evaluation results if validation sets have been specified.\n",
            "     |  \n",
            "     |  feature_importances_\n",
            "     |      :obj:`array` of shape = [n_features]: The feature importances (the higher, the more important).\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |      \n",
            "     |          ``importance_type`` attribute is passed to the function\n",
            "     |          to configure the type of importance values to be extracted.\n",
            "     |  \n",
            "     |  feature_name_\n",
            "     |      :obj:`list` of shape = [n_features]: The names of features.\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |      \n",
            "     |          If input does not contain feature names, they will be added during fitting in the format ``Column_0``, ``Column_1``, ..., ``Column_N``.\n",
            "     |  \n",
            "     |  feature_names_in_\n",
            "     |      :obj:`array` of shape = [n_features]: scikit-learn compatible version of ``.feature_name_``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.5.0\n",
            "     |  \n",
            "     |  n_estimators_\n",
            "     |      :obj:`int`: True number of boosting iterations performed.\n",
            "     |      \n",
            "     |      This might be less than parameter ``n_estimators`` if early stopping was enabled or\n",
            "     |      if boosting stopped early due to limits on complexity like ``min_gain_to_split``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |  \n",
            "     |  n_features_\n",
            "     |      :obj:`int`: The number of features of fitted model.\n",
            "     |  \n",
            "     |  n_features_in_\n",
            "     |      :obj:`int`: The number of features of fitted model.\n",
            "     |  \n",
            "     |  n_iter_\n",
            "     |      :obj:`int`: True number of boosting iterations performed.\n",
            "     |      \n",
            "     |      This might be less than parameter ``n_estimators`` if early stopping was enabled or\n",
            "     |      if boosting stopped early due to limits on complexity like ``min_gain_to_split``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |  \n",
            "     |  objective_\n",
            "     |      :obj:`str` or :obj:`callable`: The concrete objective used while fitting this model.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
            "     |  \n",
            "     |  __getstate__(self)\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self, N_CHAR_MAX=700)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  __sklearn_clone__(self)\n",
            "     |  \n",
            "     |  __sklearn_tags__(self)\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            "     |  \n",
            "     |  get_metadata_routing(self)\n",
            "     |      Get metadata routing of this object.\n",
            "     |      \n",
            "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      routing : MetadataRequest\n",
            "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
            "     |          routing information.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            "     |  \n",
            "     |  __init_subclass__(**kwargs)\n",
            "     |      Set the ``set_{method}_request`` methods.\n",
            "     |      \n",
            "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
            "     |      looks for the information available in the set default values which are\n",
            "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
            "     |      from method signatures.\n",
            "     |      \n",
            "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
            "     |      does not explicitly accept a metadata through its arguments or if the\n",
            "     |      developer would like to specify a request value for those metadata\n",
            "     |      which are different from the default ``None``.\n",
            "     |      \n",
            "     |      References\n",
            "     |      ----------\n",
            "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
            "    \n",
            "    class LGBMRanker(LGBMModel)\n",
            "     |  LGBMRanker(boosting_type: str = 'gbdt', num_leaves: int = 31, max_depth: int = -1, learning_rate: float = 0.1, n_estimators: int = 100, subsample_for_bin: int = 200000, objective: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, class_weight: Union[Dict, str, NoneType] = None, min_split_gain: float = 0.0, min_child_weight: float = 0.001, min_child_samples: int = 20, subsample: float = 1.0, subsample_freq: int = 0, colsample_bytree: float = 1.0, reg_alpha: float = 0.0, reg_lambda: float = 0.0, random_state: Union[int, numpy.random.mtrand.RandomState, numpy.random._generator.Generator, NoneType] = None, n_jobs: Optional[int] = None, importance_type: str = 'split', **kwargs: Any)\n",
            "     |  \n",
            "     |  LightGBM ranker.\n",
            "     |  \n",
            "     |  .. warning::\n",
            "     |  \n",
            "     |      scikit-learn doesn't support ranking applications yet,\n",
            "     |      therefore this class is not really compatible with the sklearn ecosystem.\n",
            "     |      Please use this class mainly for training and applying ranking models in common sklearnish way.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      LGBMRanker\n",
            "     |      LGBMModel\n",
            "     |      sklearn.base.BaseEstimator\n",
            "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
            "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  fit(self, X: Union[lightgbm.compat.dt_DataTable, List[Union[List[float], List[int]]], numpy.ndarray, pandas.core.frame.DataFrame, scipy.sparse._matrix.spmatrix], y: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray], sample_weight: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, init_score: Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, group: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, eval_set: Optional[List[Tuple[Union[lightgbm.compat.dt_DataTable, List[Union[List[float], List[int]]], numpy.ndarray, pandas.core.frame.DataFrame, scipy.sparse._matrix.spmatrix], Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]]] = None, eval_names: Optional[List[str]] = None, eval_sample_weight: Optional[List[Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]] = None, eval_init_score: Optional[List[Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]] = None, eval_group: Optional[List[Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]] = None, eval_metric: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], List[Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]]]], NoneType] = None, eval_at: Union[List[int], Tuple[int, ...]] = (1, 2, 3, 4, 5), feature_name: Union[List[str], ForwardRef(\"Literal['auto']\")] = 'auto', categorical_feature: Union[List[str], List[int], ForwardRef(\"Literal['auto']\")] = 'auto', callbacks: Optional[List[Callable]] = None, init_model: Union[str, pathlib.Path, lightgbm.basic.Booster, lightgbm.sklearn.LGBMModel, NoneType] = None) -> 'LGBMRanker'\n",
            "     |      Build a gradient boosting model from the training set (X, y).\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : numpy array, pandas DataFrame, H2O DataTable's Frame , scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]\n",
            "     |          Input feature matrix.\n",
            "     |      y : numpy array, pandas DataFrame, pandas Series, list of int or float of shape = [n_samples]\n",
            "     |          The target values (class labels in classification, real numbers in regression).\n",
            "     |      sample_weight : numpy array, pandas Series, list of int or float of shape = [n_samples] or None, optional (default=None)\n",
            "     |          Weights of training data. Weights should be non-negative.\n",
            "     |      init_score : numpy array, pandas DataFrame, pandas Series, list of int or float of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task) or shape = [n_samples, n_classes] (for multi-class task) or None, optional (default=None)\n",
            "     |          Init score of training data.\n",
            "     |      group : numpy array, pandas Series, list of int or float, or None, optional (default=None)\n",
            "     |          Group/query data.\n",
            "     |          Only used in the learning-to-rank task.\n",
            "     |          sum(group) = n_samples.\n",
            "     |          For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |          where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |      eval_set : list or None, optional (default=None)\n",
            "     |          A list of (X, y) tuple pairs to use as validation sets.\n",
            "     |      eval_names : list of str, or None, optional (default=None)\n",
            "     |          Names of eval_set.\n",
            "     |      eval_sample_weight : list of array (same types as ``sample_weight`` supports), or None, optional (default=None)\n",
            "     |          Weights of eval data. Weights should be non-negative.\n",
            "     |      eval_init_score : list of array (same types as ``init_score`` supports), or None, optional (default=None)\n",
            "     |          Init score of eval data.\n",
            "     |      eval_group : list of array (same types as ``group`` supports), or None, optional (default=None)\n",
            "     |          Group data of eval data.\n",
            "     |      eval_metric : str, callable, list or None, optional (default=None)\n",
            "     |          If str, it should be a built-in evaluation metric to use.\n",
            "     |          If callable, it should be a custom evaluation metric, see note below for more details.\n",
            "     |          If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.\n",
            "     |          In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n",
            "     |          Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n",
            "     |      eval_at : list or tuple of int, optional (default=(1, 2, 3, 4, 5))\n",
            "     |          The evaluation positions of the specified metric.\n",
            "     |      feature_name : list of str, or 'auto', optional (default='auto')\n",
            "     |          Feature names.\n",
            "     |          If 'auto' and data is pandas DataFrame, data columns names are used.\n",
            "     |      categorical_feature : list of str or int, or 'auto', optional (default='auto')\n",
            "     |          Categorical features.\n",
            "     |          If list of int, interpreted as indices.\n",
            "     |          If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
            "     |          If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
            "     |          All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
            "     |          Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
            "     |          All negative values in categorical features will be treated as missing values.\n",
            "     |          The output cannot be monotonically constrained with respect to a categorical feature.\n",
            "     |          Floating point numbers in categorical features will be rounded towards 0.\n",
            "     |      callbacks : list of callable, or None, optional (default=None)\n",
            "     |          List of callback functions that are applied at each iteration.\n",
            "     |          See Callbacks in Python API for more information.\n",
            "     |      init_model : str, pathlib.Path, Booster, LGBMModel or None, optional (default=None)\n",
            "     |          Filename of LightGBM model, Booster instance or LGBMModel instance used for continue training.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : LGBMRanker\n",
            "     |          Returns self.\n",
            "     |      \n",
            "     |      \n",
            "     |      \n",
            "     |      Note\n",
            "     |      ----\n",
            "     |      Custom eval function expects a callable with following signatures:\n",
            "     |      ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
            "     |      ``func(y_true, y_pred, weight, group)``\n",
            "     |      and returns (eval_name, eval_result, is_higher_better) or\n",
            "     |      list of (eval_name, eval_result, is_higher_better):\n",
            "     |      \n",
            "     |          y_true : numpy 1-D array of shape = [n_samples]\n",
            "     |              The target values.\n",
            "     |          y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The predicted values.\n",
            "     |              In case of custom ``objective``, predicted values are returned before any transformation,\n",
            "     |              e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
            "     |          weight : numpy 1-D array of shape = [n_samples]\n",
            "     |              The weight of samples. Weights should be non-negative.\n",
            "     |          group : numpy 1-D array\n",
            "     |              Group/query data.\n",
            "     |              Only used in the learning-to-rank task.\n",
            "     |              sum(group) = n_samples.\n",
            "     |              For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |              where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |          eval_name : str\n",
            "     |              The name of evaluation function (without whitespace).\n",
            "     |          eval_result : float\n",
            "     |              The eval result.\n",
            "     |          is_higher_better : bool\n",
            "     |              Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
            "     |  \n",
            "     |  set_fit_request(self: lightgbm.sklearn.LGBMRanker, *, callbacks: Union[bool, NoneType, str] = '$UNCHANGED$', categorical_feature: Union[bool, NoneType, str] = '$UNCHANGED$', eval_at: Union[bool, NoneType, str] = '$UNCHANGED$', eval_group: Union[bool, NoneType, str] = '$UNCHANGED$', eval_init_score: Union[bool, NoneType, str] = '$UNCHANGED$', eval_metric: Union[bool, NoneType, str] = '$UNCHANGED$', eval_names: Union[bool, NoneType, str] = '$UNCHANGED$', eval_sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$', eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', feature_name: Union[bool, NoneType, str] = '$UNCHANGED$', group: Union[bool, NoneType, str] = '$UNCHANGED$', init_model: Union[bool, NoneType, str] = '$UNCHANGED$', init_score: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.sklearn.LGBMRanker from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``fit`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      callbacks : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``callbacks`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      categorical_feature : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``categorical_feature`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_at : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_at`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_group : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_group`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_init_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_init_score`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_metric : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_metric`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_names : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_names`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_sample_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_set`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      feature_name : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``feature_name`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      group : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``group`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      init_model : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``init_model`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      init_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``init_score`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  set_predict_request(self: lightgbm.sklearn.LGBMRanker, *, num_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', pred_contrib: Union[bool, NoneType, str] = '$UNCHANGED$', pred_leaf: Union[bool, NoneType, str] = '$UNCHANGED$', raw_score: Union[bool, NoneType, str] = '$UNCHANGED$', start_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.sklearn.LGBMRanker from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``predict`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      num_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``num_iteration`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      pred_contrib : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_contrib`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      pred_leaf : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_leaf`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      raw_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``raw_score`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      start_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``start_iteration`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``validate_features`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from LGBMModel:\n",
            "     |  \n",
            "     |  __init__(self, boosting_type: str = 'gbdt', num_leaves: int = 31, max_depth: int = -1, learning_rate: float = 0.1, n_estimators: int = 100, subsample_for_bin: int = 200000, objective: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, class_weight: Union[Dict, str, NoneType] = None, min_split_gain: float = 0.0, min_child_weight: float = 0.001, min_child_samples: int = 20, subsample: float = 1.0, subsample_freq: int = 0, colsample_bytree: float = 1.0, reg_alpha: float = 0.0, reg_lambda: float = 0.0, random_state: Union[int, numpy.random.mtrand.RandomState, numpy.random._generator.Generator, NoneType] = None, n_jobs: Optional[int] = None, importance_type: str = 'split', **kwargs: Any)\n",
            "     |      Construct a gradient boosting model.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      boosting_type : str, optional (default='gbdt')\n",
            "     |          'gbdt', traditional Gradient Boosting Decision Tree.\n",
            "     |          'dart', Dropouts meet Multiple Additive Regression Trees.\n",
            "     |          'rf', Random Forest.\n",
            "     |      num_leaves : int, optional (default=31)\n",
            "     |          Maximum tree leaves for base learners.\n",
            "     |      max_depth : int, optional (default=-1)\n",
            "     |          Maximum tree depth for base learners, <=0 means no limit.\n",
            "     |          If setting this to a positive value, consider also changing ``num_leaves`` to ``<= 2^max_depth``.\n",
            "     |      learning_rate : float, optional (default=0.1)\n",
            "     |          Boosting learning rate.\n",
            "     |          You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n",
            "     |          in training using ``reset_parameter`` callback.\n",
            "     |          Note, that this will ignore the ``learning_rate`` argument in training.\n",
            "     |      n_estimators : int, optional (default=100)\n",
            "     |          Number of boosted trees to fit.\n",
            "     |      subsample_for_bin : int, optional (default=200000)\n",
            "     |          Number of samples for constructing bins.\n",
            "     |      objective : str, callable or None, optional (default=None)\n",
            "     |          Specify the learning task and the corresponding learning objective or\n",
            "     |          a custom objective function to be used (see note below).\n",
            "     |          Default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
            "     |      class_weight : dict, 'balanced' or None, optional (default=None)\n",
            "     |          Weights associated with classes in the form ``{class_label: weight}``.\n",
            "     |          Use this parameter only for multi-class classification task;\n",
            "     |          for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n",
            "     |          Note, that the usage of all these parameters will result in poor estimates of the individual class probabilities.\n",
            "     |          You may want to consider performing probability calibration\n",
            "     |          (https://scikit-learn.org/stable/modules/calibration.html) of your model.\n",
            "     |          The 'balanced' mode uses the values of y to automatically adjust weights\n",
            "     |          inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n",
            "     |          If None, all classes are supposed to have weight one.\n",
            "     |          Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)\n",
            "     |          if ``sample_weight`` is specified.\n",
            "     |      min_split_gain : float, optional (default=0.)\n",
            "     |          Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
            "     |      min_child_weight : float, optional (default=1e-3)\n",
            "     |          Minimum sum of instance weight (Hessian) needed in a child (leaf).\n",
            "     |      min_child_samples : int, optional (default=20)\n",
            "     |          Minimum number of data needed in a child (leaf).\n",
            "     |      subsample : float, optional (default=1.)\n",
            "     |          Subsample ratio of the training instance.\n",
            "     |      subsample_freq : int, optional (default=0)\n",
            "     |          Frequency of subsample, <=0 means no enable.\n",
            "     |      colsample_bytree : float, optional (default=1.)\n",
            "     |          Subsample ratio of columns when constructing each tree.\n",
            "     |      reg_alpha : float, optional (default=0.)\n",
            "     |          L1 regularization term on weights.\n",
            "     |      reg_lambda : float, optional (default=0.)\n",
            "     |          L2 regularization term on weights.\n",
            "     |      random_state : int, RandomState object or None, optional (default=None)\n",
            "     |          Random number seed.\n",
            "     |          If int, this number is used to seed the C++ code.\n",
            "     |          If RandomState or Generator object (numpy), a random integer is picked based on its state to seed the C++ code.\n",
            "     |          If None, default seeds in C++ code are used.\n",
            "     |      n_jobs : int or None, optional (default=None)\n",
            "     |          Number of parallel threads to use for training (can be changed at prediction time by\n",
            "     |          passing it as an extra keyword argument).\n",
            "     |      \n",
            "     |          For better performance, it is recommended to set this to the number of physical cores\n",
            "     |          in the CPU.\n",
            "     |      \n",
            "     |          Negative integers are interpreted as following joblib's formula (n_cpus + 1 + n_jobs), just like\n",
            "     |          scikit-learn (so e.g. -1 means using all threads). A value of zero corresponds the default number of\n",
            "     |          threads configured for OpenMP in the system. A value of ``None`` (the default) corresponds\n",
            "     |          to using the number of physical cores in the system (its correct detection requires\n",
            "     |          either the ``joblib`` or the ``psutil`` util libraries to be installed).\n",
            "     |      \n",
            "     |          .. versionchanged:: 4.0.0\n",
            "     |      \n",
            "     |      importance_type : str, optional (default='split')\n",
            "     |          The type of feature importance to be filled into ``feature_importances_``.\n",
            "     |          If 'split', result contains numbers of times the feature is used in a model.\n",
            "     |          If 'gain', result contains total gains of splits which use the feature.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the model.\n",
            "     |          Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
            "     |      \n",
            "     |          .. warning::\n",
            "     |      \n",
            "     |              \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
            "     |      \n",
            "     |      Note\n",
            "     |      ----\n",
            "     |      A custom objective function can be provided for the ``objective`` parameter.\n",
            "     |      In this case, it should have the signature\n",
            "     |      ``objective(y_true, y_pred) -> grad, hess``,\n",
            "     |      ``objective(y_true, y_pred, weight) -> grad, hess``\n",
            "     |      or ``objective(y_true, y_pred, weight, group) -> grad, hess``:\n",
            "     |      \n",
            "     |          y_true : numpy 1-D array of shape = [n_samples]\n",
            "     |              The target values.\n",
            "     |          y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The predicted values.\n",
            "     |              Predicted values are returned before any transformation,\n",
            "     |              e.g. they are raw margin instead of probability of positive class for binary task.\n",
            "     |          weight : numpy 1-D array of shape = [n_samples]\n",
            "     |              The weight of samples. Weights should be non-negative.\n",
            "     |          group : numpy 1-D array\n",
            "     |              Group/query data.\n",
            "     |              Only used in the learning-to-rank task.\n",
            "     |              sum(group) = n_samples.\n",
            "     |              For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |              where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |          grad : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The value of the first order derivative (gradient) of the loss\n",
            "     |              with respect to the elements of y_pred for each sample point.\n",
            "     |          hess : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The value of the second order derivative (Hessian) of the loss\n",
            "     |              with respect to the elements of y_pred for each sample point.\n",
            "     |      \n",
            "     |      For multi-class task, y_pred is a numpy 2-D array of shape = [n_samples, n_classes],\n",
            "     |      and grad and hess should be returned in the same format.\n",
            "     |  \n",
            "     |  __sklearn_is_fitted__(self) -> bool\n",
            "     |  \n",
            "     |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
            "     |      Get parameters for this estimator.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      deep : bool, optional (default=True)\n",
            "     |          If True, will return the parameters for this estimator and\n",
            "     |          contained subobjects that are estimators.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      params : dict\n",
            "     |          Parameter names mapped to their values.\n",
            "     |  \n",
            "     |  predict(self, X: Union[lightgbm.compat.dt_DataTable, List[Union[List[float], List[int]]], numpy.ndarray, pandas.core.frame.DataFrame, scipy.sparse._matrix.spmatrix], raw_score: bool = False, start_iteration: int = 0, num_iteration: Optional[int] = None, pred_leaf: bool = False, pred_contrib: bool = False, validate_features: bool = False, **kwargs: Any)\n",
            "     |      Return the predicted value for each sample.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : numpy array, pandas DataFrame, H2O DataTable's Frame , scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]\n",
            "     |          Input features matrix.\n",
            "     |      raw_score : bool, optional (default=False)\n",
            "     |          Whether to predict raw scores.\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          Start index of the iteration to predict.\n",
            "     |          If <= 0, starts from the first iteration.\n",
            "     |      num_iteration : int or None, optional (default=None)\n",
            "     |          Total number of iterations used in the prediction.\n",
            "     |          If None, if the best iteration exists and start_iteration <= 0, the best iteration is used;\n",
            "     |          otherwise, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |          If <= 0, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |      pred_leaf : bool, optional (default=False)\n",
            "     |          Whether to predict leaf index.\n",
            "     |      pred_contrib : bool, optional (default=False)\n",
            "     |          Whether to predict feature contributions.\n",
            "     |      \n",
            "     |          .. note::\n",
            "     |      \n",
            "     |              If you want to get more explanations for your model's predictions using SHAP values,\n",
            "     |              like SHAP interaction values,\n",
            "     |              you can install the shap package (https://github.com/slundberg/shap).\n",
            "     |              Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n",
            "     |              column, where the last column is the expected value.\n",
            "     |      \n",
            "     |      validate_features : bool, optional (default=False)\n",
            "     |          If True, ensure that the features used to predict match the ones used to train.\n",
            "     |          Used only if data is pandas DataFrame.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the prediction.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      predicted_result : array-like of shape = [n_samples] or shape = [n_samples, n_classes]\n",
            "     |          The predicted values.\n",
            "     |      X_leaves : array-like of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]\n",
            "     |          If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n",
            "     |      X_SHAP_values : array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or list with n_classes length of such objects\n",
            "     |          If ``pred_contrib=True``, the feature contributions for each sample.\n",
            "     |  \n",
            "     |  set_params(self, **params: Any) -> 'LGBMModel'\n",
            "     |      Set the parameters of this estimator.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      **params\n",
            "     |          Parameter names with their new values.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          Returns self.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties inherited from LGBMModel:\n",
            "     |  \n",
            "     |  best_iteration_\n",
            "     |      :obj:`int`: The best iteration of fitted model if ``early_stopping()`` callback has been specified.\n",
            "     |  \n",
            "     |  best_score_\n",
            "     |      :obj:`dict`: The best score of fitted model.\n",
            "     |  \n",
            "     |  booster_\n",
            "     |      Booster: The underlying Booster of this model.\n",
            "     |  \n",
            "     |  evals_result_\n",
            "     |      :obj:`dict`: The evaluation results if validation sets have been specified.\n",
            "     |  \n",
            "     |  feature_importances_\n",
            "     |      :obj:`array` of shape = [n_features]: The feature importances (the higher, the more important).\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |      \n",
            "     |          ``importance_type`` attribute is passed to the function\n",
            "     |          to configure the type of importance values to be extracted.\n",
            "     |  \n",
            "     |  feature_name_\n",
            "     |      :obj:`list` of shape = [n_features]: The names of features.\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |      \n",
            "     |          If input does not contain feature names, they will be added during fitting in the format ``Column_0``, ``Column_1``, ..., ``Column_N``.\n",
            "     |  \n",
            "     |  feature_names_in_\n",
            "     |      :obj:`array` of shape = [n_features]: scikit-learn compatible version of ``.feature_name_``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.5.0\n",
            "     |  \n",
            "     |  n_estimators_\n",
            "     |      :obj:`int`: True number of boosting iterations performed.\n",
            "     |      \n",
            "     |      This might be less than parameter ``n_estimators`` if early stopping was enabled or\n",
            "     |      if boosting stopped early due to limits on complexity like ``min_gain_to_split``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |  \n",
            "     |  n_features_\n",
            "     |      :obj:`int`: The number of features of fitted model.\n",
            "     |  \n",
            "     |  n_features_in_\n",
            "     |      :obj:`int`: The number of features of fitted model.\n",
            "     |  \n",
            "     |  n_iter_\n",
            "     |      :obj:`int`: True number of boosting iterations performed.\n",
            "     |      \n",
            "     |      This might be less than parameter ``n_estimators`` if early stopping was enabled or\n",
            "     |      if boosting stopped early due to limits on complexity like ``min_gain_to_split``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |  \n",
            "     |  objective_\n",
            "     |      :obj:`str` or :obj:`callable`: The concrete objective used while fitting this model.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
            "     |  \n",
            "     |  __getstate__(self)\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self, N_CHAR_MAX=700)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  __sklearn_clone__(self)\n",
            "     |  \n",
            "     |  __sklearn_tags__(self)\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            "     |  \n",
            "     |  get_metadata_routing(self)\n",
            "     |      Get metadata routing of this object.\n",
            "     |      \n",
            "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      routing : MetadataRequest\n",
            "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
            "     |          routing information.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            "     |  \n",
            "     |  __init_subclass__(**kwargs)\n",
            "     |      Set the ``set_{method}_request`` methods.\n",
            "     |      \n",
            "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
            "     |      looks for the information available in the set default values which are\n",
            "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
            "     |      from method signatures.\n",
            "     |      \n",
            "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
            "     |      does not explicitly accept a metadata through its arguments or if the\n",
            "     |      developer would like to specify a request value for those metadata\n",
            "     |      which are different from the default ``None``.\n",
            "     |      \n",
            "     |      References\n",
            "     |      ----------\n",
            "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
            "    \n",
            "    class LGBMRegressor(sklearn.base.RegressorMixin, LGBMModel)\n",
            "     |  LGBMRegressor(boosting_type: str = 'gbdt', num_leaves: int = 31, max_depth: int = -1, learning_rate: float = 0.1, n_estimators: int = 100, subsample_for_bin: int = 200000, objective: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, class_weight: Union[Dict, str, NoneType] = None, min_split_gain: float = 0.0, min_child_weight: float = 0.001, min_child_samples: int = 20, subsample: float = 1.0, subsample_freq: int = 0, colsample_bytree: float = 1.0, reg_alpha: float = 0.0, reg_lambda: float = 0.0, random_state: Union[int, numpy.random.mtrand.RandomState, numpy.random._generator.Generator, NoneType] = None, n_jobs: Optional[int] = None, importance_type: str = 'split', **kwargs: Any)\n",
            "     |  \n",
            "     |  LightGBM regressor.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      LGBMRegressor\n",
            "     |      sklearn.base.RegressorMixin\n",
            "     |      LGBMModel\n",
            "     |      sklearn.base.BaseEstimator\n",
            "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
            "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  fit(self, X: Union[lightgbm.compat.dt_DataTable, List[Union[List[float], List[int]]], numpy.ndarray, pandas.core.frame.DataFrame, scipy.sparse._matrix.spmatrix], y: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray], sample_weight: Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, init_score: Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray, NoneType] = None, eval_set: Optional[List[Tuple[Union[lightgbm.compat.dt_DataTable, List[Union[List[float], List[int]]], numpy.ndarray, pandas.core.frame.DataFrame, scipy.sparse._matrix.spmatrix], Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]]] = None, eval_names: Optional[List[str]] = None, eval_sample_weight: Optional[List[Union[List[float], List[int], numpy.ndarray, pandas.core.series.Series, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]] = None, eval_init_score: Optional[List[Union[List[float], List[List[float]], numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, pyarrow.lib.Table, pyarrow.lib.Array, pyarrow.lib.ChunkedArray]]] = None, eval_metric: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], List[Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], List[Tuple[str, float, bool]]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[str, float, bool]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], List[Tuple[str, float, bool]]]]], NoneType] = None, feature_name: Union[List[str], ForwardRef(\"Literal['auto']\")] = 'auto', categorical_feature: Union[List[str], List[int], ForwardRef(\"Literal['auto']\")] = 'auto', callbacks: Optional[List[Callable]] = None, init_model: Union[str, pathlib.Path, lightgbm.basic.Booster, lightgbm.sklearn.LGBMModel, NoneType] = None) -> 'LGBMRegressor'\n",
            "     |      Build a gradient boosting model from the training set (X, y).\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : numpy array, pandas DataFrame, H2O DataTable's Frame , scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]\n",
            "     |          Input feature matrix.\n",
            "     |      y : numpy array, pandas DataFrame, pandas Series, list of int or float of shape = [n_samples]\n",
            "     |          The target values (class labels in classification, real numbers in regression).\n",
            "     |      sample_weight : numpy array, pandas Series, list of int or float of shape = [n_samples] or None, optional (default=None)\n",
            "     |          Weights of training data. Weights should be non-negative.\n",
            "     |      init_score : numpy array, pandas DataFrame, pandas Series, list of int or float of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task) or shape = [n_samples, n_classes] (for multi-class task) or None, optional (default=None)\n",
            "     |          Init score of training data.\n",
            "     |      eval_set : list or None, optional (default=None)\n",
            "     |          A list of (X, y) tuple pairs to use as validation sets.\n",
            "     |      eval_names : list of str, or None, optional (default=None)\n",
            "     |          Names of eval_set.\n",
            "     |      eval_sample_weight : list of array (same types as ``sample_weight`` supports), or None, optional (default=None)\n",
            "     |          Weights of eval data. Weights should be non-negative.\n",
            "     |      eval_init_score : list of array (same types as ``init_score`` supports), or None, optional (default=None)\n",
            "     |          Init score of eval data.\n",
            "     |      eval_metric : str, callable, list or None, optional (default=None)\n",
            "     |          If str, it should be a built-in evaluation metric to use.\n",
            "     |          If callable, it should be a custom evaluation metric, see note below for more details.\n",
            "     |          If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.\n",
            "     |          In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n",
            "     |          Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n",
            "     |      feature_name : list of str, or 'auto', optional (default='auto')\n",
            "     |          Feature names.\n",
            "     |          If 'auto' and data is pandas DataFrame, data columns names are used.\n",
            "     |      categorical_feature : list of str or int, or 'auto', optional (default='auto')\n",
            "     |          Categorical features.\n",
            "     |          If list of int, interpreted as indices.\n",
            "     |          If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
            "     |          If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
            "     |          All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
            "     |          Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
            "     |          All negative values in categorical features will be treated as missing values.\n",
            "     |          The output cannot be monotonically constrained with respect to a categorical feature.\n",
            "     |          Floating point numbers in categorical features will be rounded towards 0.\n",
            "     |      callbacks : list of callable, or None, optional (default=None)\n",
            "     |          List of callback functions that are applied at each iteration.\n",
            "     |          See Callbacks in Python API for more information.\n",
            "     |      init_model : str, pathlib.Path, Booster, LGBMModel or None, optional (default=None)\n",
            "     |          Filename of LightGBM model, Booster instance or LGBMModel instance used for continue training.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : LGBMRegressor\n",
            "     |          Returns self.\n",
            "     |      \n",
            "     |      \n",
            "     |      \n",
            "     |      Note\n",
            "     |      ----\n",
            "     |      Custom eval function expects a callable with following signatures:\n",
            "     |      ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
            "     |      ``func(y_true, y_pred, weight, group)``\n",
            "     |      and returns (eval_name, eval_result, is_higher_better) or\n",
            "     |      list of (eval_name, eval_result, is_higher_better):\n",
            "     |      \n",
            "     |          y_true : numpy 1-D array of shape = [n_samples]\n",
            "     |              The target values.\n",
            "     |          y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The predicted values.\n",
            "     |              In case of custom ``objective``, predicted values are returned before any transformation,\n",
            "     |              e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
            "     |          weight : numpy 1-D array of shape = [n_samples]\n",
            "     |              The weight of samples. Weights should be non-negative.\n",
            "     |          group : numpy 1-D array\n",
            "     |              Group/query data.\n",
            "     |              Only used in the learning-to-rank task.\n",
            "     |              sum(group) = n_samples.\n",
            "     |              For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |              where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |          eval_name : str\n",
            "     |              The name of evaluation function (without whitespace).\n",
            "     |          eval_result : float\n",
            "     |              The eval result.\n",
            "     |          is_higher_better : bool\n",
            "     |              Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
            "     |  \n",
            "     |  set_fit_request(self: lightgbm.sklearn.LGBMRegressor, *, callbacks: Union[bool, NoneType, str] = '$UNCHANGED$', categorical_feature: Union[bool, NoneType, str] = '$UNCHANGED$', eval_init_score: Union[bool, NoneType, str] = '$UNCHANGED$', eval_metric: Union[bool, NoneType, str] = '$UNCHANGED$', eval_names: Union[bool, NoneType, str] = '$UNCHANGED$', eval_sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$', eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', feature_name: Union[bool, NoneType, str] = '$UNCHANGED$', init_model: Union[bool, NoneType, str] = '$UNCHANGED$', init_score: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.sklearn.LGBMRegressor from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``fit`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      callbacks : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``callbacks`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      categorical_feature : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``categorical_feature`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_init_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_init_score`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_metric : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_metric`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_names : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_names`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_sample_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``eval_set`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      feature_name : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``feature_name`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      init_model : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``init_model`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      init_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``init_score`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  set_predict_request(self: lightgbm.sklearn.LGBMRegressor, *, num_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', pred_contrib: Union[bool, NoneType, str] = '$UNCHANGED$', pred_leaf: Union[bool, NoneType, str] = '$UNCHANGED$', raw_score: Union[bool, NoneType, str] = '$UNCHANGED$', start_iteration: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.sklearn.LGBMRegressor from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``predict`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      num_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``num_iteration`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      pred_contrib : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_contrib`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      pred_leaf : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``pred_leaf`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      raw_score : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``raw_score`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      start_iteration : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``start_iteration`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``validate_features`` parameter in ``predict``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  set_score_request(self: lightgbm.sklearn.LGBMRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> lightgbm.sklearn.LGBMRegressor from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            "     |      Request metadata passed to the ``score`` method.\n",
            "     |      \n",
            "     |      Note that this method is only relevant if\n",
            "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      The options for each parameter are:\n",
            "     |      \n",
            "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
            "     |      \n",
            "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
            "     |      \n",
            "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            "     |      \n",
            "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            "     |      \n",
            "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            "     |      existing request. This allows you to change the request for some\n",
            "     |      parameters and not others.\n",
            "     |      \n",
            "     |      .. versionadded:: 1.3\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          This method is only relevant if this estimator is used as a\n",
            "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          The updated object.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
            "     |  \n",
            "     |  __sklearn_tags__(self)\n",
            "     |  \n",
            "     |  score(self, X, y, sample_weight=None)\n",
            "     |      Return the coefficient of determination of the prediction.\n",
            "     |      \n",
            "     |      The coefficient of determination :math:`R^2` is defined as\n",
            "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
            "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
            "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
            "     |      The best possible score is 1.0 and it can be negative (because the\n",
            "     |      model can be arbitrarily worse). A constant model that always predicts\n",
            "     |      the expected value of `y`, disregarding the input features, would get\n",
            "     |      a :math:`R^2` score of 0.0.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : array-like of shape (n_samples, n_features)\n",
            "     |          Test samples. For some estimators this may be a precomputed\n",
            "     |          kernel matrix or a list of generic objects instead with shape\n",
            "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
            "     |          is the number of samples used in the fitting for the estimator.\n",
            "     |      \n",
            "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            "     |          True values for `X`.\n",
            "     |      \n",
            "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
            "     |          Sample weights.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      score : float\n",
            "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
            "     |      \n",
            "     |      Notes\n",
            "     |      -----\n",
            "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
            "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
            "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
            "     |      This influences the ``score`` method of all the multioutput\n",
            "     |      regressors (except for\n",
            "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from LGBMModel:\n",
            "     |  \n",
            "     |  __init__(self, boosting_type: str = 'gbdt', num_leaves: int = 31, max_depth: int = -1, learning_rate: float = 0.1, n_estimators: int = 100, subsample_for_bin: int = 200000, objective: Union[str, Callable[[Optional[numpy.ndarray], numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], Callable[[Optional[numpy.ndarray], numpy.ndarray, Optional[numpy.ndarray], Optional[numpy.ndarray]], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, class_weight: Union[Dict, str, NoneType] = None, min_split_gain: float = 0.0, min_child_weight: float = 0.001, min_child_samples: int = 20, subsample: float = 1.0, subsample_freq: int = 0, colsample_bytree: float = 1.0, reg_alpha: float = 0.0, reg_lambda: float = 0.0, random_state: Union[int, numpy.random.mtrand.RandomState, numpy.random._generator.Generator, NoneType] = None, n_jobs: Optional[int] = None, importance_type: str = 'split', **kwargs: Any)\n",
            "     |      Construct a gradient boosting model.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      boosting_type : str, optional (default='gbdt')\n",
            "     |          'gbdt', traditional Gradient Boosting Decision Tree.\n",
            "     |          'dart', Dropouts meet Multiple Additive Regression Trees.\n",
            "     |          'rf', Random Forest.\n",
            "     |      num_leaves : int, optional (default=31)\n",
            "     |          Maximum tree leaves for base learners.\n",
            "     |      max_depth : int, optional (default=-1)\n",
            "     |          Maximum tree depth for base learners, <=0 means no limit.\n",
            "     |          If setting this to a positive value, consider also changing ``num_leaves`` to ``<= 2^max_depth``.\n",
            "     |      learning_rate : float, optional (default=0.1)\n",
            "     |          Boosting learning rate.\n",
            "     |          You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n",
            "     |          in training using ``reset_parameter`` callback.\n",
            "     |          Note, that this will ignore the ``learning_rate`` argument in training.\n",
            "     |      n_estimators : int, optional (default=100)\n",
            "     |          Number of boosted trees to fit.\n",
            "     |      subsample_for_bin : int, optional (default=200000)\n",
            "     |          Number of samples for constructing bins.\n",
            "     |      objective : str, callable or None, optional (default=None)\n",
            "     |          Specify the learning task and the corresponding learning objective or\n",
            "     |          a custom objective function to be used (see note below).\n",
            "     |          Default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
            "     |      class_weight : dict, 'balanced' or None, optional (default=None)\n",
            "     |          Weights associated with classes in the form ``{class_label: weight}``.\n",
            "     |          Use this parameter only for multi-class classification task;\n",
            "     |          for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n",
            "     |          Note, that the usage of all these parameters will result in poor estimates of the individual class probabilities.\n",
            "     |          You may want to consider performing probability calibration\n",
            "     |          (https://scikit-learn.org/stable/modules/calibration.html) of your model.\n",
            "     |          The 'balanced' mode uses the values of y to automatically adjust weights\n",
            "     |          inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n",
            "     |          If None, all classes are supposed to have weight one.\n",
            "     |          Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)\n",
            "     |          if ``sample_weight`` is specified.\n",
            "     |      min_split_gain : float, optional (default=0.)\n",
            "     |          Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
            "     |      min_child_weight : float, optional (default=1e-3)\n",
            "     |          Minimum sum of instance weight (Hessian) needed in a child (leaf).\n",
            "     |      min_child_samples : int, optional (default=20)\n",
            "     |          Minimum number of data needed in a child (leaf).\n",
            "     |      subsample : float, optional (default=1.)\n",
            "     |          Subsample ratio of the training instance.\n",
            "     |      subsample_freq : int, optional (default=0)\n",
            "     |          Frequency of subsample, <=0 means no enable.\n",
            "     |      colsample_bytree : float, optional (default=1.)\n",
            "     |          Subsample ratio of columns when constructing each tree.\n",
            "     |      reg_alpha : float, optional (default=0.)\n",
            "     |          L1 regularization term on weights.\n",
            "     |      reg_lambda : float, optional (default=0.)\n",
            "     |          L2 regularization term on weights.\n",
            "     |      random_state : int, RandomState object or None, optional (default=None)\n",
            "     |          Random number seed.\n",
            "     |          If int, this number is used to seed the C++ code.\n",
            "     |          If RandomState or Generator object (numpy), a random integer is picked based on its state to seed the C++ code.\n",
            "     |          If None, default seeds in C++ code are used.\n",
            "     |      n_jobs : int or None, optional (default=None)\n",
            "     |          Number of parallel threads to use for training (can be changed at prediction time by\n",
            "     |          passing it as an extra keyword argument).\n",
            "     |      \n",
            "     |          For better performance, it is recommended to set this to the number of physical cores\n",
            "     |          in the CPU.\n",
            "     |      \n",
            "     |          Negative integers are interpreted as following joblib's formula (n_cpus + 1 + n_jobs), just like\n",
            "     |          scikit-learn (so e.g. -1 means using all threads). A value of zero corresponds the default number of\n",
            "     |          threads configured for OpenMP in the system. A value of ``None`` (the default) corresponds\n",
            "     |          to using the number of physical cores in the system (its correct detection requires\n",
            "     |          either the ``joblib`` or the ``psutil`` util libraries to be installed).\n",
            "     |      \n",
            "     |          .. versionchanged:: 4.0.0\n",
            "     |      \n",
            "     |      importance_type : str, optional (default='split')\n",
            "     |          The type of feature importance to be filled into ``feature_importances_``.\n",
            "     |          If 'split', result contains numbers of times the feature is used in a model.\n",
            "     |          If 'gain', result contains total gains of splits which use the feature.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the model.\n",
            "     |          Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
            "     |      \n",
            "     |          .. warning::\n",
            "     |      \n",
            "     |              \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
            "     |      \n",
            "     |      Note\n",
            "     |      ----\n",
            "     |      A custom objective function can be provided for the ``objective`` parameter.\n",
            "     |      In this case, it should have the signature\n",
            "     |      ``objective(y_true, y_pred) -> grad, hess``,\n",
            "     |      ``objective(y_true, y_pred, weight) -> grad, hess``\n",
            "     |      or ``objective(y_true, y_pred, weight, group) -> grad, hess``:\n",
            "     |      \n",
            "     |          y_true : numpy 1-D array of shape = [n_samples]\n",
            "     |              The target values.\n",
            "     |          y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The predicted values.\n",
            "     |              Predicted values are returned before any transformation,\n",
            "     |              e.g. they are raw margin instead of probability of positive class for binary task.\n",
            "     |          weight : numpy 1-D array of shape = [n_samples]\n",
            "     |              The weight of samples. Weights should be non-negative.\n",
            "     |          group : numpy 1-D array\n",
            "     |              Group/query data.\n",
            "     |              Only used in the learning-to-rank task.\n",
            "     |              sum(group) = n_samples.\n",
            "     |              For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
            "     |              where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
            "     |          grad : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The value of the first order derivative (gradient) of the loss\n",
            "     |              with respect to the elements of y_pred for each sample point.\n",
            "     |          hess : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)\n",
            "     |              The value of the second order derivative (Hessian) of the loss\n",
            "     |              with respect to the elements of y_pred for each sample point.\n",
            "     |      \n",
            "     |      For multi-class task, y_pred is a numpy 2-D array of shape = [n_samples, n_classes],\n",
            "     |      and grad and hess should be returned in the same format.\n",
            "     |  \n",
            "     |  __sklearn_is_fitted__(self) -> bool\n",
            "     |  \n",
            "     |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
            "     |      Get parameters for this estimator.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      deep : bool, optional (default=True)\n",
            "     |          If True, will return the parameters for this estimator and\n",
            "     |          contained subobjects that are estimators.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      params : dict\n",
            "     |          Parameter names mapped to their values.\n",
            "     |  \n",
            "     |  predict(self, X: Union[lightgbm.compat.dt_DataTable, List[Union[List[float], List[int]]], numpy.ndarray, pandas.core.frame.DataFrame, scipy.sparse._matrix.spmatrix], raw_score: bool = False, start_iteration: int = 0, num_iteration: Optional[int] = None, pred_leaf: bool = False, pred_contrib: bool = False, validate_features: bool = False, **kwargs: Any)\n",
            "     |      Return the predicted value for each sample.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      X : numpy array, pandas DataFrame, H2O DataTable's Frame , scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]\n",
            "     |          Input features matrix.\n",
            "     |      raw_score : bool, optional (default=False)\n",
            "     |          Whether to predict raw scores.\n",
            "     |      start_iteration : int, optional (default=0)\n",
            "     |          Start index of the iteration to predict.\n",
            "     |          If <= 0, starts from the first iteration.\n",
            "     |      num_iteration : int or None, optional (default=None)\n",
            "     |          Total number of iterations used in the prediction.\n",
            "     |          If None, if the best iteration exists and start_iteration <= 0, the best iteration is used;\n",
            "     |          otherwise, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |          If <= 0, all iterations from ``start_iteration`` are used (no limits).\n",
            "     |      pred_leaf : bool, optional (default=False)\n",
            "     |          Whether to predict leaf index.\n",
            "     |      pred_contrib : bool, optional (default=False)\n",
            "     |          Whether to predict feature contributions.\n",
            "     |      \n",
            "     |          .. note::\n",
            "     |      \n",
            "     |              If you want to get more explanations for your model's predictions using SHAP values,\n",
            "     |              like SHAP interaction values,\n",
            "     |              you can install the shap package (https://github.com/slundberg/shap).\n",
            "     |              Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n",
            "     |              column, where the last column is the expected value.\n",
            "     |      \n",
            "     |      validate_features : bool, optional (default=False)\n",
            "     |          If True, ensure that the features used to predict match the ones used to train.\n",
            "     |          Used only if data is pandas DataFrame.\n",
            "     |      **kwargs\n",
            "     |          Other parameters for the prediction.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      predicted_result : array-like of shape = [n_samples] or shape = [n_samples, n_classes]\n",
            "     |          The predicted values.\n",
            "     |      X_leaves : array-like of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]\n",
            "     |          If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n",
            "     |      X_SHAP_values : array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or list with n_classes length of such objects\n",
            "     |          If ``pred_contrib=True``, the feature contributions for each sample.\n",
            "     |  \n",
            "     |  set_params(self, **params: Any) -> 'LGBMModel'\n",
            "     |      Set the parameters of this estimator.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      **params\n",
            "     |          Parameter names with their new values.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      self : object\n",
            "     |          Returns self.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties inherited from LGBMModel:\n",
            "     |  \n",
            "     |  best_iteration_\n",
            "     |      :obj:`int`: The best iteration of fitted model if ``early_stopping()`` callback has been specified.\n",
            "     |  \n",
            "     |  best_score_\n",
            "     |      :obj:`dict`: The best score of fitted model.\n",
            "     |  \n",
            "     |  booster_\n",
            "     |      Booster: The underlying Booster of this model.\n",
            "     |  \n",
            "     |  evals_result_\n",
            "     |      :obj:`dict`: The evaluation results if validation sets have been specified.\n",
            "     |  \n",
            "     |  feature_importances_\n",
            "     |      :obj:`array` of shape = [n_features]: The feature importances (the higher, the more important).\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |      \n",
            "     |          ``importance_type`` attribute is passed to the function\n",
            "     |          to configure the type of importance values to be extracted.\n",
            "     |  \n",
            "     |  feature_name_\n",
            "     |      :obj:`list` of shape = [n_features]: The names of features.\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |      \n",
            "     |          If input does not contain feature names, they will be added during fitting in the format ``Column_0``, ``Column_1``, ..., ``Column_N``.\n",
            "     |  \n",
            "     |  feature_names_in_\n",
            "     |      :obj:`array` of shape = [n_features]: scikit-learn compatible version of ``.feature_name_``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.5.0\n",
            "     |  \n",
            "     |  n_estimators_\n",
            "     |      :obj:`int`: True number of boosting iterations performed.\n",
            "     |      \n",
            "     |      This might be less than parameter ``n_estimators`` if early stopping was enabled or\n",
            "     |      if boosting stopped early due to limits on complexity like ``min_gain_to_split``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |  \n",
            "     |  n_features_\n",
            "     |      :obj:`int`: The number of features of fitted model.\n",
            "     |  \n",
            "     |  n_features_in_\n",
            "     |      :obj:`int`: The number of features of fitted model.\n",
            "     |  \n",
            "     |  n_iter_\n",
            "     |      :obj:`int`: True number of boosting iterations performed.\n",
            "     |      \n",
            "     |      This might be less than parameter ``n_estimators`` if early stopping was enabled or\n",
            "     |      if boosting stopped early due to limits on complexity like ``min_gain_to_split``.\n",
            "     |      \n",
            "     |      .. versionadded:: 4.0.0\n",
            "     |  \n",
            "     |  objective_\n",
            "     |      :obj:`str` or :obj:`callable`: The concrete objective used while fitting this model.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
            "     |  \n",
            "     |  __getstate__(self)\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self, N_CHAR_MAX=700)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  __sklearn_clone__(self)\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            "     |  \n",
            "     |  get_metadata_routing(self)\n",
            "     |      Get metadata routing of this object.\n",
            "     |      \n",
            "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
            "     |      mechanism works.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      routing : MetadataRequest\n",
            "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
            "     |          routing information.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            "     |  \n",
            "     |  __init_subclass__(**kwargs)\n",
            "     |      Set the ``set_{method}_request`` methods.\n",
            "     |      \n",
            "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
            "     |      looks for the information available in the set default values which are\n",
            "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
            "     |      from method signatures.\n",
            "     |      \n",
            "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
            "     |      does not explicitly accept a metadata through its arguments or if the\n",
            "     |      developer would like to specify a request value for those metadata\n",
            "     |      which are different from the default ``None``.\n",
            "     |      \n",
            "     |      References\n",
            "     |      ----------\n",
            "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
            "    \n",
            "    class Sequence(abc.ABC)\n",
            "     |  Generic data access interface.\n",
            "     |  \n",
            "     |  Object should support the following operations:\n",
            "     |  \n",
            "     |  .. code-block::\n",
            "     |  \n",
            "     |      # Get total row number.\n",
            "     |      >>> len(seq)\n",
            "     |      # Random access by row index. Used for data sampling.\n",
            "     |      >>> seq[10]\n",
            "     |      # Range data access. Used to read data in batch when constructing Dataset.\n",
            "     |      >>> seq[0:100]\n",
            "     |      # Optionally specify batch_size to control range data read size.\n",
            "     |      >>> seq.batch_size\n",
            "     |  \n",
            "     |  - With random access, **data sampling does not need to go through all data**.\n",
            "     |  - With range data access, there's **no need to read all data into memory thus reduce memory usage**.\n",
            "     |  \n",
            "     |  .. versionadded:: 3.3.0\n",
            "     |  \n",
            "     |  Attributes\n",
            "     |  ----------\n",
            "     |  batch_size : int\n",
            "     |      Default size of a batch.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      Sequence\n",
            "     |      abc.ABC\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __getitem__(self, idx: Union[int, slice, List[int]]) -> numpy.ndarray\n",
            "     |      Return data for given row index.\n",
            "     |      \n",
            "     |      A basic implementation should look like this:\n",
            "     |      \n",
            "     |      .. code-block:: python\n",
            "     |      \n",
            "     |          if isinstance(idx, numbers.Integral):\n",
            "     |              return self._get_one_line(idx)\n",
            "     |          elif isinstance(idx, slice):\n",
            "     |              return np.stack([self._get_one_line(i) for i in range(idx.start, idx.stop)])\n",
            "     |          elif isinstance(idx, list):\n",
            "     |              # Only required if using ``Dataset.subset()``.\n",
            "     |              return np.array([self._get_one_line(i) for i in idx])\n",
            "     |          else:\n",
            "     |              raise TypeError(f\"Sequence index must be integer, slice or list, got {type(idx).__name__}\")\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      idx : int, slice[int], list[int]\n",
            "     |          Item index.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      result : numpy 1-D array or numpy 2-D array\n",
            "     |          1-D array if idx is int, 2-D array if idx is slice or list.\n",
            "     |  \n",
            "     |  __len__(self) -> int\n",
            "     |      Return row count of this sequence.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __abstractmethods__ = frozenset({'__getitem__', '__len__'})\n",
            "     |  \n",
            "     |  batch_size = 4096\n",
            "\n",
            "FUNCTIONS\n",
            "    create_tree_digraph(booster: Union[lightgbm.basic.Booster, lightgbm.sklearn.LGBMModel], tree_index: int = 0, show_info: Optional[List[str]] = None, precision: Optional[int] = 3, orientation: str = 'horizontal', example_case: Union[numpy.ndarray, pandas.core.frame.DataFrame, NoneType] = None, max_category_values: int = 10, **kwargs: Any) -> Any\n",
            "        Create a digraph representation of specified tree.\n",
            "        \n",
            "        Each node in the graph represents a node in the tree.\n",
            "        \n",
            "        Non-leaf nodes have labels like ``Column_10 <= 875.9``, which means\n",
            "        \"this node splits on the feature named \"Column_10\", with threshold 875.9\".\n",
            "        \n",
            "        Leaf nodes have labels like ``leaf 2: 0.422``, which means \"this node is a\n",
            "        leaf node, and the predicted value for records that fall into this node\n",
            "        is 0.422\". The number (``2``) is an internal unique identifier and doesn't\n",
            "        have any special meaning.\n",
            "        \n",
            "        .. note::\n",
            "        \n",
            "            For more information please visit\n",
            "            https://graphviz.readthedocs.io/en/stable/api.html#digraph.\n",
            "        \n",
            "        Parameters\n",
            "        ----------\n",
            "        booster : Booster or LGBMModel\n",
            "            Booster or LGBMModel instance to be converted.\n",
            "        tree_index : int, optional (default=0)\n",
            "            The index of a target tree to convert.\n",
            "        show_info : list of str, or None, optional (default=None)\n",
            "            What information should be shown in nodes.\n",
            "        \n",
            "                - ``'split_gain'`` : gain from adding this split to the model\n",
            "                - ``'internal_value'`` : raw predicted value that would be produced by this node if it was a leaf node\n",
            "                - ``'internal_count'`` : number of records from the training data that fall into this non-leaf node\n",
            "                - ``'internal_weight'`` : total weight of all nodes that fall into this non-leaf node\n",
            "                - ``'leaf_count'`` : number of records from the training data that fall into this leaf node\n",
            "                - ``'leaf_weight'`` : total weight (sum of Hessian) of all observations that fall into this leaf node\n",
            "                - ``'data_percentage'`` : percentage of training data that fall into this node\n",
            "        precision : int or None, optional (default=3)\n",
            "            Used to restrict the display of floating point values to a certain precision.\n",
            "        orientation : str, optional (default='horizontal')\n",
            "            Orientation of the tree.\n",
            "            Can be 'horizontal' or 'vertical'.\n",
            "        example_case : numpy 2-D array, pandas DataFrame or None, optional (default=None)\n",
            "            Single row with the same structure as the training data.\n",
            "            If not None, the plot will highlight the path that sample takes through the tree.\n",
            "        \n",
            "            .. versionadded:: 4.0.0\n",
            "        \n",
            "        max_category_values : int, optional (default=10)\n",
            "            The maximum number of category values to display in tree nodes, if the number of thresholds is greater than this value, thresholds will be collapsed and displayed on the label tooltip instead.\n",
            "        \n",
            "            .. warning::\n",
            "        \n",
            "                Consider wrapping the SVG string of the tree graph with ``IPython.display.HTML`` when running on JupyterLab to get the `tooltip <https://graphviz.org/docs/attrs/tooltip>`_ working right.\n",
            "        \n",
            "                Example:\n",
            "        \n",
            "                .. code-block:: python\n",
            "        \n",
            "                    from IPython.display import HTML\n",
            "        \n",
            "                    graph = lgb.create_tree_digraph(clf, max_category_values=5)\n",
            "                    HTML(graph._repr_image_svg_xml())\n",
            "        \n",
            "            .. versionadded:: 4.0.0\n",
            "        \n",
            "        **kwargs\n",
            "            Other parameters passed to ``Digraph`` constructor.\n",
            "            Check https://graphviz.readthedocs.io/en/stable/api.html#digraph for the full list of supported parameters.\n",
            "        \n",
            "        Returns\n",
            "        -------\n",
            "        graph : graphviz.Digraph\n",
            "            The digraph representation of specified tree.\n",
            "    \n",
            "    cv(params: Dict[str, Any], train_set: lightgbm.basic.Dataset, num_boost_round: int = 100, folds: Union[Iterable[Tuple[numpy.ndarray, numpy.ndarray]], sklearn.model_selection._split.BaseCrossValidator, NoneType] = None, nfold: int = 5, stratified: bool = True, shuffle: bool = True, metrics: Union[str, List[str], NoneType] = None, feval: Union[Callable[[numpy.ndarray, lightgbm.basic.Dataset], Tuple[str, float, bool]], Callable[[numpy.ndarray, lightgbm.basic.Dataset], List[Tuple[str, float, bool]]], List[Union[Callable[[numpy.ndarray, lightgbm.basic.Dataset], Tuple[str, float, bool]], Callable[[numpy.ndarray, lightgbm.basic.Dataset], List[Tuple[str, float, bool]]]]], NoneType] = None, init_model: Union[str, pathlib.Path, lightgbm.basic.Booster, NoneType] = None, feature_name: Union[List[str], ForwardRef(\"Literal['auto']\")] = 'auto', categorical_feature: Union[List[str], List[int], ForwardRef(\"Literal['auto']\")] = 'auto', fpreproc: Optional[Callable[[lightgbm.basic.Dataset, lightgbm.basic.Dataset, Dict[str, Any]], Tuple[lightgbm.basic.Dataset, lightgbm.basic.Dataset, Dict[str, Any]]]] = None, seed: int = 0, callbacks: Optional[List[Callable]] = None, eval_train_metric: bool = False, return_cvbooster: bool = False) -> Dict[str, Union[List[float], lightgbm.engine.CVBooster]]\n",
            "        Perform the cross-validation with given parameters.\n",
            "        \n",
            "        Parameters\n",
            "        ----------\n",
            "        params : dict\n",
            "            Parameters for training. Values passed through ``params`` take precedence over those\n",
            "            supplied via arguments.\n",
            "        train_set : Dataset\n",
            "            Data to be trained on.\n",
            "        num_boost_round : int, optional (default=100)\n",
            "            Number of boosting iterations.\n",
            "        folds : generator or iterator of (train_idx, test_idx) tuples, scikit-learn splitter object or None, optional (default=None)\n",
            "            If generator or iterator, it should yield the train and test indices for each fold.\n",
            "            If object, it should be one of the scikit-learn splitter classes\n",
            "            (https://scikit-learn.org/stable/modules/classes.html#splitter-classes)\n",
            "            and have ``split`` method.\n",
            "            This argument has highest priority over other data split arguments.\n",
            "        nfold : int, optional (default=5)\n",
            "            Number of folds in CV.\n",
            "        stratified : bool, optional (default=True)\n",
            "            Whether to perform stratified sampling.\n",
            "        shuffle : bool, optional (default=True)\n",
            "            Whether to shuffle before splitting data.\n",
            "        metrics : str, list of str, or None, optional (default=None)\n",
            "            Evaluation metrics to be monitored while CV.\n",
            "            If not None, the metric in ``params`` will be overridden.\n",
            "        feval : callable, list of callable, or None, optional (default=None)\n",
            "            Customized evaluation function.\n",
            "            Each evaluation function should accept two parameters: preds, eval_data,\n",
            "            and return (eval_name, eval_result, is_higher_better) or list of such tuples.\n",
            "        \n",
            "                preds : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
            "                    The predicted values.\n",
            "                    For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes].\n",
            "                    If custom objective function is used, predicted values are returned before any transformation,\n",
            "                    e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
            "                eval_data : Dataset\n",
            "                    A ``Dataset`` to evaluate.\n",
            "                eval_name : str\n",
            "                    The name of evaluation function (without whitespace).\n",
            "                eval_result : float\n",
            "                    The eval result.\n",
            "                is_higher_better : bool\n",
            "                    Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
            "        \n",
            "            To ignore the default metric corresponding to the used objective,\n",
            "            set ``metrics`` to the string ``\"None\"``.\n",
            "        init_model : str, pathlib.Path, Booster or None, optional (default=None)\n",
            "            Filename of LightGBM model or Booster instance used for continue training.\n",
            "        feature_name : list of str, or 'auto', optional (default=\"auto\")\n",
            "            **Deprecated.** Set ``feature_name`` on ``train_set`` instead.\n",
            "            Feature names.\n",
            "            If 'auto' and data is pandas DataFrame, data columns names are used.\n",
            "        categorical_feature : list of str or int, or 'auto', optional (default=\"auto\")\n",
            "            **Deprecated.** Set ``categorical_feature`` on ``train_set`` instead.\n",
            "            Categorical features.\n",
            "            If list of int, interpreted as indices.\n",
            "            If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
            "            If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
            "            All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
            "            Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
            "            All negative values in categorical features will be treated as missing values.\n",
            "            The output cannot be monotonically constrained with respect to a categorical feature.\n",
            "            Floating point numbers in categorical features will be rounded towards 0.\n",
            "        fpreproc : callable or None, optional (default=None)\n",
            "            Preprocessing function that takes (dtrain, dtest, params)\n",
            "            and returns transformed versions of those.\n",
            "        seed : int, optional (default=0)\n",
            "            Seed used to generate the folds (passed to numpy.random.seed).\n",
            "        callbacks : list of callable, or None, optional (default=None)\n",
            "            List of callback functions that are applied at each iteration.\n",
            "            See Callbacks in Python API for more information.\n",
            "        eval_train_metric : bool, optional (default=False)\n",
            "            Whether to display the train metric in progress.\n",
            "            The score of the metric is calculated again after each training step, so there is some impact on performance.\n",
            "        return_cvbooster : bool, optional (default=False)\n",
            "            Whether to return Booster models trained on each fold through ``CVBooster``.\n",
            "        \n",
            "        Note\n",
            "        ----\n",
            "        A custom objective function can be provided for the ``objective`` parameter.\n",
            "        It should accept two parameters: preds, train_data and return (grad, hess).\n",
            "        \n",
            "            preds : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
            "                The predicted values.\n",
            "                Predicted values are returned before any transformation,\n",
            "                e.g. they are raw margin instead of probability of positive class for binary task.\n",
            "            train_data : Dataset\n",
            "                The training dataset.\n",
            "            grad : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
            "                The value of the first order derivative (gradient) of the loss\n",
            "                with respect to the elements of preds for each sample point.\n",
            "            hess : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
            "                The value of the second order derivative (Hessian) of the loss\n",
            "                with respect to the elements of preds for each sample point.\n",
            "        \n",
            "        For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes],\n",
            "        and grad and hess should be returned in the same format.\n",
            "        \n",
            "        Returns\n",
            "        -------\n",
            "        eval_results : dict\n",
            "            History of evaluation results of each metric.\n",
            "            The dictionary has the following format:\n",
            "            {'valid metric1-mean': [values], 'valid metric1-stdv': [values],\n",
            "            'valid metric2-mean': [values], 'valid metric2-stdv': [values],\n",
            "            ...}.\n",
            "            If ``return_cvbooster=True``, also returns trained boosters wrapped in a ``CVBooster`` object via ``cvbooster`` key.\n",
            "            If ``eval_train_metric=True``, also returns the train metric history.\n",
            "            In this case, the dictionary has the following format:\n",
            "            {'train metric1-mean': [values], 'valid metric1-mean': [values],\n",
            "            'train metric2-mean': [values], 'valid metric2-mean': [values],\n",
            "            ...}.\n",
            "    \n",
            "    early_stopping(stopping_rounds: int, first_metric_only: bool = False, verbose: bool = True, min_delta: Union[float, List[float]] = 0.0) -> lightgbm.callback._EarlyStoppingCallback\n",
            "        Create a callback that activates early stopping.\n",
            "        \n",
            "        Activates early stopping.\n",
            "        The model will train until the validation score doesn't improve by at least ``min_delta``.\n",
            "        Validation score needs to improve at least every ``stopping_rounds`` round(s)\n",
            "        to continue training.\n",
            "        Requires at least one validation data and one metric.\n",
            "        If there's more than one, will check all of them. But the training data is ignored anyway.\n",
            "        To check only the first metric set ``first_metric_only`` to True.\n",
            "        The index of iteration that has the best performance will be saved in the ``best_iteration`` attribute of a model.\n",
            "        \n",
            "        Parameters\n",
            "        ----------\n",
            "        stopping_rounds : int\n",
            "            The possible number of rounds without the trend occurrence.\n",
            "        first_metric_only : bool, optional (default=False)\n",
            "            Whether to use only the first metric for early stopping.\n",
            "        verbose : bool, optional (default=True)\n",
            "            Whether to log message with early stopping information.\n",
            "            By default, standard output resource is used.\n",
            "            Use ``register_logger()`` function to register a custom logger.\n",
            "        min_delta : float or list of float, optional (default=0.0)\n",
            "            Minimum improvement in score to keep training.\n",
            "            If float, this single value is used for all metrics.\n",
            "            If list, its length should match the total number of metrics.\n",
            "        \n",
            "            .. versionadded:: 4.0.0\n",
            "        \n",
            "        Returns\n",
            "        -------\n",
            "        callback : _EarlyStoppingCallback\n",
            "            The callback that activates early stopping.\n",
            "    \n",
            "    log_evaluation(period: int = 1, show_stdv: bool = True) -> lightgbm.callback._LogEvaluationCallback\n",
            "        Create a callback that logs the evaluation results.\n",
            "        \n",
            "        By default, standard output resource is used.\n",
            "        Use ``register_logger()`` function to register a custom logger.\n",
            "        \n",
            "        Note\n",
            "        ----\n",
            "        Requires at least one validation data.\n",
            "        \n",
            "        Parameters\n",
            "        ----------\n",
            "        period : int, optional (default=1)\n",
            "            The period to log the evaluation results.\n",
            "            The last boosting stage or the boosting stage found by using ``early_stopping`` callback is also logged.\n",
            "        show_stdv : bool, optional (default=True)\n",
            "            Whether to log stdv (if provided).\n",
            "        \n",
            "        Returns\n",
            "        -------\n",
            "        callback : _LogEvaluationCallback\n",
            "            The callback that logs the evaluation results every ``period`` boosting iteration(s).\n",
            "    \n",
            "    plot_importance(booster: Union[lightgbm.basic.Booster, lightgbm.sklearn.LGBMModel], ax: 'Optional[matplotlib.axes.Axes]' = None, height: float = 0.2, xlim: Optional[Tuple[float, float]] = None, ylim: Optional[Tuple[float, float]] = None, title: Optional[str] = 'Feature importance', xlabel: Optional[str] = 'Feature importance', ylabel: Optional[str] = 'Features', importance_type: str = 'auto', max_num_features: Optional[int] = None, ignore_zero: bool = True, figsize: Optional[Tuple[float, float]] = None, dpi: Optional[int] = None, grid: bool = True, precision: Optional[int] = 3, **kwargs: Any) -> Any\n",
            "        Plot model's feature importances.\n",
            "        \n",
            "        Parameters\n",
            "        ----------\n",
            "        booster : Booster or LGBMModel\n",
            "            Booster or LGBMModel instance which feature importance should be plotted.\n",
            "        ax : matplotlib.axes.Axes or None, optional (default=None)\n",
            "            Target axes instance.\n",
            "            If None, new figure and axes will be created.\n",
            "        height : float, optional (default=0.2)\n",
            "            Bar height, passed to ``ax.barh()``.\n",
            "        xlim : tuple of 2 elements or None, optional (default=None)\n",
            "            Tuple passed to ``ax.xlim()``.\n",
            "        ylim : tuple of 2 elements or None, optional (default=None)\n",
            "            Tuple passed to ``ax.ylim()``.\n",
            "        title : str or None, optional (default=\"Feature importance\")\n",
            "            Axes title.\n",
            "            If None, title is disabled.\n",
            "        xlabel : str or None, optional (default=\"Feature importance\")\n",
            "            X-axis title label.\n",
            "            If None, title is disabled.\n",
            "            @importance_type@ placeholder can be used, and it will be replaced with the value of ``importance_type`` parameter.\n",
            "        ylabel : str or None, optional (default=\"Features\")\n",
            "            Y-axis title label.\n",
            "            If None, title is disabled.\n",
            "        importance_type : str, optional (default=\"auto\")\n",
            "            How the importance is calculated.\n",
            "            If \"auto\", if ``booster`` parameter is LGBMModel, ``booster.importance_type`` attribute is used; \"split\" otherwise.\n",
            "            If \"split\", result contains numbers of times the feature is used in a model.\n",
            "            If \"gain\", result contains total gains of splits which use the feature.\n",
            "        max_num_features : int or None, optional (default=None)\n",
            "            Max number of top features displayed on plot.\n",
            "            If None or <1, all features will be displayed.\n",
            "        ignore_zero : bool, optional (default=True)\n",
            "            Whether to ignore features with zero importance.\n",
            "        figsize : tuple of 2 elements or None, optional (default=None)\n",
            "            Figure size.\n",
            "        dpi : int or None, optional (default=None)\n",
            "            Resolution of the figure.\n",
            "        grid : bool, optional (default=True)\n",
            "            Whether to add a grid for axes.\n",
            "        precision : int or None, optional (default=3)\n",
            "            Used to restrict the display of floating point values to a certain precision.\n",
            "        **kwargs\n",
            "            Other parameters passed to ``ax.barh()``.\n",
            "        \n",
            "        Returns\n",
            "        -------\n",
            "        ax : matplotlib.axes.Axes\n",
            "            The plot with model's feature importances.\n",
            "    \n",
            "    plot_metric(booster: Union[Dict, lightgbm.sklearn.LGBMModel], metric: Optional[str] = None, dataset_names: Optional[List[str]] = None, ax: 'Optional[matplotlib.axes.Axes]' = None, xlim: Optional[Tuple[float, float]] = None, ylim: Optional[Tuple[float, float]] = None, title: Optional[str] = 'Metric during training', xlabel: Optional[str] = 'Iterations', ylabel: Optional[str] = '@metric@', figsize: Optional[Tuple[float, float]] = None, dpi: Optional[int] = None, grid: bool = True) -> Any\n",
            "        Plot one metric during training.\n",
            "        \n",
            "        Parameters\n",
            "        ----------\n",
            "        booster : dict or LGBMModel\n",
            "            Dictionary returned from ``lightgbm.train()`` or LGBMModel instance.\n",
            "        metric : str or None, optional (default=None)\n",
            "            The metric name to plot.\n",
            "            Only one metric supported because different metrics have various scales.\n",
            "            If None, first metric picked from dictionary (according to hashcode).\n",
            "        dataset_names : list of str, or None, optional (default=None)\n",
            "            List of the dataset names which are used to calculate metric to plot.\n",
            "            If None, all datasets are used.\n",
            "        ax : matplotlib.axes.Axes or None, optional (default=None)\n",
            "            Target axes instance.\n",
            "            If None, new figure and axes will be created.\n",
            "        xlim : tuple of 2 elements or None, optional (default=None)\n",
            "            Tuple passed to ``ax.xlim()``.\n",
            "        ylim : tuple of 2 elements or None, optional (default=None)\n",
            "            Tuple passed to ``ax.ylim()``.\n",
            "        title : str or None, optional (default=\"Metric during training\")\n",
            "            Axes title.\n",
            "            If None, title is disabled.\n",
            "        xlabel : str or None, optional (default=\"Iterations\")\n",
            "            X-axis title label.\n",
            "            If None, title is disabled.\n",
            "        ylabel : str or None, optional (default=\"@metric@\")\n",
            "            Y-axis title label.\n",
            "            If 'auto', metric name is used.\n",
            "            If None, title is disabled.\n",
            "            @metric@ placeholder can be used, and it will be replaced with metric name.\n",
            "        figsize : tuple of 2 elements or None, optional (default=None)\n",
            "            Figure size.\n",
            "        dpi : int or None, optional (default=None)\n",
            "            Resolution of the figure.\n",
            "        grid : bool, optional (default=True)\n",
            "            Whether to add a grid for axes.\n",
            "        \n",
            "        Returns\n",
            "        -------\n",
            "        ax : matplotlib.axes.Axes\n",
            "            The plot with metric's history over the training.\n",
            "    \n",
            "    plot_split_value_histogram(booster: Union[lightgbm.basic.Booster, lightgbm.sklearn.LGBMModel], feature: Union[int, str], bins: Union[int, str, NoneType] = None, ax: 'Optional[matplotlib.axes.Axes]' = None, width_coef: float = 0.8, xlim: Optional[Tuple[float, float]] = None, ylim: Optional[Tuple[float, float]] = None, title: Optional[str] = 'Split value histogram for feature with @index/name@ @feature@', xlabel: Optional[str] = 'Feature split value', ylabel: Optional[str] = 'Count', figsize: Optional[Tuple[float, float]] = None, dpi: Optional[int] = None, grid: bool = True, **kwargs: Any) -> Any\n",
            "        Plot split value histogram for the specified feature of the model.\n",
            "        \n",
            "        Parameters\n",
            "        ----------\n",
            "        booster : Booster or LGBMModel\n",
            "            Booster or LGBMModel instance of which feature split value histogram should be plotted.\n",
            "        feature : int or str\n",
            "            The feature name or index the histogram is plotted for.\n",
            "            If int, interpreted as index.\n",
            "            If str, interpreted as name.\n",
            "        bins : int, str or None, optional (default=None)\n",
            "            The maximum number of bins.\n",
            "            If None, the number of bins equals number of unique split values.\n",
            "            If str, it should be one from the list of the supported values by ``numpy.histogram()`` function.\n",
            "        ax : matplotlib.axes.Axes or None, optional (default=None)\n",
            "            Target axes instance.\n",
            "            If None, new figure and axes will be created.\n",
            "        width_coef : float, optional (default=0.8)\n",
            "            Coefficient for histogram bar width.\n",
            "        xlim : tuple of 2 elements or None, optional (default=None)\n",
            "            Tuple passed to ``ax.xlim()``.\n",
            "        ylim : tuple of 2 elements or None, optional (default=None)\n",
            "            Tuple passed to ``ax.ylim()``.\n",
            "        title : str or None, optional (default=\"Split value histogram for feature with @index/name@ @feature@\")\n",
            "            Axes title.\n",
            "            If None, title is disabled.\n",
            "            @feature@ placeholder can be used, and it will be replaced with the value of ``feature`` parameter.\n",
            "            @index/name@ placeholder can be used,\n",
            "            and it will be replaced with ``index`` word in case of ``int`` type ``feature`` parameter\n",
            "            or ``name`` word in case of ``str`` type ``feature`` parameter.\n",
            "        xlabel : str or None, optional (default=\"Feature split value\")\n",
            "            X-axis title label.\n",
            "            If None, title is disabled.\n",
            "        ylabel : str or None, optional (default=\"Count\")\n",
            "            Y-axis title label.\n",
            "            If None, title is disabled.\n",
            "        figsize : tuple of 2 elements or None, optional (default=None)\n",
            "            Figure size.\n",
            "        dpi : int or None, optional (default=None)\n",
            "            Resolution of the figure.\n",
            "        grid : bool, optional (default=True)\n",
            "            Whether to add a grid for axes.\n",
            "        **kwargs\n",
            "            Other parameters passed to ``ax.bar()``.\n",
            "        \n",
            "        Returns\n",
            "        -------\n",
            "        ax : matplotlib.axes.Axes\n",
            "            The plot with specified model's feature split value histogram.\n",
            "    \n",
            "    plot_tree(booster: Union[lightgbm.basic.Booster, lightgbm.sklearn.LGBMModel], ax: 'Optional[matplotlib.axes.Axes]' = None, tree_index: int = 0, figsize: Optional[Tuple[float, float]] = None, dpi: Optional[int] = None, show_info: Optional[List[str]] = None, precision: Optional[int] = 3, orientation: str = 'horizontal', example_case: Union[numpy.ndarray, pandas.core.frame.DataFrame, NoneType] = None, **kwargs: Any) -> Any\n",
            "        Plot specified tree.\n",
            "        \n",
            "        Each node in the graph represents a node in the tree.\n",
            "        \n",
            "        Non-leaf nodes have labels like ``Column_10 <= 875.9``, which means\n",
            "        \"this node splits on the feature named \"Column_10\", with threshold 875.9\".\n",
            "        \n",
            "        Leaf nodes have labels like ``leaf 2: 0.422``, which means \"this node is a\n",
            "        leaf node, and the predicted value for records that fall into this node\n",
            "        is 0.422\". The number (``2``) is an internal unique identifier and doesn't\n",
            "        have any special meaning.\n",
            "        \n",
            "        .. note::\n",
            "        \n",
            "            It is preferable to use ``create_tree_digraph()`` because of its lossless quality\n",
            "            and returned objects can be also rendered and displayed directly inside a Jupyter notebook.\n",
            "        \n",
            "        Parameters\n",
            "        ----------\n",
            "        booster : Booster or LGBMModel\n",
            "            Booster or LGBMModel instance to be plotted.\n",
            "        ax : matplotlib.axes.Axes or None, optional (default=None)\n",
            "            Target axes instance.\n",
            "            If None, new figure and axes will be created.\n",
            "        tree_index : int, optional (default=0)\n",
            "            The index of a target tree to plot.\n",
            "        figsize : tuple of 2 elements or None, optional (default=None)\n",
            "            Figure size.\n",
            "        dpi : int or None, optional (default=None)\n",
            "            Resolution of the figure.\n",
            "        show_info : list of str, or None, optional (default=None)\n",
            "            What information should be shown in nodes.\n",
            "        \n",
            "                - ``'split_gain'`` : gain from adding this split to the model\n",
            "                - ``'internal_value'`` : raw predicted value that would be produced by this node if it was a leaf node\n",
            "                - ``'internal_count'`` : number of records from the training data that fall into this non-leaf node\n",
            "                - ``'internal_weight'`` : total weight of all nodes that fall into this non-leaf node\n",
            "                - ``'leaf_count'`` : number of records from the training data that fall into this leaf node\n",
            "                - ``'leaf_weight'`` : total weight (sum of Hessian) of all observations that fall into this leaf node\n",
            "                - ``'data_percentage'`` : percentage of training data that fall into this node\n",
            "        precision : int or None, optional (default=3)\n",
            "            Used to restrict the display of floating point values to a certain precision.\n",
            "        orientation : str, optional (default='horizontal')\n",
            "            Orientation of the tree.\n",
            "            Can be 'horizontal' or 'vertical'.\n",
            "        example_case : numpy 2-D array, pandas DataFrame or None, optional (default=None)\n",
            "            Single row with the same structure as the training data.\n",
            "            If not None, the plot will highlight the path that sample takes through the tree.\n",
            "        \n",
            "            .. versionadded:: 4.0.0\n",
            "        \n",
            "        **kwargs\n",
            "            Other parameters passed to ``Digraph`` constructor.\n",
            "            Check https://graphviz.readthedocs.io/en/stable/api.html#digraph for the full list of supported parameters.\n",
            "        \n",
            "        Returns\n",
            "        -------\n",
            "        ax : matplotlib.axes.Axes\n",
            "            The plot with single tree.\n",
            "    \n",
            "    record_evaluation(eval_result: Dict[str, Dict[str, List[Any]]]) -> Callable\n",
            "        Create a callback that records the evaluation history into ``eval_result``.\n",
            "        \n",
            "        Parameters\n",
            "        ----------\n",
            "        eval_result : dict\n",
            "            Dictionary used to store all evaluation results of all validation sets.\n",
            "            This should be initialized outside of your call to ``record_evaluation()`` and should be empty.\n",
            "            Any initial contents of the dictionary will be deleted.\n",
            "        \n",
            "            .. rubric:: Example\n",
            "        \n",
            "            With two validation sets named 'eval' and 'train', and one evaluation metric named 'logloss'\n",
            "            this dictionary after finishing a model training process will have the following structure:\n",
            "        \n",
            "            .. code-block::\n",
            "        \n",
            "                {\n",
            "                 'train':\n",
            "                     {\n",
            "                      'logloss': [0.48253, 0.35953, ...]\n",
            "                     },\n",
            "                 'eval':\n",
            "                     {\n",
            "                      'logloss': [0.480385, 0.357756, ...]\n",
            "                     }\n",
            "                }\n",
            "        \n",
            "        Returns\n",
            "        -------\n",
            "        callback : _RecordEvaluationCallback\n",
            "            The callback that records the evaluation history into the passed dictionary.\n",
            "    \n",
            "    register_logger(logger: Any, info_method_name: str = 'info', warning_method_name: str = 'warning') -> None\n",
            "        Register custom logger.\n",
            "        \n",
            "        Parameters\n",
            "        ----------\n",
            "        logger : Any\n",
            "            Custom logger.\n",
            "        info_method_name : str, optional (default=\"info\")\n",
            "            Method used to log info messages.\n",
            "        warning_method_name : str, optional (default=\"warning\")\n",
            "            Method used to log warning messages.\n",
            "    \n",
            "    reset_parameter(**kwargs: Union[list, Callable]) -> Callable\n",
            "        Create a callback that resets the parameter after the first iteration.\n",
            "        \n",
            "        .. note::\n",
            "        \n",
            "            The initial parameter will still take in-effect on first iteration.\n",
            "        \n",
            "        Parameters\n",
            "        ----------\n",
            "        **kwargs : value should be list or callable\n",
            "            List of parameters for each boosting round\n",
            "            or a callable that calculates the parameter in terms of\n",
            "            current number of round (e.g. yields learning rate decay).\n",
            "            If list lst, parameter = lst[current_round].\n",
            "            If callable func, parameter = func(current_round).\n",
            "        \n",
            "        Returns\n",
            "        -------\n",
            "        callback : _ResetParameterCallback\n",
            "            The callback that resets the parameter after the first iteration.\n",
            "    \n",
            "    train(params: Dict[str, Any], train_set: lightgbm.basic.Dataset, num_boost_round: int = 100, valid_sets: Optional[List[lightgbm.basic.Dataset]] = None, valid_names: Optional[List[str]] = None, feval: Union[Callable[[numpy.ndarray, lightgbm.basic.Dataset], Tuple[str, float, bool]], Callable[[numpy.ndarray, lightgbm.basic.Dataset], List[Tuple[str, float, bool]]], List[Union[Callable[[numpy.ndarray, lightgbm.basic.Dataset], Tuple[str, float, bool]], Callable[[numpy.ndarray, lightgbm.basic.Dataset], List[Tuple[str, float, bool]]]]], NoneType] = None, init_model: Union[str, pathlib.Path, lightgbm.basic.Booster, NoneType] = None, feature_name: Union[List[str], ForwardRef(\"Literal['auto']\")] = 'auto', categorical_feature: Union[List[str], List[int], ForwardRef(\"Literal['auto']\")] = 'auto', keep_training_booster: bool = False, callbacks: Optional[List[Callable]] = None) -> lightgbm.basic.Booster\n",
            "        Perform the training with given parameters.\n",
            "        \n",
            "        Parameters\n",
            "        ----------\n",
            "        params : dict\n",
            "            Parameters for training. Values passed through ``params`` take precedence over those\n",
            "            supplied via arguments.\n",
            "        train_set : Dataset\n",
            "            Data to be trained on.\n",
            "        num_boost_round : int, optional (default=100)\n",
            "            Number of boosting iterations.\n",
            "        valid_sets : list of Dataset, or None, optional (default=None)\n",
            "            List of data to be evaluated on during training.\n",
            "        valid_names : list of str, or None, optional (default=None)\n",
            "            Names of ``valid_sets``.\n",
            "        feval : callable, list of callable, or None, optional (default=None)\n",
            "            Customized evaluation function.\n",
            "            Each evaluation function should accept two parameters: preds, eval_data,\n",
            "            and return (eval_name, eval_result, is_higher_better) or list of such tuples.\n",
            "        \n",
            "                preds : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
            "                    The predicted values.\n",
            "                    For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes].\n",
            "                    If custom objective function is used, predicted values are returned before any transformation,\n",
            "                    e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
            "                eval_data : Dataset\n",
            "                    A ``Dataset`` to evaluate.\n",
            "                eval_name : str\n",
            "                    The name of evaluation function (without whitespaces).\n",
            "                eval_result : float\n",
            "                    The eval result.\n",
            "                is_higher_better : bool\n",
            "                    Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
            "        \n",
            "            To ignore the default metric corresponding to the used objective,\n",
            "            set the ``metric`` parameter to the string ``\"None\"`` in ``params``.\n",
            "        init_model : str, pathlib.Path, Booster or None, optional (default=None)\n",
            "            Filename of LightGBM model or Booster instance used for continue training.\n",
            "        feature_name : list of str, or 'auto', optional (default=\"auto\")\n",
            "            **Deprecated.** Set ``feature_name`` on ``train_set`` instead.\n",
            "            Feature names.\n",
            "            If 'auto' and data is pandas DataFrame, data columns names are used.\n",
            "        categorical_feature : list of str or int, or 'auto', optional (default=\"auto\")\n",
            "            **Deprecated.** Set ``categorical_feature`` on ``train_set`` instead.\n",
            "            Categorical features.\n",
            "            If list of int, interpreted as indices.\n",
            "            If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
            "            If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
            "            All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
            "            Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
            "            All negative values in categorical features will be treated as missing values.\n",
            "            The output cannot be monotonically constrained with respect to a categorical feature.\n",
            "            Floating point numbers in categorical features will be rounded towards 0.\n",
            "        keep_training_booster : bool, optional (default=False)\n",
            "            Whether the returned Booster will be used to keep training.\n",
            "            If False, the returned value will be converted into _InnerPredictor before returning.\n",
            "            This means you won't be able to use ``eval``, ``eval_train`` or ``eval_valid`` methods of the returned Booster.\n",
            "            When your model is very large and cause the memory error,\n",
            "            you can try to set this param to ``True`` to avoid the model conversion performed during the internal call of ``model_to_string``.\n",
            "            You can still use _InnerPredictor as ``init_model`` for future continue training.\n",
            "        callbacks : list of callable, or None, optional (default=None)\n",
            "            List of callback functions that are applied at each iteration.\n",
            "            See Callbacks in Python API for more information.\n",
            "        \n",
            "        Note\n",
            "        ----\n",
            "        A custom objective function can be provided for the ``objective`` parameter.\n",
            "        It should accept two parameters: preds, train_data and return (grad, hess).\n",
            "        \n",
            "            preds : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
            "                The predicted values.\n",
            "                Predicted values are returned before any transformation,\n",
            "                e.g. they are raw margin instead of probability of positive class for binary task.\n",
            "            train_data : Dataset\n",
            "                The training dataset.\n",
            "            grad : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
            "                The value of the first order derivative (gradient) of the loss\n",
            "                with respect to the elements of preds for each sample point.\n",
            "            hess : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
            "                The value of the second order derivative (Hessian) of the loss\n",
            "                with respect to the elements of preds for each sample point.\n",
            "        \n",
            "        For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes],\n",
            "        and grad and hess should be returned in the same format.\n",
            "        \n",
            "        Returns\n",
            "        -------\n",
            "        booster : Booster\n",
            "            The trained Booster model.\n",
            "\n",
            "DATA\n",
            "    __all__ = ['Dataset', 'Booster', 'CVBooster', 'Sequence', 'register_lo...\n",
            "\n",
            "VERSION\n",
            "    4.5.0\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.11/dist-packages/lightgbm/__init__.py\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "o4sti8v3TiF9"
      },
      "id": "o4sti8v3TiF9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['신용_거래_연수_그룹'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "WjxF4FNBb4b5",
        "outputId": "e0ad722b-64d1-4ccc-a3b9-6f7d96668b7a"
      },
      "id": "WjxF4FNBb4b5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1281    2\n",
              "971     2\n",
              "5928    3\n",
              "4481    1\n",
              "2771    3\n",
              "Name: 신용_거래_연수_그룹, dtype: category\n",
              "Categories (4, int64): [0 < 1 < 2 < 3]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>신용_거래_연수_그룹</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1281</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5928</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4481</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2771</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> category</label>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "params = {\n",
        "    \"n_estimators\": 100,\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"max_depth\": 5,\n",
        "    \"random_state\": 42,\n",
        "    \"num_leaves\":32,\n",
        "    \"force_row_wise\":True\n",
        "\n",
        "}\n",
        "\n",
        "# 모델 초기화\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=100, max_depth=5, learning_rate=0.15,\n",
        "    random_state=42, use_label_encoder=False, eval_metric=\"auc\"\n",
        "\n",
        ")\n",
        "xgb_model.set_params(\n",
        "    scale_pos_weight=1.0,\n",
        "    enable_categorical=True\n",
        ")\n",
        "\n",
        "dtrain = lgb.Dataset(X_train_smote, label=y_train_smote)\n",
        "dvalid = lgb.Dataset(X_val, label=y_val)\n",
        "eval_set = [(X_train_smote, y_train_smote), (X_val, y_val)]\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100, max_depth=5, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# XGBoost 학습\n",
        "xgb_model.fit(\n",
        "    X_train_smote, y_train_smote,\n",
        "    eval_set=eval_set\n",
        ")\n",
        "\n",
        "# LightGBM 학습\n",
        "lgbm_model=lgb.train(\n",
        "    params=params,\n",
        "    num_boost_round=10,\n",
        "    train_set=dtrain,\n",
        "    valid_sets=[dvalid],\n",
        "    callbacks=[\n",
        "        lgb.early_stopping(stopping_rounds=10),\n",
        "        lgb.log_evaluation(1)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# RandomForest 학습\n",
        "rf_model.fit(X_train_smote, y_train_smote)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yHpuVEo29H6T",
        "outputId": "4669c7a6-9cf7-4c67-a6de-62715263938d"
      },
      "id": "yHpuVEo29H6T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.79183\tvalidation_1-auc:0.68247\n",
            "[1]\tvalidation_0-auc:0.80243\tvalidation_1-auc:0.69874\n",
            "[2]\tvalidation_0-auc:0.80945\tvalidation_1-auc:0.70818\n",
            "[3]\tvalidation_0-auc:0.81289\tvalidation_1-auc:0.71399\n",
            "[4]\tvalidation_0-auc:0.81496\tvalidation_1-auc:0.71711\n",
            "[5]\tvalidation_0-auc:0.81689\tvalidation_1-auc:0.71893\n",
            "[6]\tvalidation_0-auc:0.81909\tvalidation_1-auc:0.72025\n",
            "[7]\tvalidation_0-auc:0.82329\tvalidation_1-auc:0.72269\n",
            "[8]\tvalidation_0-auc:0.82695\tvalidation_1-auc:0.72475\n",
            "[9]\tvalidation_0-auc:0.83350\tvalidation_1-auc:0.73053\n",
            "[10]\tvalidation_0-auc:0.83487\tvalidation_1-auc:0.73173\n",
            "[11]\tvalidation_0-auc:0.83930\tvalidation_1-auc:0.73381\n",
            "[12]\tvalidation_0-auc:0.84168\tvalidation_1-auc:0.73490\n",
            "[13]\tvalidation_0-auc:0.84454\tvalidation_1-auc:0.73598\n",
            "[14]\tvalidation_0-auc:0.84654\tvalidation_1-auc:0.73759\n",
            "[15]\tvalidation_0-auc:0.84983\tvalidation_1-auc:0.73803\n",
            "[16]\tvalidation_0-auc:0.85230\tvalidation_1-auc:0.73811\n",
            "[17]\tvalidation_0-auc:0.85362\tvalidation_1-auc:0.73888\n",
            "[18]\tvalidation_0-auc:0.85556\tvalidation_1-auc:0.73986\n",
            "[19]\tvalidation_0-auc:0.85801\tvalidation_1-auc:0.74165\n",
            "[20]\tvalidation_0-auc:0.85872\tvalidation_1-auc:0.74157\n",
            "[21]\tvalidation_0-auc:0.86081\tvalidation_1-auc:0.74115\n",
            "[22]\tvalidation_0-auc:0.86154\tvalidation_1-auc:0.74177\n",
            "[23]\tvalidation_0-auc:0.86222\tvalidation_1-auc:0.74228\n",
            "[24]\tvalidation_0-auc:0.86488\tvalidation_1-auc:0.74292\n",
            "[25]\tvalidation_0-auc:0.86620\tvalidation_1-auc:0.74297\n",
            "[26]\tvalidation_0-auc:0.86757\tvalidation_1-auc:0.74324\n",
            "[27]\tvalidation_0-auc:0.86837\tvalidation_1-auc:0.74368\n",
            "[28]\tvalidation_0-auc:0.86938\tvalidation_1-auc:0.74306\n",
            "[29]\tvalidation_0-auc:0.86992\tvalidation_1-auc:0.74312\n",
            "[30]\tvalidation_0-auc:0.87189\tvalidation_1-auc:0.74357\n",
            "[31]\tvalidation_0-auc:0.87343\tvalidation_1-auc:0.74406\n",
            "[32]\tvalidation_0-auc:0.87400\tvalidation_1-auc:0.74442\n",
            "[33]\tvalidation_0-auc:0.87589\tvalidation_1-auc:0.74501\n",
            "[34]\tvalidation_0-auc:0.87724\tvalidation_1-auc:0.74550\n",
            "[35]\tvalidation_0-auc:0.87783\tvalidation_1-auc:0.74544\n",
            "[36]\tvalidation_0-auc:0.87815\tvalidation_1-auc:0.74554\n",
            "[37]\tvalidation_0-auc:0.87949\tvalidation_1-auc:0.74663\n",
            "[38]\tvalidation_0-auc:0.88037\tvalidation_1-auc:0.74620\n",
            "[39]\tvalidation_0-auc:0.88081\tvalidation_1-auc:0.74562\n",
            "[40]\tvalidation_0-auc:0.88217\tvalidation_1-auc:0.74529\n",
            "[41]\tvalidation_0-auc:0.88350\tvalidation_1-auc:0.74518\n",
            "[42]\tvalidation_0-auc:0.88400\tvalidation_1-auc:0.74481\n",
            "[43]\tvalidation_0-auc:0.88460\tvalidation_1-auc:0.74519\n",
            "[44]\tvalidation_0-auc:0.88522\tvalidation_1-auc:0.74489\n",
            "[45]\tvalidation_0-auc:0.88588\tvalidation_1-auc:0.74483\n",
            "[46]\tvalidation_0-auc:0.88703\tvalidation_1-auc:0.74440\n",
            "[47]\tvalidation_0-auc:0.88734\tvalidation_1-auc:0.74507\n",
            "[48]\tvalidation_0-auc:0.88802\tvalidation_1-auc:0.74490\n",
            "[49]\tvalidation_0-auc:0.88827\tvalidation_1-auc:0.74459\n",
            "[50]\tvalidation_0-auc:0.88855\tvalidation_1-auc:0.74437\n",
            "[51]\tvalidation_0-auc:0.88980\tvalidation_1-auc:0.74444\n",
            "[52]\tvalidation_0-auc:0.89025\tvalidation_1-auc:0.74487\n",
            "[53]\tvalidation_0-auc:0.89160\tvalidation_1-auc:0.74453\n",
            "[54]\tvalidation_0-auc:0.89251\tvalidation_1-auc:0.74452\n",
            "[55]\tvalidation_0-auc:0.89290\tvalidation_1-auc:0.74450\n",
            "[56]\tvalidation_0-auc:0.89436\tvalidation_1-auc:0.74443\n",
            "[57]\tvalidation_0-auc:0.89484\tvalidation_1-auc:0.74421\n",
            "[58]\tvalidation_0-auc:0.89585\tvalidation_1-auc:0.74406\n",
            "[59]\tvalidation_0-auc:0.89620\tvalidation_1-auc:0.74411\n",
            "[60]\tvalidation_0-auc:0.89649\tvalidation_1-auc:0.74381\n",
            "[61]\tvalidation_0-auc:0.89689\tvalidation_1-auc:0.74372\n",
            "[62]\tvalidation_0-auc:0.89760\tvalidation_1-auc:0.74342\n",
            "[63]\tvalidation_0-auc:0.89799\tvalidation_1-auc:0.74313\n",
            "[64]\tvalidation_0-auc:0.89866\tvalidation_1-auc:0.74302\n",
            "[65]\tvalidation_0-auc:0.89968\tvalidation_1-auc:0.74303\n",
            "[66]\tvalidation_0-auc:0.90026\tvalidation_1-auc:0.74272\n",
            "[67]\tvalidation_0-auc:0.90066\tvalidation_1-auc:0.74260\n",
            "[68]\tvalidation_0-auc:0.90130\tvalidation_1-auc:0.74338\n",
            "[69]\tvalidation_0-auc:0.90170\tvalidation_1-auc:0.74335\n",
            "[70]\tvalidation_0-auc:0.90198\tvalidation_1-auc:0.74333\n",
            "[71]\tvalidation_0-auc:0.90241\tvalidation_1-auc:0.74333\n",
            "[72]\tvalidation_0-auc:0.90300\tvalidation_1-auc:0.74322\n",
            "[73]\tvalidation_0-auc:0.90341\tvalidation_1-auc:0.74267\n",
            "[74]\tvalidation_0-auc:0.90375\tvalidation_1-auc:0.74248\n",
            "[75]\tvalidation_0-auc:0.90445\tvalidation_1-auc:0.74209\n",
            "[76]\tvalidation_0-auc:0.90540\tvalidation_1-auc:0.74146\n",
            "[77]\tvalidation_0-auc:0.90654\tvalidation_1-auc:0.74107\n",
            "[78]\tvalidation_0-auc:0.90665\tvalidation_1-auc:0.74097\n",
            "[79]\tvalidation_0-auc:0.90680\tvalidation_1-auc:0.74072\n",
            "[80]\tvalidation_0-auc:0.90693\tvalidation_1-auc:0.74083\n",
            "[81]\tvalidation_0-auc:0.90723\tvalidation_1-auc:0.74051\n",
            "[82]\tvalidation_0-auc:0.90802\tvalidation_1-auc:0.74035\n",
            "[83]\tvalidation_0-auc:0.90864\tvalidation_1-auc:0.73947\n",
            "[84]\tvalidation_0-auc:0.90920\tvalidation_1-auc:0.73959\n",
            "[85]\tvalidation_0-auc:0.90949\tvalidation_1-auc:0.73949\n",
            "[86]\tvalidation_0-auc:0.90996\tvalidation_1-auc:0.73946\n",
            "[87]\tvalidation_0-auc:0.91081\tvalidation_1-auc:0.73881\n",
            "[88]\tvalidation_0-auc:0.91167\tvalidation_1-auc:0.73785\n",
            "[89]\tvalidation_0-auc:0.91201\tvalidation_1-auc:0.73790\n",
            "[90]\tvalidation_0-auc:0.91231\tvalidation_1-auc:0.73743\n",
            "[91]\tvalidation_0-auc:0.91280\tvalidation_1-auc:0.73802\n",
            "[92]\tvalidation_0-auc:0.91311\tvalidation_1-auc:0.73794\n",
            "[93]\tvalidation_0-auc:0.91415\tvalidation_1-auc:0.73829\n",
            "[94]\tvalidation_0-auc:0.91422\tvalidation_1-auc:0.73794\n",
            "[95]\tvalidation_0-auc:0.91502\tvalidation_1-auc:0.73797\n",
            "[96]\tvalidation_0-auc:0.91577\tvalidation_1-auc:0.73782\n",
            "[97]\tvalidation_0-auc:0.91592\tvalidation_1-auc:0.73748\n",
            "[98]\tvalidation_0-auc:0.91670\tvalidation_1-auc:0.73752\n",
            "[99]\tvalidation_0-auc:0.91803\tvalidation_1-auc:0.73687\n",
            "[LightGBM] [Info] Total Bins 2307\n",
            "[LightGBM] [Info] Number of data points in the train set: 10636, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 0.500000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[1]\tvalid_0's l2: 0.242462\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[2]\tvalid_0's l2: 0.236061\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[3]\tvalid_0's l2: 0.230744\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[4]\tvalid_0's l2: 0.226281\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[5]\tvalid_0's l2: 0.222472\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[6]\tvalid_0's l2: 0.218942\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[7]\tvalid_0's l2: 0.216115\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[8]\tvalid_0's l2: 0.213977\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[9]\tvalid_0's l2: 0.211904\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[10]\tvalid_0's l2: 0.209924\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[11]\tvalid_0's l2: 0.207654\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[12]\tvalid_0's l2: 0.206514\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[13]\tvalid_0's l2: 0.204774\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[14]\tvalid_0's l2: 0.203629\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[15]\tvalid_0's l2: 0.202287\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[16]\tvalid_0's l2: 0.201076\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[17]\tvalid_0's l2: 0.200183\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[18]\tvalid_0's l2: 0.199523\n",
            "[19]\tvalid_0's l2: 0.198665\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[20]\tvalid_0's l2: 0.19819\n",
            "[21]\tvalid_0's l2: 0.197623\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[22]\tvalid_0's l2: 0.197191\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[23]\tvalid_0's l2: 0.196589\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[24]\tvalid_0's l2: 0.195826\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[25]\tvalid_0's l2: 0.195077\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[26]\tvalid_0's l2: 0.194883\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[27]\tvalid_0's l2: 0.194696\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[28]\tvalid_0's l2: 0.194413\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[29]\tvalid_0's l2: 0.194354\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[30]\tvalid_0's l2: 0.194122\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[31]\tvalid_0's l2: 0.194046\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[32]\tvalid_0's l2: 0.193649\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[33]\tvalid_0's l2: 0.193471\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[34]\tvalid_0's l2: 0.193149\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[35]\tvalid_0's l2: 0.193052\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[36]\tvalid_0's l2: 0.192757\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[37]\tvalid_0's l2: 0.192427\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[38]\tvalid_0's l2: 0.192284\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[39]\tvalid_0's l2: 0.192254\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[40]\tvalid_0's l2: 0.192184\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[41]\tvalid_0's l2: 0.192071\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[42]\tvalid_0's l2: 0.192096\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[43]\tvalid_0's l2: 0.192075\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[44]\tvalid_0's l2: 0.192007\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[45]\tvalid_0's l2: 0.191786\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[46]\tvalid_0's l2: 0.191674\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[47]\tvalid_0's l2: 0.191509\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[48]\tvalid_0's l2: 0.191516\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[49]\tvalid_0's l2: 0.191433\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[50]\tvalid_0's l2: 0.191287\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[51]\tvalid_0's l2: 0.191239\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[52]\tvalid_0's l2: 0.191174\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[53]\tvalid_0's l2: 0.191102\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[54]\tvalid_0's l2: 0.190996\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[55]\tvalid_0's l2: 0.190798\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[56]\tvalid_0's l2: 0.190822\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[57]\tvalid_0's l2: 0.190832\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[58]\tvalid_0's l2: 0.190767\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[59]\tvalid_0's l2: 0.190723\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[60]\tvalid_0's l2: 0.190773\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[61]\tvalid_0's l2: 0.190766\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[62]\tvalid_0's l2: 0.190914\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[63]\tvalid_0's l2: 0.19094\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[64]\tvalid_0's l2: 0.19089\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[65]\tvalid_0's l2: 0.190868\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[66]\tvalid_0's l2: 0.190969\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[67]\tvalid_0's l2: 0.190972\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[68]\tvalid_0's l2: 0.190889\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[69]\tvalid_0's l2: 0.19094\n",
            "Early stopping, best iteration is:\n",
            "[59]\tvalid_0's l2: 0.190723\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=5, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-11 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-11 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-11 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-11 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-11 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-11 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-11 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-11 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-11 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=5, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11efa6b9-131e-475d-b1dd-9310c879505a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "11efa6b9-131e-475d-b1dd-9310c879505a",
        "outputId": "f5150054-05a7-44e5-f1f4-6bbb9ac46b9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.72433\tvalidation_1-auc:0.70532\n",
            "[1]\tvalidation_0-auc:0.74095\tvalidation_1-auc:0.72382\n",
            "[2]\tvalidation_0-auc:0.75141\tvalidation_1-auc:0.72907\n",
            "[3]\tvalidation_0-auc:0.75502\tvalidation_1-auc:0.73067\n",
            "[4]\tvalidation_0-auc:0.76131\tvalidation_1-auc:0.73761\n",
            "[5]\tvalidation_0-auc:0.76461\tvalidation_1-auc:0.74009\n",
            "[6]\tvalidation_0-auc:0.77187\tvalidation_1-auc:0.74335\n",
            "[7]\tvalidation_0-auc:0.77519\tvalidation_1-auc:0.74489\n",
            "[8]\tvalidation_0-auc:0.77946\tvalidation_1-auc:0.74751\n",
            "[9]\tvalidation_0-auc:0.78253\tvalidation_1-auc:0.74925\n",
            "[10]\tvalidation_0-auc:0.78470\tvalidation_1-auc:0.74920\n",
            "[11]\tvalidation_0-auc:0.78854\tvalidation_1-auc:0.75046\n",
            "[12]\tvalidation_0-auc:0.79067\tvalidation_1-auc:0.75051\n",
            "[13]\tvalidation_0-auc:0.79451\tvalidation_1-auc:0.75142\n",
            "[14]\tvalidation_0-auc:0.79672\tvalidation_1-auc:0.75105\n",
            "[15]\tvalidation_0-auc:0.79826\tvalidation_1-auc:0.75128\n",
            "[16]\tvalidation_0-auc:0.80147\tvalidation_1-auc:0.75204\n",
            "[17]\tvalidation_0-auc:0.80225\tvalidation_1-auc:0.75233\n",
            "[18]\tvalidation_0-auc:0.80565\tvalidation_1-auc:0.75306\n",
            "[19]\tvalidation_0-auc:0.80702\tvalidation_1-auc:0.75408\n",
            "[20]\tvalidation_0-auc:0.80874\tvalidation_1-auc:0.75398\n",
            "[21]\tvalidation_0-auc:0.80938\tvalidation_1-auc:0.75427\n",
            "[22]\tvalidation_0-auc:0.81036\tvalidation_1-auc:0.75480\n",
            "[23]\tvalidation_0-auc:0.81164\tvalidation_1-auc:0.75477\n",
            "[24]\tvalidation_0-auc:0.81300\tvalidation_1-auc:0.75489\n",
            "[25]\tvalidation_0-auc:0.81416\tvalidation_1-auc:0.75454\n",
            "[26]\tvalidation_0-auc:0.81613\tvalidation_1-auc:0.75467\n",
            "[27]\tvalidation_0-auc:0.81699\tvalidation_1-auc:0.75445\n",
            "[28]\tvalidation_0-auc:0.81930\tvalidation_1-auc:0.75490\n",
            "[29]\tvalidation_0-auc:0.82025\tvalidation_1-auc:0.75488\n",
            "[30]\tvalidation_0-auc:0.82160\tvalidation_1-auc:0.75469\n",
            "[31]\tvalidation_0-auc:0.82214\tvalidation_1-auc:0.75443\n",
            "[32]\tvalidation_0-auc:0.82308\tvalidation_1-auc:0.75448\n",
            "[33]\tvalidation_0-auc:0.82386\tvalidation_1-auc:0.75498\n",
            "[34]\tvalidation_0-auc:0.82525\tvalidation_1-auc:0.75508\n",
            "[35]\tvalidation_0-auc:0.82638\tvalidation_1-auc:0.75516\n",
            "[36]\tvalidation_0-auc:0.82787\tvalidation_1-auc:0.75533\n",
            "[37]\tvalidation_0-auc:0.82849\tvalidation_1-auc:0.75497\n",
            "[38]\tvalidation_0-auc:0.83071\tvalidation_1-auc:0.75521\n",
            "[39]\tvalidation_0-auc:0.83147\tvalidation_1-auc:0.75513\n",
            "[40]\tvalidation_0-auc:0.83211\tvalidation_1-auc:0.75478\n",
            "[41]\tvalidation_0-auc:0.83305\tvalidation_1-auc:0.75471\n",
            "[42]\tvalidation_0-auc:0.83371\tvalidation_1-auc:0.75516\n",
            "[43]\tvalidation_0-auc:0.83475\tvalidation_1-auc:0.75491\n",
            "[44]\tvalidation_0-auc:0.83523\tvalidation_1-auc:0.75468\n",
            "[45]\tvalidation_0-auc:0.83691\tvalidation_1-auc:0.75449\n",
            "[46]\tvalidation_0-auc:0.83875\tvalidation_1-auc:0.75348\n",
            "[47]\tvalidation_0-auc:0.83934\tvalidation_1-auc:0.75331\n",
            "[48]\tvalidation_0-auc:0.84069\tvalidation_1-auc:0.75354\n",
            "[49]\tvalidation_0-auc:0.84148\tvalidation_1-auc:0.75340\n",
            "[50]\tvalidation_0-auc:0.84324\tvalidation_1-auc:0.75299\n",
            "[51]\tvalidation_0-auc:0.84524\tvalidation_1-auc:0.75257\n",
            "[52]\tvalidation_0-auc:0.84700\tvalidation_1-auc:0.75246\n",
            "[53]\tvalidation_0-auc:0.84748\tvalidation_1-auc:0.75245\n",
            "[54]\tvalidation_0-auc:0.84750\tvalidation_1-auc:0.75241\n",
            "[55]\tvalidation_0-auc:0.84822\tvalidation_1-auc:0.75207\n",
            "[56]\tvalidation_0-auc:0.84922\tvalidation_1-auc:0.75217\n",
            "[57]\tvalidation_0-auc:0.85084\tvalidation_1-auc:0.75160\n",
            "[58]\tvalidation_0-auc:0.85154\tvalidation_1-auc:0.75136\n",
            "[59]\tvalidation_0-auc:0.85298\tvalidation_1-auc:0.75119\n",
            "[60]\tvalidation_0-auc:0.85336\tvalidation_1-auc:0.75101\n",
            "[61]\tvalidation_0-auc:0.85403\tvalidation_1-auc:0.75074\n",
            "[62]\tvalidation_0-auc:0.85493\tvalidation_1-auc:0.75067\n",
            "[63]\tvalidation_0-auc:0.85579\tvalidation_1-auc:0.75071\n",
            "[64]\tvalidation_0-auc:0.85786\tvalidation_1-auc:0.75044\n",
            "[65]\tvalidation_0-auc:0.85841\tvalidation_1-auc:0.75048\n",
            "[66]\tvalidation_0-auc:0.85912\tvalidation_1-auc:0.75053\n",
            "[67]\tvalidation_0-auc:0.85942\tvalidation_1-auc:0.75014\n",
            "[68]\tvalidation_0-auc:0.86144\tvalidation_1-auc:0.75066\n",
            "[69]\tvalidation_0-auc:0.86338\tvalidation_1-auc:0.75034\n",
            "[70]\tvalidation_0-auc:0.86400\tvalidation_1-auc:0.75046\n",
            "[71]\tvalidation_0-auc:0.86592\tvalidation_1-auc:0.75009\n",
            "[72]\tvalidation_0-auc:0.86817\tvalidation_1-auc:0.75072\n",
            "[73]\tvalidation_0-auc:0.86942\tvalidation_1-auc:0.75095\n",
            "[74]\tvalidation_0-auc:0.87047\tvalidation_1-auc:0.75104\n",
            "[75]\tvalidation_0-auc:0.87091\tvalidation_1-auc:0.75092\n",
            "[76]\tvalidation_0-auc:0.87203\tvalidation_1-auc:0.75069\n",
            "[77]\tvalidation_0-auc:0.87303\tvalidation_1-auc:0.75044\n",
            "[78]\tvalidation_0-auc:0.87450\tvalidation_1-auc:0.75136\n",
            "[79]\tvalidation_0-auc:0.87574\tvalidation_1-auc:0.75155\n",
            "[80]\tvalidation_0-auc:0.87622\tvalidation_1-auc:0.75144\n",
            "[81]\tvalidation_0-auc:0.87677\tvalidation_1-auc:0.75136\n",
            "[82]\tvalidation_0-auc:0.87800\tvalidation_1-auc:0.75148\n",
            "[83]\tvalidation_0-auc:0.87924\tvalidation_1-auc:0.75153\n",
            "[84]\tvalidation_0-auc:0.88095\tvalidation_1-auc:0.75120\n",
            "[85]\tvalidation_0-auc:0.88230\tvalidation_1-auc:0.75101\n",
            "[86]\tvalidation_0-auc:0.88254\tvalidation_1-auc:0.75105\n",
            "[87]\tvalidation_0-auc:0.88276\tvalidation_1-auc:0.75108\n",
            "[88]\tvalidation_0-auc:0.88321\tvalidation_1-auc:0.75108\n",
            "[89]\tvalidation_0-auc:0.88399\tvalidation_1-auc:0.75113\n",
            "[90]\tvalidation_0-auc:0.88538\tvalidation_1-auc:0.75153\n",
            "[91]\tvalidation_0-auc:0.88609\tvalidation_1-auc:0.75151\n",
            "[92]\tvalidation_0-auc:0.88628\tvalidation_1-auc:0.75159\n",
            "[93]\tvalidation_0-auc:0.88730\tvalidation_1-auc:0.75105\n",
            "[94]\tvalidation_0-auc:0.88797\tvalidation_1-auc:0.75078\n",
            "[95]\tvalidation_0-auc:0.88867\tvalidation_1-auc:0.75038\n",
            "[96]\tvalidation_0-auc:0.88931\tvalidation_1-auc:0.75062\n",
            "[97]\tvalidation_0-auc:0.88960\tvalidation_1-auc:0.75043\n",
            "[98]\tvalidation_0-auc:0.89010\tvalidation_1-auc:0.75044\n",
            "[99]\tvalidation_0-auc:0.89157\tvalidation_1-auc:0.75025\n",
            "[LightGBM] [Info] Total Bins 1768\n",
            "[LightGBM] [Info] Number of data points in the train set: 7999, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 0.335167\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[1]\tvalid_0's l2: 0.226773\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[2]\tvalid_0's l2: 0.222008\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[3]\tvalid_0's l2: 0.218016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[4]\tvalid_0's l2: 0.214494\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[5]\tvalid_0's l2: 0.211816\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[6]\tvalid_0's l2: 0.209131\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[7]\tvalid_0's l2: 0.207028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[8]\tvalid_0's l2: 0.205392\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[9]\tvalid_0's l2: 0.203585\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[10]\tvalid_0's l2: 0.202368\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[11]\tvalid_0's l2: 0.201012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[12]\tvalid_0's l2: 0.199928\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[13]\tvalid_0's l2: 0.198422\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[14]\tvalid_0's l2: 0.197703\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[15]\tvalid_0's l2: 0.197011\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[16]\tvalid_0's l2: 0.196298\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[17]\tvalid_0's l2: 0.195596\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[18]\tvalid_0's l2: 0.194729\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[19]\tvalid_0's l2: 0.194336\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[20]\tvalid_0's l2: 0.193885\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[21]\tvalid_0's l2: 0.193484\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[22]\tvalid_0's l2: 0.193114\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[23]\tvalid_0's l2: 0.192781\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[24]\tvalid_0's l2: 0.192504\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[25]\tvalid_0's l2: 0.192313\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[26]\tvalid_0's l2: 0.192206\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[27]\tvalid_0's l2: 0.192127\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[28]\tvalid_0's l2: 0.191702\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[29]\tvalid_0's l2: 0.191379\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[30]\tvalid_0's l2: 0.191197\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[31]\tvalid_0's l2: 0.191107\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[32]\tvalid_0's l2: 0.191048\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[33]\tvalid_0's l2: 0.191026\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[34]\tvalid_0's l2: 0.190887\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[35]\tvalid_0's l2: 0.190884\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[36]\tvalid_0's l2: 0.190943\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[37]\tvalid_0's l2: 0.190808\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[38]\tvalid_0's l2: 0.190659\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[39]\tvalid_0's l2: 0.190669\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[40]\tvalid_0's l2: 0.190545\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[41]\tvalid_0's l2: 0.190433\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[42]\tvalid_0's l2: 0.19048\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[43]\tvalid_0's l2: 0.190598\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[44]\tvalid_0's l2: 0.190582\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[45]\tvalid_0's l2: 0.190563\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[46]\tvalid_0's l2: 0.19065\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[47]\tvalid_0's l2: 0.19064\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[48]\tvalid_0's l2: 0.190639\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[49]\tvalid_0's l2: 0.190791\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[50]\tvalid_0's l2: 0.19087\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[51]\tvalid_0's l2: 0.190882\n",
            "Early stopping, best iteration is:\n",
            "[41]\tvalid_0's l2: 0.190433\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=5, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-10 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-10 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-10 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-10 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-10 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-10 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-10 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-10 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-10 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-10 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-10 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-10 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-10 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=5, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "params = {\n",
        "    \"n_estimators\": 100,\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"max_depth\": 5,\n",
        "    \"random_state\": 42,\n",
        "    \"num_leaves\":32,\n",
        "    \"force_row_wise\":True\n",
        "\n",
        "}\n",
        "\n",
        "# 모델 초기화\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=100, max_depth=5, learning_rate=0.15,\n",
        "    random_state=42, use_label_encoder=False, eval_metric=\"auc\"\n",
        "\n",
        ")\n",
        "xgb_model.set_params(\n",
        "    scale_pos_weight=1.0,\n",
        "    enable_categorical=True\n",
        ")\n",
        "\n",
        "dtrain = lgb.Dataset(X_train, label=y_train)\n",
        "dvalid = lgb.Dataset(X_val, label=y_val)\n",
        "eval_set = [(X_train, y_train), (X_val, y_val)]\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100, max_depth=5, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# XGBoost 학습\n",
        "xgb_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=eval_set\n",
        ")\n",
        "\n",
        "# LightGBM 학습\n",
        "lgbm_model=lgb.train(\n",
        "    params=params,\n",
        "    num_boost_round=10,\n",
        "    train_set=dtrain,\n",
        "    valid_sets=[dvalid],\n",
        "    callbacks=[\n",
        "        lgb.early_stopping(stopping_rounds=10),\n",
        "        lgb.log_evaluation(1)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# RandomForest 학습\n",
        "rf_model.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_lgb=lgbm_model.predict(X_val)\n",
        "result_lgb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54-L55NIbUxD",
        "outputId": "fa3551ca-5913-426a-bae4-4c4df9a60d0d"
      },
      "id": "54-L55NIbUxD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.25582663, 0.15874393, 0.4240388 , ..., 0.61309945, 0.18074487,\n",
              "       0.47656421])"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_demo=lgbm_model.predict(test_df)\n",
        "result_demo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDZGOD60pxzh",
        "outputId": "bd65a93b-9ba1-4ad2-d7bc-2b42603ab5ae"
      },
      "id": "oDZGOD60pxzh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.40623662, 0.50045649, 0.5164926 , ..., 0.46339193, 0.34895765,\n",
              "       0.71611626])"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "# LGBMClassifier 객체 생성\n",
        "lgbm_model = LGBMClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# K-Fold 설정\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 교차 검증 수행\n",
        "cv_scores = cross_val_score(lgbm_model, X_smote, y_smote, cv=kf, scoring='roc_auc')\n",
        "\n",
        "print(f\"평균 AUC Score: {cv_scores.mean():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EAU7sIN3f9n",
        "outputId": "bf3a4d52-d73a-4ea8-bd1c-f52d4ad5cffd"
      },
      "id": "_EAU7sIN3f9n",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 5270, number of negative: 5270\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001609 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2305\n",
            "[LightGBM] [Info] Number of data points in the train set: 10540, number of used features: 16\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 5271, number of negative: 5270\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001684 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2308\n",
            "[LightGBM] [Info] Number of data points in the train set: 10541, number of used features: 16\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500047 -> initscore=0.000190\n",
            "[LightGBM] [Info] Start training from score 0.000190\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 5271, number of negative: 5270\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001540 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2308\n",
            "[LightGBM] [Info] Number of data points in the train set: 10541, number of used features: 16\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500047 -> initscore=0.000190\n",
            "[LightGBM] [Info] Start training from score 0.000190\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 5270, number of negative: 5271\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001534 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2308\n",
            "[LightGBM] [Info] Number of data points in the train set: 10541, number of used features: 16\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499953 -> initscore=-0.000190\n",
            "[LightGBM] [Info] Start training from score -0.000190\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 5270, number of negative: 5271\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001610 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2305\n",
            "[LightGBM] [Info] Number of data points in the train set: 10541, number of used features: 16\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499953 -> initscore=-0.000190\n",
            "[LightGBM] [Info] Start training from score -0.000190\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "평균 AUC Score: 0.8362\n",
            "[LightGBM] [Info] Number of positive: 5270, number of negative: 5270\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001557 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2305\n",
            "[LightGBM] [Info] Number of data points in the train set: 10540, number of used features: 16\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 5271, number of negative: 5270\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001576 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2308\n",
            "[LightGBM] [Info] Number of data points in the train set: 10541, number of used features: 16\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500047 -> initscore=0.000190\n",
            "[LightGBM] [Info] Start training from score 0.000190\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 5271, number of negative: 5270\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001560 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2308\n",
            "[LightGBM] [Info] Number of data points in the train set: 10541, number of used features: 16\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500047 -> initscore=0.000190\n",
            "[LightGBM] [Info] Start training from score 0.000190\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 5270, number of negative: 5271\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001597 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2308\n",
            "[LightGBM] [Info] Number of data points in the train set: 10541, number of used features: 16\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499953 -> initscore=-0.000190\n",
            "[LightGBM] [Info] Start training from score -0.000190\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 5270, number of negative: 5271\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2305\n",
            "[LightGBM] [Info] Number of data points in the train set: 10541, number of used features: 16\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499953 -> initscore=-0.000190\n",
            "[LightGBM] [Info] Start training from score -0.000190\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[0.34784431 0.14055434 0.52050931 ... 0.99772978 0.99932764 0.93103109]\n",
            "Cross-Validation ROC-AUC Score: 0.8361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1️⃣ LGBMClassifier 객체 생성 (최종 학습용)\n",
        "final_lgbm_model = LGBMClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2️⃣ 전체 데이터로 최종 학습\n",
        "final_lgbm_model.fit(X_smote, y_smote)\n",
        "\n",
        "# 3️⃣ 테스트 데이터에서 예측 확률 계산 (predict_proba 사용)\n",
        "y_test_proba = final_lgbm_model.predict_proba(test_df)[:, 1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIoPR9cs6p3I",
        "outputId": "b7a92c38-70d6-4e78-b038-bbec123ddb85"
      },
      "id": "aIoPR9cs6p3I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 6588, number of negative: 6588\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002031 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2309\n",
            "[LightGBM] [Info] Number of data points in the train set: 13176, number of used features: 16\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# K-Fold 설정\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 교차 검증 수행\n",
        "cv_scores = cross_val_score(xgb_model, X_smote, y_smote, cv=kf, scoring='roc_auc')\n",
        "\n",
        "print(f\"평균 AUC Score: {cv_scores.mean():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BchxmQpI4uEW",
        "outputId": "1f672eed-a178-4f90-f937-80ec06d09057"
      },
      "id": "BchxmQpI4uEW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 AUC Score: 0.8370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Fold 설정\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 교차 검증 수행\n",
        "cv_scores = cross_val_score(rf_model, X_smote, y_smote, cv=kf, scoring='roc_auc')\n",
        "\n",
        "print(f\"평균 AUC Score: {cv_scores.mean():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf2nw6Ru5Eu9",
        "outputId": "f1f56c11-80c6-48e4-d75a-94111404c30b"
      },
      "id": "xf2nw6Ru5Eu9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 AUC Score: 0.8124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('/content/drive/MyDrive/dacon_project_default_prediction/sample_submission.csv')\n",
        "\n",
        "# 결과 저장\n",
        "submit['채무 불이행 확률'] = y_test_proba\n",
        "submit.to_csv('/content/drive/MyDrive/dacon_project_default_prediction/submission_smote_lgbm.csv', encoding='UTF-8-sig', index=False)"
      ],
      "metadata": {
        "id": "W-anxsUr7xG4"
      },
      "id": "W-anxsUr7xG4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('/content/drive/MyDrive/dacon_project_default_prediction/sample_submission.csv')\n",
        "\n",
        "# 결과 저장\n",
        "submit['채무 불이행 확률'] = result_demo\n",
        "submit.to_csv('/content/drive/MyDrive/dacon_project_default_prediction/submission_demo_smote.csv', encoding='UTF-8-sig', index=False)"
      ],
      "metadata": {
        "id": "X4-8TDgMp428"
      },
      "id": "X4-8TDgMp428",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc_score_lgb = roc_auc_score(y_val, result_lgb)\n",
        "auc_score_lgb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qynAd7ejXYdX",
        "outputId": "f74f3ef0-813c-4d5c-f4b2-c501aa4b3e9d"
      },
      "id": "qynAd7ejXYdX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7563790313881997"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QaTrrsoT3fC8"
      },
      "id": "QaTrrsoT3fC8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI0gsS44YKMY",
        "outputId": "c7592024-aa8e-41e8-ffa9-13287ef03a3f"
      },
      "id": "yI0gsS44YKMY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.9.3)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (1.25.2)\n",
            "Downloading scipy-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.9.3\n",
            "    Uninstalling scipy-1.9.3:\n",
            "      Successfully uninstalled scipy-1.9.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.1.3 which is incompatible.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.1 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.1.3 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.1.3 which is incompatible.\n",
            "bigframes 1.34.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scipy-1.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall xgboost\n",
        "!pip install --upgrade xgboost\n",
        "!pip install --upgrade pandas\n",
        "!pip install --upgrade scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq_v3pS3Wxr5",
        "outputId": "1d6bc361-70b7-4c4a-d6f9-4db0ed8662dd"
      },
      "id": "tq_v3pS3Wxr5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: xgboost 1.5.0\n",
            "Uninstalling xgboost-1.5.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.11/dist-packages/xgboost-1.5.0.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/xgboost.libs/libgomp-a34b3233.so.1.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/xgboost/*\n",
            "Proceed (Y/n)? ㅛ\n",
            "Your response ('ㅛ') was not one of the expected responses: y, n, \n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled xgboost-1.5.0\n",
            "Collecting xgboost\n",
            "  Downloading xgboost-2.1.4-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.1)\n",
            "Downloading xgboost-2.1.4-py3-none-manylinux_2_28_x86_64.whl (223.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xgboost\n",
            "Successfully installed xgboost-2.1.4\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (1.5.3)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.1.3 which is incompatible.\n",
            "bigframes 1.34.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.2.3\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.1.3)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.1.3\n",
            "    Uninstalling scikit-learn-1.1.3:\n",
            "      Successfully uninstalled scikit-learn-1.1.3\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed scikit-learn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 예측 확률 계산\n",
        "xgb_pred = xgb_model.predict_proba(X_test)[:, 1]\n",
        "lgbm_pred = lgbm_model.predict_proba(X_test)[:, 1]\n",
        "rf_pred = rf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# ROC-AUC Score 계산\n",
        "xgb_auc = roc_auc_score(y_test, xgb_pred)\n",
        "lgbm_auc = roc_auc_score(y_test, lgbm_pred)\n",
        "rf_auc = roc_auc_score(y_test, rf_pred)\n",
        "\n",
        "print(f\"XGBoost AUC: {xgb_auc:.4f}\")\n",
        "print(f\"LightGBM AUC: {lgbm_auc:.4f}\")\n",
        "print(f\"RandomForest AUC: {rf_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "9mjeOsOC5VTu",
        "outputId": "8a08ad7c-5015-4e4e-ce1a-b1e51c1f2ac2"
      },
      "id": "9mjeOsOC5VTu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==1.1.3\n",
            "  Downloading scikit_learn-1.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.1.3) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.1.3) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.1.3) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.1.3) (3.5.0)\n",
            "Downloading scikit_learn-1.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.0/32.0 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.1.3 which is incompatible.\n",
            "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.1.3 which is incompatible.\n",
            "bigframes 1.34.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.1.3 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-learn-1.1.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              },
              "id": "4b47e24cebe9413f9e1b7152079ef693"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# ROC Curve 계산\n",
        "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, xgb_pred)\n",
        "fpr_lgbm, tpr_lgbm, _ = roc_curve(y_test, lgbm_pred)\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_pred)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC={xgb_auc:.4f})')\n",
        "plt.plot(fpr_lgbm, tpr_lgbm, label=f'LightGBM (AUC={lgbm_auc:.4f})')\n",
        "plt.plot(fpr_rf, tpr_rf, label=f'RandomForest (AUC={rf_auc:.4f})')\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve Comparison\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X9B8Zy6ZT4dp"
      },
      "id": "X9B8Zy6ZT4dp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "08f6a4a8-425a-4e51-a664-dc11a1c2f791",
      "metadata": {
        "id": "08f6a4a8-425a-4e51-a664-dc11a1c2f791"
      },
      "source": [
        "## 6. Prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Wjh05qlT4AO"
      },
      "id": "1Wjh05qlT4AO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAJT5dUrES60",
        "outputId": "d16a6dc5-4073-42b5-fcc3-133ac9ce840d"
      },
      "id": "IAJT5dUrES60",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 10.3 MB of archives.\n",
            "After this operation, 34.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n",
            "Fetched 10.3 MB in 1s (8,757 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "BagCgwoBZaYr",
        "outputId": "ca5f3ad2-fdc7-4295-f7c6-88340dab0c40"
      },
      "id": "BagCgwoBZaYr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          연간_소득  체납_세금_압류_횟수  개설된_신용계좌_수  신용_거래_연수    최대_신용한도  신용_문제_발생_횟수  \\\n",
              "0     14.260255          0.0          13      12.0  13.113448            0   \n",
              "1     14.558693          0.0           9      29.0  13.272220            0   \n",
              "2     14.722959          0.0          11      26.5  13.811344            0   \n",
              "3     14.267281          0.0           7      34.4  13.307443            0   \n",
              "4     14.644176          0.0          19      25.0  14.485708            0   \n",
              "...         ...          ...         ...       ...        ...          ...   \n",
              "2057  13.456130          0.0           5       7.7  11.259542            0   \n",
              "2058  14.553829          0.0          15      27.2  14.586588            0   \n",
              "2059  14.534326          0.0          20      26.7  14.113215            0   \n",
              "2060  15.262377          0.0          18      21.3  12.948619            0   \n",
              "2061  14.450189          0.0          14      16.5  14.024329            0   \n",
              "\n",
              "      마지막_연체_이후_경과_개월_수  개인_파산_횟수  대출_상환_기간   현재_대출_잔액  ...  현재_직장_근속_연수_1년  \\\n",
              "0                    18         0         0  12.838230  ...             0.0   \n",
              "1                    40         0         1  13.629639  ...             0.0   \n",
              "2                    44         0         1  13.684987  ...             0.0   \n",
              "3                    45         0         0  13.096592  ...             0.0   \n",
              "4                    14         0         0  12.893662  ...             0.0   \n",
              "...                 ...       ...       ...        ...  ...             ...   \n",
              "2057                 33         0         0  12.175655  ...             0.0   \n",
              "2058                 35         0         0  13.938301  ...             0.0   \n",
              "2059                 69         0         0  13.840667  ...             0.0   \n",
              "2060                  6         0         0  13.394079  ...             0.0   \n",
              "2061                 58         0         1  13.418131  ...             0.0   \n",
              "\n",
              "      현재_직장_근속_연수_1년_미만  현재_직장_근속_연수_2년  현재_직장_근속_연수_3년  현재_직장_근속_연수_4년  \\\n",
              "0                   0.0             0.0             0.0             0.0   \n",
              "1                   0.0             1.0             0.0             0.0   \n",
              "2                   0.0             0.0             0.0             0.0   \n",
              "3                   0.0             0.0             0.0             0.0   \n",
              "4                   0.0             0.0             0.0             0.0   \n",
              "...                 ...             ...             ...             ...   \n",
              "2057                0.0             0.0             0.0             0.0   \n",
              "2058                0.0             0.0             0.0             0.0   \n",
              "2059                0.0             0.0             0.0             0.0   \n",
              "2060                0.0             0.0             0.0             0.0   \n",
              "2061                0.0             0.0             0.0             0.0   \n",
              "\n",
              "     현재_직장_근속_연수_5년  현재_직장_근속_연수_6년  현재_직장_근속_연수_7년  현재_직장_근속_연수_8년  \\\n",
              "0               0.0             0.0             0.0             0.0   \n",
              "1               0.0             0.0             0.0             0.0   \n",
              "2               0.0             0.0             0.0             0.0   \n",
              "3               0.0             1.0             0.0             0.0   \n",
              "4               0.0             0.0             0.0             0.0   \n",
              "...             ...             ...             ...             ...   \n",
              "2057            1.0             0.0             0.0             0.0   \n",
              "2058            0.0             0.0             0.0             0.0   \n",
              "2059            0.0             0.0             0.0             0.0   \n",
              "2060            0.0             1.0             0.0             0.0   \n",
              "2061            0.0             0.0             0.0             1.0   \n",
              "\n",
              "      현재_직장_근속_연수_9년  \n",
              "0                0.0  \n",
              "1                0.0  \n",
              "2                0.0  \n",
              "3                0.0  \n",
              "4                0.0  \n",
              "...              ...  \n",
              "2057             0.0  \n",
              "2058             0.0  \n",
              "2059             0.0  \n",
              "2060             0.0  \n",
              "2061             0.0  \n",
              "\n",
              "[2062 rows x 47 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02d78471-d9c0-499b-9dbb-06a7b2501e9f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>연간_소득</th>\n",
              "      <th>체납_세금_압류_횟수</th>\n",
              "      <th>개설된_신용계좌_수</th>\n",
              "      <th>신용_거래_연수</th>\n",
              "      <th>최대_신용한도</th>\n",
              "      <th>신용_문제_발생_횟수</th>\n",
              "      <th>마지막_연체_이후_경과_개월_수</th>\n",
              "      <th>개인_파산_횟수</th>\n",
              "      <th>대출_상환_기간</th>\n",
              "      <th>현재_대출_잔액</th>\n",
              "      <th>...</th>\n",
              "      <th>현재_직장_근속_연수_1년</th>\n",
              "      <th>현재_직장_근속_연수_1년_미만</th>\n",
              "      <th>현재_직장_근속_연수_2년</th>\n",
              "      <th>현재_직장_근속_연수_3년</th>\n",
              "      <th>현재_직장_근속_연수_4년</th>\n",
              "      <th>현재_직장_근속_연수_5년</th>\n",
              "      <th>현재_직장_근속_연수_6년</th>\n",
              "      <th>현재_직장_근속_연수_7년</th>\n",
              "      <th>현재_직장_근속_연수_8년</th>\n",
              "      <th>현재_직장_근속_연수_9년</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.260255</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.113448</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12.838230</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.558693</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>29.0</td>\n",
              "      <td>13.272220</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>13.629639</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.722959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11</td>\n",
              "      <td>26.5</td>\n",
              "      <td>13.811344</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>13.684987</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.267281</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>34.4</td>\n",
              "      <td>13.307443</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.096592</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14.644176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19</td>\n",
              "      <td>25.0</td>\n",
              "      <td>14.485708</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12.893662</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2057</th>\n",
              "      <td>13.456130</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>7.7</td>\n",
              "      <td>11.259542</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12.175655</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2058</th>\n",
              "      <td>14.553829</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15</td>\n",
              "      <td>27.2</td>\n",
              "      <td>14.586588</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.938301</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2059</th>\n",
              "      <td>14.534326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20</td>\n",
              "      <td>26.7</td>\n",
              "      <td>14.113215</td>\n",
              "      <td>0</td>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.840667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2060</th>\n",
              "      <td>15.262377</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18</td>\n",
              "      <td>21.3</td>\n",
              "      <td>12.948619</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.394079</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2061</th>\n",
              "      <td>14.450189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14</td>\n",
              "      <td>16.5</td>\n",
              "      <td>14.024329</td>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>13.418131</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2062 rows × 47 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02d78471-d9c0-499b-9dbb-06a7b2501e9f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-02d78471-d9c0-499b-9dbb-06a7b2501e9f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-02d78471-d9c0-499b-9dbb-06a7b2501e9f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-61af00f0-ffb6-47b7-adb6-92665b9ed3aa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-61af00f0-ffb6-47b7-adb6-92665b9ed3aa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-61af00f0-ffb6-47b7-adb6-92665b9ed3aa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f91f9338-4654-474b-b87c-3fce6db8f873\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f91f9338-4654-474b-b87c-3fce6db8f873 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa2b7f75-b22e-465f-a646-ce56d96303a7",
      "metadata": {
        "id": "aa2b7f75-b22e-465f-a646-ce56d96303a7"
      },
      "outputs": [],
      "source": [
        "# 채무 불이행 '확률'을 예측합니다.\n",
        "result_xgb = xgb_model.predict_proba(X_val)[:,1]\n",
        "result_rf = rf_model.predict_proba(X_val)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auc_score_xgb = roc_auc_score(y_val, result_xgb)\n",
        "auc_score_xgb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET_udmy-zTd1",
        "outputId": "e1027c56-1bfe-4168-f232-021e5c674073"
      },
      "id": "ET_udmy-zTd1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7553349153273649"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auc_score_rf = roc_auc_score(y_val, result_rf)\n",
        "auc_score_rf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khkqqApgzYPJ",
        "outputId": "0a8e26b5-900b-4ac4-d957-965ebb063f0e"
      },
      "id": "khkqqApgzYPJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7544428864200194"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('/content/drive/MyDrive/dacon_project_default_prediction/sample_submission.csv')\n",
        "\n",
        "# 결과 저장\n",
        "submit['채무 불이행 확률'] = preds_xgb\n",
        "submit.to_csv('/content/drive/MyDrive/dacon_project_default_prediction/submission_xgb.csv', encoding='UTF-8-sig', index=False)"
      ],
      "metadata": {
        "id": "RC1RaJzGsRl4"
      },
      "id": "RC1RaJzGsRl4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('/content/drive/MyDrive/dacon_project_default_prediction/sample_submission.csv')\n",
        "\n",
        "# 결과 저장\n",
        "submit['채무 불이행 확률'] = preds_rf\n",
        "submit.to_csv('/content/drive/MyDrive/dacon_project_default_prediction/submission_rf.csv', encoding='UTF-8-sig', index=False)"
      ],
      "metadata": {
        "id": "zfD_swsRsUF1"
      },
      "id": "zfD_swsRsUF1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import plot_importance\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# 1. 한글 폰트 설정\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "plot_importance(model, max_num_features=10, importance_type ='gain')\n",
        "plt.rcParams['figure.figsize'] = (40,10)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "UJW-_jN-DrXA",
        "outputId": "0a28bb04-12fa-4d45-ea18-8089ccae73cf"
      },
      "id": "UJW-_jN-DrXA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 4000x1000 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAADNQAAANWCAYAAACMVDCRAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Xm812P+P/7H6Zw67YXIUCNLlo+k7EZDtsYwZR/G2Bk0hCG7SLQwyBhjGYzQR8xYsmXJ2mSyjn1EKEIbSlKdzumc3x/9en8c57SY78xkvO/32+1907mu63W9nq/X+6Trdt7n8bpKampqagIAAAAAAAAAAAAAAABFosGKLgAAAAAAAAAAAAAAAAD+kwRqAAAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVgRoAAAAAAAAAAAAAAACKikANAAAAAAAAAAAAAAAARUWgBgAAAAAAAAAAAAAAgKIiUAMAAAAAAAAAAAAAAEBREagBAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFQEagAAAAAAAPjO2X777bPjjjuu6DIAAAAAAIDvKYEaAAAAAACA77DDDz88JSUl9b423HDDFV3ev83HH3+cjz76aEWXAQAAAAAAfE+VregCAAAAAAAAWLq2bdvmscceq9NeXl7+Lz3PpEmTsvbaa+fJJ59M9+7d/6Vzf1uvvfbaCj3/P+Opp57KjjvumIkTJ6ZDhw4ruhwAAAAAAGApBGoAAAAAAAC+48rKytKpU6cVXcZ/VLNmzVZ0CQAAAAAAwPdYgxVdAAAAAAAAAP/vHn300XTr1i1NmzZN69ats88+++T9998v9M+ZMye/+93vstlmm6VJkyZZZZVV0qtXr0yaNClJ0r1796y99tpJkh133DElJSU5/PDDC32L//x1hx9+eK2dbLp3754DDjgg11xzTdq3b5+SkpI89dRTy1XfN3Xv3j3dunWr9fUvfvGLPPzww9lkk03StGnTbLPNNhk/fnyqqqpy+umnp02bNmnVqlWOO+64VFVVFY7t0KFDDjnkkDzwwAPp1KlTysvL07Fjx1x55ZW1zjl//vz069cva6+9dsrLy7P22mvnvPPOS0VFRWHMsGHDUlJSkhdeeCHdunVLw4YNc/jhh6dDhw7ZcccdkyRrr712SkpK0r9//yTJ5MmT07dv36y33nopLy9Pu3btcuKJJ2bu3LlJFu0MVFJSkgcffDCDBw/OD3/4wzRu3DjbbrttXn311Vo1VlVV5ZJLLsnGG2+cxo0bp3379jnyyCPz8ccfJ0m++OKL/OY3v0m7du1SXl6eDTbYIFddddUS7zMAAAAAABQrO9QAAAAAAAD8l7vjjjty0EEH5aijjsqgQYMye/bsnHfeedl+++3z+uuvZ6WVVsoDDzyQa6+9NieddFK22GKLfPbZZ+nTp09+8YtfZNy4cbnpppsyYcKE/OQnP8mf/vSnbLnllllppZW+dS2PP/54Xn755Vx99dVp3rx5OnbsuFz1LY+///3vefLJJzN06NCsscYaOfHEE3PkkUemS5cueeeddzJy5MiMHz8+v/71r7PRRhvlpJNOKhw7duzYPP7447niiiuy+uqr549//GNOOumkNGvWLEcddVSSZP/998/YsWMzZMiQdO7cOa+++mrOPPPMvPbaaxk5cmStWnr16pWTTjopl19+eSorK3P22WfnmWeeyZFHHplHHnkka6yxRlZbbbUkycCBA/P+++9nyJAhWWeddfLmm2/mmGOOSbNmzTJ48ODCnGeeeWZKSkpy7bXXpkmTJjnnnHNy0EEH5c0330yS1NTUZP/9988DDzyQ/v37p0ePHpkxY0buu+++PP744/n5z3+enXfeOZ9++mkGDx6c9dZbL4888kh+85vfZO7cuTn99NO/9fsJAAAAAADfVwI1AAAAAAAA33Eff/xxysrqfqxz1FFHZejQoTn++OPzq1/9Ktdee22hr2vXrllnnXXypz/9Kaeeemp22mmn7LPPPmnUqFFhzCmnnJLevXvnyy+/LOyqkizaYaVTp07/VK2zZ8/Oc889l3XXXTdJMnfu3OWqb3m88847eeqpp7LDDjskSc4777zst99+mTlzZl577bU0bNgw3bp1y7333psHHnigVqBm0qRJefHFF7P55psnSbbffvu8++67GThwYI488sg8/PDDeeCBB/L4449np512SpJsu+22WWeddfKTn/wkDz/8cHbbbbfCfL17986ZZ55Zq75PPvkkSbL++uunQ4cOhfZzzz037dq1K3y92Wab5cEHH8zo0aNrBWpmz56dN998M82bN0+SDB06NNtss01ee+21dO7cOX/+858zcuTI3HTTTbV2DNp9991TVVWVyy67LG+99VZee+21wv3fdttt8+mnn2bIkCE55ZRT6v0+AgAAAACAYuQn5gAAAAAAAN9xbdu2zWOPPVanfeWVV87o0aPz2Wef5cQTT6zVt+aaa2b99dfPs88+mySF3VIqKiry1ltv5Z133in0zZw5My1atPiX1LrtttsWwhxJlru+5dGlS5dCmCZJNthggyTJcccdl4YNG9Zqf+CBB+rUtThMs9jBBx+cPn36ZOrUqbn//vuz2mqrFcI0i/Xo0SOrrrpq7rvvvlqBmkMOOWS5614cppk1a1b+8Y9/ZMKECZk8eXI+//zzWuNOOumkQpgmSf7nf/4nSfLBBx+kc+fOuf3227PmmmvWe+6ysrLcfvvt2WOPPWrd/yTZcccd84c//CFvv/12Nt544+WuGwAAAAAAvs8EagAAAAAAAL7jysrKlrhjzNtvv50k6dy5c52+hQsXZtVVV02yKDRz8skn56677kpFRUXWWmuttGzZMklSXV39L6t1rbXW+qfqWx4bbbRRra8Xh0/qa6+oqKjVtjh8U1+tkydPzvvvv1+n9q+PmzhxYr3HLo8333wzJ5xwQv7617+mvLw866yzTubNm1fnvn8z7LI45LQ4ePP222+nc+fOKS0trfc8b7/9dl599dU6u9DU1NQkST777LPlrhkAAAAAAL7vBGoAAAAAAAD+iy0OSzzzzDNp1qxZnf7Fbfvss0/Gjx+fO+64Iz169EjDhg3z1FNPZccdd1zmOUpKSuptr6ysrNPWoEGDf6q+5dGoUaPlbl983sXKy8vrjJk3b16SRTWXlJRkwYIF9c5fX/s3r3NJPv/88+ywww5Zf/318+KLL6ZLly5Jkv79+2fYsGHLrDH5v2uprq5eYphm8bhDDjkkp512Wr39a6+99nLVDAAAAAAAxUCgBgAAAAAA4L/YOuuskyRp0qTJEnexef/99/PUU0/luuuuyx577FFonzx58nKdY+WVV87s2bPrtI8fP76wi8r/S33/CbNmzarT9t577yVJ1l133ayzzjp5/vnnU1NTUytAVF1dncmTJ6dbt27/1HlHjhyZzz77LMOGDcv6669faF/ee/91a621Vt56660l9q+zzjr58ssvV+h9BgAAAACA/xbL9+gsAAAAAAAAvpN69OiR5s2b5w9/+EOdvurq6nz55Zf54osvkiwKxixWU1OT6667rtb4srKywnFft+666+a1116r1fa3v/0tf//73/8l9f0nPPnkk7VCQdXV1bnllluy9dZbZ6WVVsqee+6Zzz//PKNGjap13P3335+ZM2dmzz33XOY56rt/9d37adOm5Z577vnW17DXXnvlvffeq/fYefPmZZ999slDDz2UiRMn1ulfXAcAAAAAALCIHWoAAAAAAAD+i7Vq1SqXXXZZjjvuuFRUVOQXv/hFWrRokTfffDPXXXdd+vfvn1122SVt27ZN//7906JFizRu3DiDBg3Kxx9/XGuutm3bpnHjxrnlllvy5Zdf5pVXXsn555+fww47LJdeemlOPvnkHHDAAXnjjTfSr1+/rL322v+S+n72s5/9u25PwWeffZaf/OQnOffcc7PSSivliiuuyIQJE/Loo48mWRT82XPPPXPwwQdnyJAh2XTTTfPqq6/mjDPOyF577ZUePXos8xxrrbVWkuTaa6/Ntttum/fffz877rhjGjRokGOPPTZ9+/bN1KlTc9ppp6VVq1apqan5Vtdw9NFH5/bbb88vfvGL9O/fPzvvvHM+//zz3HPPPdloo41y2mmn5c4778yPf/zj9O/fP5tssklmzJiRJ554Ii+88EL++te/fvsbBwAAAAAA31N2qAEAAAAAAPgvd8wxx+Tee+/NhAkTss8++2S33XbLFVdckV122SU77LBDGjdunPvuuy+tW7fOPvvsk4MOOihbbbVVrrjiilrzNGzYML/73e8yevToHHjggXn++eeTJBtvvHFuvvnmPPDAA+nevXuuvvrqDBs2LFtuueW/pL7/hP322y/dunXLEUcckZ122imTJk3Kgw8+mJ122qkw5o477sivf/3rDBo0KNtvv30GDx6cPn365Pbbb1+uc7Rv3z7nn39+brrpphx88MGZMGFCNttss9x000158803s+OOO+bcc89N//798/Of//xbX0PDhg3zyCOP5Oyzz86wYcMK1zNz5szsu+++admyZZ555pnstdde6d+/f7bffvsce+yxefPNN3PBBRd86/MBAAAAAMD3WUnNt330FQAAAAAAAPwX6dChQ7p165bhw4ev6FIAAAAAAIDvCDvUAAAAAAAAAAAAAAAAUFQEagAAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUlZKampqaFV0EAAAAAAAAAAAAAAAA/KfYoQYAAAAAAAAAAAAAAICiUraiC4Bvq7q6Op988klatGiRkpKSFV0OAAAAAAAAAAAAAADwHVBTU5Mvv/wya6yxRho0WPoeNAI1/Nf55JNP0r59+xVdBgAAAAAAAAAAAAAA8B00efLktGvXbqljBGr4r9OiRYskycSJE7Pyyiuv4GoAgBWpsrIyjz76aHr06JGGDRuu6HIAgBXEmgAAWMy6AABIrAkAgEWsCQCgOM2ePTvt27cv5A6WRqCG/zolJSVJFgVrWrZsuYKrAQBWpMrKyjRt2jQtW7b0wy8AKGLWBADAYtYFAEBiTQAALGJNAADFbXHuYGka/AfqAAAAAAAAAAAAAAAAgO8MgRoAAAAAAAAAAAAAAACKikANAAAAAAAAAAAAAAAARUWgBgAAAAAAAAAAAAAAgKIiUAMAAAAAAAAAAAAAAEBREagBAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFQEagAAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFYEaAAAAAAAAAAAAAAAAiopADQAAAAAAAAAAAAAAAEVFoAYAAAAAAAAAAAAAAICiIlADAAAAAAAAAAAAAABAURGoAQAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBUBGoAAAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBWBGgAAAAAAAAAAAAAAAIqKQA0AAAAAAAAAAAAAAABFRaAGAAAAAAAAAAAAAACAoiJQAwAAAAAAAAAAAAAAQFERqAEAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVARqAAAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVgRoAAAAAAAAAAAAAAACKikANAAAAAAAAAAAAAAAARUWgBgAAAAAAAAAAAAAAgKIiUAMAAAAAAAAAAAAAAEBREagBAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFQEagAAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFYEaAAAAAAAAAAAAAAAAiopADQAAAAAAAAAAAAAAAEVFoAYAAAAAAAAAAAAAAICiIlADAAAAAAAAAAAAAABAURGoAQAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBUBGoAAAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBWBGgAAAAAAAAAAAAAAAIqKQA0AAAAAAAAAAAAAAABFRaAGAAAAAAAAAAAAAACAoiJQAwAAAAAAAAAAAAAAQFERqAEAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVARqAAAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVgRoAAAAAAAAAAAAAAACKikANAAAAAAAAAAAAAAAARUWgBgAAAAAAAAAAAAAAgKIiUAMAAAAAAAAAAAAAAEBREagBAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFQEagAAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFYEaAAAAAAAAAAAAAAAAiopADQAAAAAAAAAAAAAAAEVFoAYAAAAAAAAAAAAAAICiUlJTU1OzoouAb2P27Nlp1apV1j31jlSVNVvR5QAAK1B5aU0u2WphTn++NBULS1Z0OQDACmJNAAAsZl0AACTWBADAItYE8N02acgeK7oEluH5559P//798+KLL6a0tDQbbbRRLr/88nz00Uc5+uij64z//PPP88c//jGHH354nb6ZM2dm4MCB+fOf/5wFCxakVatWOfHEE3P88ccnSaZNm5bzzjsvDz/8cCoqKtKyZcscdthhOfvss1NSUvv/4QsWLMhWW22VWbNmZdKkSXXOtaT+O+64I4MHD84nn3yS5s2bp2/fvvn1r39d6L/yyitz/fXX59NPP015eXl23nnnDB48OKuttlqS5LHHHku/fv3y3nvvpVGjRvnVr36Vfv36pUGDBjnkkEMyevToWnUsXLgwn376aWpqanL22WfnT3/6U51ap02blokTJ6ZDhw5Jkvfeey99+/bNs88+m8rKynTs2DHjxo0rjJ8+fXpOP/30jB49OgsWLEi7du0yevTotGnTJkkyb968HH/88bnpppsyevTo7LLLLrXOV1VVlf79+2fgwIG5/vrra72Py3oPvvzyywwYMCD33HNP5syZkyZNmmSfffbJoEGDUl5eXufaVqTFeYMvvvgiLVu2XOpYO9T8h8yZMyclJSWZNGlSXnnllTp/sRfr0KFDGjduXHj16dPnP1bj4mzVpEmTUlJSklmzZtUZM3PmzIwcObJW2/jx4/Pcc88Vvj788MNz8skn1xozf/78XHTRRenatWuaN2+esrKyrLzyyunevXvuuOOOf/WlAAAAAAAAAAAAAADwTzr99NPTu3fvTJkyJR9//HG23nrr7LnnnvnZz36WqVOn1nq9/fbbadKkSTbbbLN65/rd736Xli1b5pVXXsnUqVMzYsSInHbaaXniiSeSJGPGjMm6665b6B81alSuvvrqXHPNNXXmGjBgQFZaaaUl1l1f/0MPPZSjjjoqV1xxRaZPn54nnngi1157be6+++4kyS233JLzzz8/1113XaZMmZIXX3wxH374YQ455JAkyauvvpqePXvmlFNOybRp0/Lyyy9nzJgxGTp0aJLk1ltvrXNPLr744nTt2jVJMmjQoDr9t912W1ZfffWsscYaSZLJkydnxx13zG677ZbJkydnxowZufjiiwvXMHv27Oywww5ZZ5118t5772XGjBm58cYbC2GWuXPnZuONN17qvdl2220zefLktG3btk7fst6D1157LaWlpRk7dmymTp2acePGZfTo0enXr98Sz/ffQKDmX2xxGOXrr28GUOpz/vnnp02bNpkzZ06aN2+e5s2bp2XLlhkxYkTatWuX+fPnL/X41q1b1znv119Tp04tjD311FNTVlZW61VSUpIxY8Yss8633347e++9d62222+/PYMHD17qcccee2xuueWWXHbZZZk6dWoWLFiQ8ePH58ADD8yhhx6aP//5z8s8NwAAAAAAAAAAAAAA/36PPfZYevbsmdLS0sIuLB9++GGmTZtWZ+w111yTbbbZJp07d653rnPPPTfnnXdeVl555STJZpttlk6dOuWFF15Ikuy///45/fTTC2GQ9dZbL1tttVXeeOONWvO88MILuffee3PGGWfUe54l9Q8fPjwHHnhgunfvnmTRJhj9+/fPVVddlSQZN25cunfvnh/96EdJkjZt2uSYY44p7A7z5z//Odttt13233//lJSUZNVVV81vf/vb/OEPf6i3jpqamlx66aU57bTT6u1PkksuuSQnnnhiGjVqlCQ5++yz06dPnxx77LGF3+/ffvvtC+N/+9vfZqeddsp5552Xxo0bF+5jixYtkiTl5eUZM2ZMLrvssiWe884778zNN99cOP7rlvUebLfddhkyZEhWX331JMnqq6+enXfeuc579N9GoObf5KOPPsq8efMyb9689OrVa5nj+/Xrl48++igfffRRPv7440ycODHHH398SktLc+ONN9b7TftNd955Z2bOnFnr9eqrr9YZN3jw4MyaNSuzZs3K7Nmzc9VVV2X11Vcv/A/g32H8+PHZdddds9NOO6V58+Zp0KBBVltttRx++OFZc801849//OPfdm4AAAAAAAAAAAAAAJZfWVlZra/HjRuXtm3bpk2bNrXaKyoqcuWVV6Zv377LPdfMmTPz9ttvp1OnTnXGVlVVZdSoURk7dmwOOOCAQvv8+fNzxBFH5Prrr6/3d+uX1j9v3rxCcOXrdS/+Hfb99tsvY8eOzWOPPZaampp89NFH+cMf/pCDDz54qcdPnDix3o0z7r///sydOzf7779/vffjtddeyzPPPJPjjjsuSVJZWZm77747m2yySX70ox9ltdVWS/fu3fPmm28WjhkxYkS6d++eXXfdNW3bts0WW2yRsWPHFvpLS0vTrl27es+32FprrbXU/sWW9B4sVl1dnb/97W+566678stf/nK55vyuEqj5NykvL0/jxo3TuHHjNGiw7NtcVlaWxo0bZ8KECRk4cGDWW2+99O/fP0cccUQ22WST5Tpno0aNCudc/Fq8hdM3xy3eBWfGjBnp379/hg4dmscffzwlJSVZe+21v/X1LsvFF1+cu+66K1tvvXWOPfbYnHzyyTn00EPTsWPHrLrqqundu/e//JwAAAAAAAAAAAAAAPy/effdd9O3b99ceumlKS0trdV36623ZrXVVsuuu+66XHPV1NTksMMOy9Zbb5099tijVt/DDz+cpk2bZr/99svFF1+cHXbYodB3zjnnZLfddss222xT77xL6+/Zs2dGjBiRcePGpbq6Om+88UauuOKKfP7550mSnXfeOTfddFP22WefNGnSJO3bt0/Hjh0LO9j07Nkzjz32WB544IEsXLgwH3zwQS688MIkKczxdZdccklOPvnkOkGir/cfddRRhd1gJk+enJqamgwdOjQjRozIpEmTsu2222annXbK7NmzU1lZmYkTJ+b3v/99hg4dmsmTJ+eII47Irrvumg8++GBZt/xbWdp7kCRvvvlmmjZtmu233z7HHHOMQA3fTkVFRRYsWFCrbfz48enZs2fat2+fbbfdNlOmTMmDDz6YkSNH5pVXXslaa62VDTbYIPfff/9S5+7Vq1eaNGlS67XhhhsucfwHH3yQXXfdNWVlZZk2bVp69OiRefPmZfz48cu8jpKSksLrggsuWOb47t2758MPP8zQoUOzww47ZNNNN02vXr3y8MMP57nnnkvbtm2XOQcAAAAAAAAAAAAAAP85M2fOTK9evXLEEUcUdmxZrKamJpdeeulSd6f5prPOOivjx4/PbbfdVqdvt912y1dffZUHHnggZ555ZoYNG5YkGTt2bEaNGlUIsXzTsvoPP/zw9O/fP8cdd1zWXHPNnHHGGTn22GPTokWLJMnjjz+eI444IiNGjMicOXPy3nvvZcKECTn22GOTJDvuuGOGDRuWCy64IO3atcthhx2Wo446KkkKcyw2bty4vPnmmzn66KPrreXDDz/MXXfdld/85jeFtqlTp2bevHm56KKLstZaa6Vp06a58MILU11dnfvvvz8zZsxIdXV1+vTpk06dOqVRo0Y5/vjjs+GGG2b48OFLudvf3pLeg8U23njjfPXVVxk3blxuvvnm5coSfJfVH3ni36a+gMu6666b3XbbLWeffXa6du1a2GJqiy22yJ577pkvvvgiTz31VLbbbrslzjtr1qzCn/v27Zt33303I0eOrHfswoULc8stt6Rv3745//zzc/DBB2ennXbKc889l6FDh9a7q83XlZaWZs6cOYWvhwwZkldeeaXesfvvv38eeuihpc73ddddd12dlFpFRUUqKioKX8+ePTtJUt6gJqWlNcs9NwDw/VPeoKbWfwGA4mRNAAAsZl0AACTWBADAItYE8N1WWVm5oktgOcyZMye77bZbunbtmiFDhtR53+69997MnTs3++6773K9p5dddlmGDx+eJ554Iq1atVriMT/+8Y9z7LHH5qqrrsq+++6bI444IjfccEPKyspSWVmZqqqqJIu+j+bPn7/U/sV+/etf59e//nXh66uvvjqdO3dOZWVlLrzwwhx99NHp0aNHampq0r59+1x77bXZaKON0rdv36yzzjrZf//9s//++xeOf/DBB7P22muncePGtc4zePDg/OpXv0p5eXm913fppZemV69eWWONNQr9TZo0SUlJSTp16lTrmB/+8IeZNGlSmjRpkiSFehdbe+2188EHH9R7nqqqqqW+JwsXLlxq/9ffg/p2oenSpUvOPPPMnHnmmTn77LOXOM+K8G3+/yJQ8x82ceLEzJo1K127dk2SXHHFFTnzzDPrjKuoqEijRo1SUlJSq/2QQw7J9ddfX/i6efPm+eqrr+o91zePTZJXX301PXv2TNOmTXPPPfdk++23T5KMGTMmJ5xwQgYMGJDTTjttmdexOPSTZIlbUSXJHXfckerq6iTJqFGjcswxx2Tq1KlJkqeeeiq77bZbrXDON7cASxb9T6W+5Nq5XavTtOnCZdYKAHz/XbhF9YouAQD4DrAmAAAWsy4AABJrAgBgEWsC+G4aNWrUii6BZaioqMiAAQPSokWL7LvvvvVustCvX7/svPPOefTRR5c536hRo3LHHXdk4MCBeeutt/LWW28V+hYuXFjn98gnTpyYL7/8Mrfffns+/PDD7L777oW+6urqVFRUpHXr1unVq9dS+w855JD89Kc/rTV3dXV1Lr/88uy+++4ZNWpUPvjgg7Rr167W9+Xnn3+eZFFwZt11161zPRdeeGG6du1a65iPP/44jzzySPbee+96v8fnzJmT66+/PhdddFGt/srKyjRp0iQ33XRT1lxzzULbhAkT8tlnn2XMmDFZY401MmLEiEIOIUleeuml/PjHP673XM8//3ytTS2+bu7cuXn99ddrHbe092DUqFH19r/55pupqqr6zv19njt37nKPFahZwU4++eScfPLJtdrmzJmTFi1a5LnnnkuXLl2Wevxnn32WmprlT0+Xl5fn+uuvz0477VQrCNOyZcvccsstqampyaxZs3LGGWfUCs38sxo0aJAGDRoU/lyfpQVykkXbep1yyimFr2fPnp327dvnopcbpKph3QAOAFA8yhvU5MItqtPvxQapqK4bJgYAioM1AQCwmHUBAJBYEwAAi1gTwHfbG/1/sqJLYCkWLFiQffbZJ2ussUbuueeeNGrUqM6YZ555JlOmTMlll12WFi1a1Oo744wz8vHHH2f48OFJkltuuSV33nlnRo8eXe/vx//qV7/KNttskwMPPDDNmjXLq6++mscffzxnn312Dj/88Bx++OG1xj/99NM5+uijM2HChML8S+ufOnVqvvrqq6y77rqZNWtWTjvttKy22mq59NJL06hRo7z44ov54x//mOOOOy5bb711Pvvssxx77LFZb731cuyxx2bBggV57733summm2bu3LkZMmRIZs6cmYceeigrrbRS4bzHHntsfvGLX+Tggw+u974OGjQo22yzTU488cQ6fYceemjuuuuujBgxIk2aNMm5556btm3bZsCAASkvL0+fPn1y22235bDDDsvqq6+eq666KnPmzMkll1ySVVddtc58W221VXbeeed662jatGk22WSTWiGkpb0Hu+++e84555y0bt06Rx99dFZaaaVMnDgxZ555Zo488sha83wXzJ49e7nHCtT8m8ybNy+TJ0/O1KlT8/rrry8zGNO/f/86u7B8PT225557ZuTIkXWOKy8vT01NzRLTY18ft3jHmh49euSjjz5K+/btl3rMmWeeWW+oZuHChXV2v9lzzz2XOlePHj0yZsyYJKkzZ4MGDXL55ZfXCRZ9vfby8vI67RXVJalaaJELACxaF1RYFwBA0bMmAAAWsy4AABJrAgBgEWsC+G5q2LDhii6Bpfjb3/6WRx99NCuvvHKd3VmGDx+eXXbZJUOHDs0xxxyTlVdeuc7xkyZNyqRJkwrv80UXXZR58+alZ8+etcb17Nkz119/fc4444xceOGFueiii1JVVZWVV145Z511Vk444YQ6v7ee/N+GDkv6Pvpm/5dffpl99tknn3/+eRo1apS99torjz/+eJo1a5Zk0e/yN2vWLEcffXQ+++yzVFdXZ9ddd82jjz6aZs2aZd68eTnqqKPyySefpKysLDvvvHOeeeaZrLbaaoVzTp06NSNGjMiLL75Yb13z58/P1VdfnZtuuqne/ssvvzx9+/ZNp06dsmDBgnTr1i2jR49O8+bNkySnn3565s6dm+222y5z585N586d8+STT2aNNdZY4j1Y2t+z0tLSWv3Leg9OOumkXHDBBdlqq60yb968tGzZMgcddFDOOeec79zf529TT0nNt9nehGWaNGlS1l577ZSUlKRJkyZZc801s8kmm+Scc87J5ptvnokTJ2bWrFnp2rXrcu8s079//7zyyiv1BmqS5MUXX8yWW2651Dlef/31dOrUqVbb/Pnz6x37wQcfZMMNN8zMmTPTunXrOv1VVVV12r6+E83hhx+e1q1b54orrlhqTYt17949e+211xIDNd80e/bstGrVKuueekeqypot1zEAwPdTeWlNLtlqYU5/vtQPvwCgiFkTAACLWRcAAIk1AQCwiDUBfLdNGrLHii4B+J5anDf44osv0rJly6WOtUPNv1iHDh3qDcrMmTNnqcf1798/gwYNStOmTevt32OPJf+jscUWWywxnDN//vw0adKk3r76dp9JUu9uMF+3OLH3bXTv3j3jxo1bYtrr5z//+beeEwAAAAAAAAAAAAAA4J8hUPMd0qtXr9x5550ruox/m8suuywnnHDCii4DAAAAAAAAAAAAAAAocg1WdAH8n7vvvjtlZWVLfC1cuPA/UkfLli1z0kknLXOnmm/rpJNOWuK1de/e/V96LgAAAAAAAAAAAAAAgCUpqampqVnRRfDvU1NTkw8++CBrrrlmGjZsuKLL+ZeYPXt2WrVqlU8//TSrrLLKii4HAFiBKisrM2rUqOy+++7fm7UOAPDtWRMAAItZFwAAiTUBALCINQEAFKfFeYMvvvgiLVu2XOrYsv9QTawgJSUl6dChw4ouAwAAAAAAAAAAAAAA4DujwYouAAAAAAAAAAAAAAAAAP6TBGoAAAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBWBGgAAAAAAAAAAAAAAAIqKQA0AAAAAAAAAAAAAAABFRaAGAAAAAAAAAAAAAACAoiJQAwAAAAAAAAAAAAAAQFERqAEAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVARqAAAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVgRoAAAAAAAAAAAAAAACKikANAAAAAAAAAAAAAAAARUWgBgAAAAAAAAAAAAAAgKIiUAMAAAAAAAAAAAAAAEBREagBAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFQEagAAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFYEaAAAAAAAAAAAAAAAAiopADQAAAAAAAAAAAAAAAEVFoAYAAAAAAAAAAAAAAICiIlADAAAAAAAAAAAAAABAURGoAQAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBUBGoAAAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBWBGgAAAAAAAAAAAAAAAIqKQA0AAAAAAAAAAAAAAABFRaAGAAAAAAAAAAAAAACAoiJQAwAAAAAAAAAAAAAAQFERqAEAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVARqAAAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVgRoAAAAAAAAAAAAAAACKikANAAAAAAAAAAAAAAAARUWgBgAAAAAAAAAAAAAAgKIiUAMAAAAAAAAAAAAAAEBREagBAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFQEagAAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFYEaAAAAAAAAAAAAAAAAiopADQAAAAAAAAAAAAAAAEVFoAYAAAAAAAAAAAAAAICiIlADAAAAAAAAAAAAAABAURGoAQAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBUBGoAAAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBWBGgAAAAAAAAAAAAAAAIqKQA0AAAAAAAAAAAAAAABFRaAGAAAAAAAAAAAAAACAolK2oguAf9bWgx9PVVmzFV0GALAClZfW5JKtkk79H0nFwpIVXQ4AsIJYEwAAi1kXUJ9JQ/ZY0SWwHCZPnpx99903L7zwQiorK1NW9n8fZU+fPj2nn356Ro8enQULFqRdu3YZPXp02rRpU2eemTNnZuDAgfnzn/+cBQsWpFWrVjnxxBNz/PHHF8ZcddVV+cMf/pBPP/00q666agYMGJD99tuv0P/EE0/klFNOyZQpU9K6desMGDAgBxxwQJ1zLViwIFtttVVmzZqVSZMmFdpfffXVHH/88XnnnXfSrFmz/OY3v8mJJ55Y69gxY8Zkv/32y/rrr5+xY8cu8b707t071157bSZOnJgOHTokSTp06JCvvvoqpaWlhXF77bVXrr322iTJo48+mosuuijvvvtuGjRokM6dO2fgwIHp2rVrrrnmmlxwwQV1zjNjxow8/vjj6d69e632O+64IwceeGBuuummHH744UmS6urqnHfeeRk2bFgWLFiQzTffPNdcc02hvo8//jj9+/fPgw8+mOrq6qy22mrp169f9t9//yTJu+++m/PPPz9PP/10Fi5cmFVWWSV9+vTJscceW6eumTNnplOnTunYsWOeeuqpJd4nAAAAAPhn2KHmP2TOnDkpKSnJpEmT8sorr6SkpP4PcTp06JDGjRsXXn369Pl/Ou+kSZNSUlKSWbNm1WofNGhQmjdvXnhtsMEGhb6TTz658MPQ5VVTU1P48+GHH56TTz55ucd36NAhI0eO/FbnAwAAAAAAAL4fnnvuufzoRz9Kly5d6vTNnj07O+ywQ9ZZZ5289957mTFjRm688caUl5fXO9fvfve7tGzZMq+88kqmTp2aESNG5LTTTssTTzyRJLnmmmsyaNCg3H777ZkxY0Zuv/329O3bNy+88EKS5P3330/Pnj1z/vnnZ9q0aRk2bFiOOuqoPPPMM3XONWDAgKy00kq12mbNmpUePXrk5z//eaZPn56HH344AwcOzIgRIwpjrrzyyvTu3TvbbrvtUu/L6NGj8/bbb9fb98ILL2Tq1KmF1+IwzbvvvpuePXvmoIMOyscff5z3338/m2yySXr06JEvv/wyvXv3rnXc1KlTM3bs2DRu3Dj/8z//U+sc06ZNS79+/dK5c+da7RdffHHuvvvuvPjii5kyZUr+53/+J3vssUeqqqqSJBdeeGE23XTTvPPOO5k6dWqGDBmSgw46KO+8806S5OGHH86OO+6Yt99+O1OmTMlNN92UU089NaNGjapznX369Mn666+/1PsEAAAAAP8sgZp/scUBlq+/licscv7556dNmzaZM2dOIeTSsmXLjBgxIu3atcv8+fOXOcchhxySo48+ernqPPvsszNnzpzCa0k/iP2mp59+OmVlZbVeDRo0yGabbbbEY3beeeda40tLS9OgQYNMmTJluc4JAAAAAAAAfH+tt956eeutt3LQQQfV6fvtb3+bnXbaKeedd14aN26cJNlss83SokWLeuc699xzc95552XllVcujO3UqVMhMDN8+PD8+te/zqabbpok6dy5c0488cRcc801SZJrr7022223Xfbee+8kybbbbpsDDzwwV155Za3zvPDCC7n33ntzxhln1Gq/7bbbCrviJMkGG2yQPn365IorriiM2XvvvfP666+na9euS7wnX3zxRY4//vhCXcvrpZdeStOmTXPcccelpKQkjRo1St++ffPpp59mwoQJ9R5z6aWX5uCDD85qq61Wq/2YY47JOeecUys0VFNTk9/97nc599xzs/rqq6e0tDQXXXRRPvzww4wePTrJoh2ATjjhhDRv3jxJsvvuu2ellVbKyy+/nCQ54YQTcvTRR6dZs2ZJki233DIdO3bMG2+8Uev899xzTz755JMceuih3+oeAAAAAMDyEqj5N/noo48yb968zJs3L7169Vrm+H79+uWjjz7KRx99lI8//jgTJ07M8ccfn9LS0tx4442FHw4vzZQpU7LOOussdczEiRPTunXrJb7q297767p165ZZs2YVXl9++WX69u2bjh07LvGYBx54oNb4G264Iauttlp+8IMfLPOaAAAAAAAAgO+3VVZZpRC++KYRI0ake/fu2XXXXdO2bdtsscUWGTt27BLnKisrq/X1zJkz8/bbb6dTp05Jknnz5qVRo0a1xlRUVOQf//hHkuTZZ5/NdtttV6t/u+22y7PPPlv4ev78+TniiCNy/fXX1/kcd0nH//3vf09lZWWSpH379mnQYOkf1Z988sn51a9+lQ022GCp475pxx13TJMmTTJ06NAsWLAgX331VS666KJ06dIlG2+8cZ3x06dPz6233ppTTz21VvvNN9+cqqqqHHbYYbXaJ06cmGnTptW6xiZNmmSzzTYr3KNvvgcTJkzI559/Xu/5KyoqMnz48HzwwQfZa6+9Cu0zZszIqaeemhtvvDElJSXf6h4AAAAAwPIqW/YQ/hnl5eXLFYJZbPHuLa+//nr+8pe/5Lrrrsv06dNzxhlnZJNNNlnm8R9++GFee+21lJeXp7q6us4PYBc/NWjmzJmZNWtW3n333YwcOTJTpkxJixYt0q1bt+yyyy5JFv1wdklKS0vr/DD7mWeeyc9//vMlHtOkSZNaX997773Zc889l3lNAAAAAAAAQPGqrKzMxIkT8/vf/z5XX3111l9//Vx//fXZddddM378+Ky11lpLPb6mpiaHHXZYtt566+yxxx5Jkp49e+baa6/NHnvskY022ijPPvtsbrrppsIx06ZNS9u2bWvN07Zt20ybNq3w9TnnnJPddtst22yzTZ566qlaY6dNm1Zn55m2bdumqqoqn332WVZfffVlXvf999+ft956KzfccMMSx3Tr1i0VFRVZddVVs+uuu+bss89O27Zts9pqq+Xpp5/OHnvskTPOOCMLFy7MlltumUcffTTl5eV15rnyyiuz6667Zv311y+0ffTRRzn//PPzzDPP1Bm/+D4s6x4tNn/+/Bx00EE54ogjCqGmxf74xz+md+/eadWqVW699dZaNfTu3TunnHJK1l577Tz99NNLvA8AAAAA8P/CDjX/YRUVFVmwYEGttvHjx6dnz55p3759tt1220yZMiUPPvhgRo4cmVdeeSVrrbVWNthgg9x///31zllZWZljjjkm5557bnbbbbccfPDBmT9/fq0xkyZNysyZM9OqVau88sor2XLLLdO0adPsu+++6dq1a37zm99k0KBBhfELFizIrFmzUlFRsdTreeedd/L8889nn332Wa7rf/LJJ/Pwww/nlFNOqdW+9957p6SkJCNHjlyueQAAAAAAAIDvtxkzZqS6ujp9+vRJp06d0qhRoxx//PHZcMMNM3z48GUef9ZZZ2X8+PG57bbbCm3nnHNODj744Oy///5p3759fv/73+dXv/pVWrRokSSprq6usyNKgwYNUl1dnSQZO3ZsRo0alQsvvLDecy7p+MV9y/L555+nT58++dOf/pTS0tJ6xzz33HOZPHlypk+fnjvvvDPjx49Pjx49UlVVlSlTpmSXXXbJkUcemVmzZuXzzz/PlltumV133TVz586tNc9XX32Va665Jn379q3VftRRR6Vfv35Zc801672+JEu9R4vV1NTkyCOPTKNGjfL73/++zlzHHHNM5s6dm+uvvz6/+MUv8thjjyVJbrvttsyYMSPHH3/8Mu4WAAAAAPy/sUPNf9iGG25Yp23dddfNbrvtlrPPPjtdu3Yt7GyzxRZbZM8998wXX3yRp556qs7W4MmipwMdffTRKS8vT58+fVJSUpJ33nknm222WX7/+99n3XXXTZK0atUqrVu3TrJo2+7S0tJstdVW2XTTTfPpp5/mhz/8YT788MPCvCNGjMiIESPy29/+ts4PUL+uX79+2WuvvdK+fftlXvuTTz6Z/fffPxdeeGGd+zB8+PDsscceadasWZ3jKioqagV7Zs+enSQpb1CT0tKaZZ4XAPj+Km9QU+u/AEBxsiYAABazLqA+lZWVK7oEllNVVVWSRe9ZTU1NmjRpkiTp3Llzrfdx7bXXzgcffLDU9/ayyy7L8OHD88QTT6RVq1aFsSUlJenXr1/69etXGHvGGWdkk002SWVlZVZeeeXMmDGj1tzTp09PmzZt8uWXX+aII47IDTfckLKyslRWVtaqOUlWWmmlfPrpp3WOLykpSYsWLWq1L1y4MDU1NbXaTjjhhBx99NHp2LFjrfbKysrC1yuvvHLhvB07dszVV1+d9dZbLy+88EIeeuihtGvXLqeeemqSpGHDhrnsssvSsWPH/O///m8OP/zwwpzXXnttOnbsmK233row95/+9KfU1NTk0EMPLbTV1NRk4cKFqaysTMuWLZMs2qnmBz/4QWGuzz77LGuttVatmk888cS89tprefzxx1NaWlrv+9WgQYP06tUre+21V6655ppstNFGOeOMMzJ69OjCNdZ3n2BZFn+/+L4BgOJmTQAAxenb/NsvUPMfNnHixMyaNauwzfcVV1yRM888s864ioqKNGrUqM6TfQ455JBcf/31ha+POuqorLHGGrnuuusKY3//+9/ntttuKzxF6Zt69OiRP/zhD7n44oszcuTIbLbZZtlzzz1z0kknFcYcdthhGTZs2FKv5bbbbsuDDz6Yl19+eanjpk2blqFDh+bSSy/NWWedldNOO63OmGbNmhUCP980ePDgXHDBBXXaz+1anaZNFy713ABAcbhwi2U/2REA+P6zJgAAFrMu4OtGjRq1oktgOb3++utJkoceeqiwO8saa6yRESNGFD5fTZKXXnopP/7xj5f43o4aNSp33HFHBg4cmLfeeitvvfXWEs9ZUVGRG264Ib/5zW8yatSotGnTJqNGjcomm2xSGPOXv/wla665Zm6//fZ8+OGH2X333Qt91dXVqaioSOvWrXPIIYekWbNmefLJJ2vVdt9996V9+/Z54oknap17woQJmTlzZq2xTz/9dO69994MHjy41thNN900W265ZU455ZQ61/Dxxx8nSV599dW8/PLL+eqrr+rcm6qqqowbNy6rrbZakkUhlYsvvjhHHHFErbF33XVX/vrXv9b67Hb+/Pl59tlnc9ZZZ+Xaa69N06ZN88c//jFbbrllYa7nn38+m222WWGuYcOG5fnnn8/AgQPz7LPP1qpl4cKFdXbfmTp1aubNm5ebb74506dPz+abb16r9qqqqrRu3TqnnHJKtthiizr3AJZk9OjRK7oEAOA7wJoAAIrLN3dqXhqBmhXs5JNPzsknn1yrbc6cOWnRokWee+65dOnSZanHP/DAA2nYsGGd9oMOOijJoh88brfddikrq/1WH3DAATnggAPSpk2bnHbaadl6663z9ttvZ+bMmctV93333Zejjjoq119/fTp27LjEcc8++2x22GGHdOjQIffff39++tOfLtf8X3fWWWfV+sHw7Nmz0759+1z0coNUNax/m3MAoDiUN6jJhVtUp9+LDVJRXbLsAwCA7yVrAgBgMesC6vNG/5+s6BJYTs2aNUuS/PSnPy18vtmnT5/cdtttOeyww7L66qvnqquuypw5c3LJJZdk1VVXzRlnnJGPP/44w4cPT5LccsstufPOOzN69Oh6P2t9//3306RJk/zgBz/IlClTctxxx2XHHXfMueeemyRp3759unXrlqqqqvTs2TPjxo3L008/neHDh+enP/1prR1ekkUBmKOPPjoTJkxIsuhhgxtvvHE++uijHH300Xn77bfz8MMP58wzz6wVxEmSF198MZMnT67VPmnSpDo1N2rUKK+++mo6dOiQMWPGZPLkydlrr73SrFmzfPDBB7n88suz33775aijjso666yT3XffPdOnT8+hhx6ahQsX5re//W0+//zznHzyydloo42SJP/7v/+bVq1aZcCAAWnQoEHhXN+sMUl22WWXHHrooTn00EOTJL179859992XY445Jm3atMn555+flVZaKeecc06aNGmSCy+8MH//+98zZsyY/PCHP6wz31577ZWDDz44PXv2THl5eZ588sk888wzue2227L77rvXeUDjLbfckltuuSWPPfZYnblgSSorKzN69Ojsuuuu9f5OBQBQHKwJAKA4zZ49e7nHCtT8m8ybNy+TJ0/O1KlT8/rrry8zGNO/f/86u7B8/SlLe+65Z0aOHFnnuMWLvDlz5mTAgAG5++6788EHH6S6ujpt27bNrrvumttuuy3NmzdPsmi78ssuuyzJoq25S0tLc8wxx6R169ZZbbXVssUWW9QJ33zd/Pnzc9FFF+XSSy/NlVdemYMPPnip17XNNtvk4Ycfzg477FDrB7HfRnl5ecrLy+u0V1SXpGqhD8MAgEXrggrrAgAoetYEAMBi1gV8nV+a+u+x+HPKhg0bFv58+umnZ+7cudluu+0yd+7cdO7cOU8++WTWWGONJIsCKJMmTSq8zxdddFHmzZuXnj171pq7Z8+euf766/PJJ5/kyCOPzNy5c9OkSZMcfPDBOe+88wrHb7bZZhkxYkTOOuusHHnkkWnTpk2uuOKK9OrVa5k1J0m7du0yatSonHTSSTnnnHPSvHnznHDCCenTp0+dY0tLS1NSUrJc36MNGzZMw4YN07FjxwwbNiz9+vXL/PnzU15eniOOOCJnnXVWGjZsmB49euQvf/lLhgwZkn79+mXevHnZdNNN8/DDD6dz586F+a644or85je/qfdz2G8qKSlJaWlpoc7BgwensrIyW2yxRSorK7PZZpvlkUceScuWLZMkF154YZo3b57tttuu1jy//vWvc95556Vfv34ZPHhwTj311FRXV+cHP/hBbrzxxuy55571nv/b3Cf4psV/dwCA4mZNAADF5dv8u19SU1NT82+spehMmjQpa6+9dkpKStKkSZOsueaa2WSTTXLOOedk8803z8SJEzNr1qx07do1y3vr+/fvn1deeaXeQM1ivXr1yscff5zf/va32WSTTVJWVpb3338/AwcOzEsvvZR33nkn5eXlhe2wS0pKUlZWVmcr7SQ599xz88UXX+T3v/99nb5LLrkkN9xwQ2688cb8+Mc/rreWww8/PK1bt84VV1xRaHv00Udz/vnnZ9y4cXXGP/HEE9l4443Ttm3bZd+MLEqMtWrVKuueekeqypot1zEAwPdTeWlNLtlqYU5/vtQvyQBAEbMmAAAWsy6gPpOG7LGiSwDgP6yysjKjRo3K7rvv7pdnAaCIWRMAQHFanDf44osvCg+BWRI71PyLdejQod6gzJw5c5Z6XP/+/TNo0KA0bdq03v499lj6D/qfeOKJ3Hzzzdlpp50KbZtvvnmGDh2aDh065N13383GG2+csrKylJWVpV+/fiktLU3//v3rzHXRRRct8TynnXZaTjrppOV6UtHXzZ07N5MnT6637+s1AwAAAAAAAAAAAAAA/LsJ1HyH9OrVK3feeec/dexPfvKTDBw4MCuvvHKtHWouuuiidOjQIR07dqw1fsqUKSkpKcn8+fPrna9BgwZp1KhRnfaSkpJvHaZZrKamZonBooYNG/7T8wIAAAAAAAAAAAAAAHwbDVZ0Afyfu+++u7CDTH2vhQsXLvHYW2+9NXvssUdOOOGEtGvXLquuumr22WeftGnTJn/961/rDcfccMMNadKkSb2vrbba6l9+fZ988klatGhR7+ukk076l58PAAAAAAAAAAAAAACgPiU1NTU1K7oI+DZmz56dVq1a5dNPP80qq6yyossBAFagysrKjBo1KrvvvnsaNmy4ossBAFYQawIAYDHrAgAgsSYAABaxJgCA4rQ4b/DFF1+kZcuWSx1rhxoAAAAAAAAAAAAAAACKikANAAAAAAAAAAAAAAAARUWgBgAAAAAAAAAAAAAAgKIiUAMAAAAAAAAAAAAAAEBREagBAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFQEagAAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFYEaAAAAAAAAAAAAAAAAiopADQAAAAAAAAAAAAAAAEVFoAYAAAAAAAAAAAAAAICiIlADAAAAAAAAAAAAAABAURGoAQAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBUBGoAAAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBWBGgAAAAAAAAAAAAAAAIqKQA0AAAAAAAAAAAAAAABFRaAGAAAAAAAAAAAAAACAoiJQAwAAAAAAAAAAAAAAQFERqAEAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVARqAAAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVgRoAAAAAAAAAAAAAAACKikANAAAAAAAAAAAAAAAARUWgBgAAAAAAAAAAAAAAgKIiUAMAAAAAAAAAAAAAAEBREagBAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFQEagAAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFYEaAAAAAAAAAAAAAAAAiopADQAAAAAAAAAAAAAAAEVFoAYAAAAAAAAAAAAAAICiIlADAAAAAAAAAAAAAABAURGoAQAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBUBGoAAAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBWBGgAAAAAAAAAAAAAAAIqKQA0AAAAAAAAAAAAAAABFRaAGAAAAAAAAAAAAAACAoiJQAwAAAAAAAAAAAAAAQFERqAEAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVARqAAAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVgRoAAAAAAAAAAAAAAACKikANAAAAAAAAAAAAAAAARUWgBgAAAAAAAAAAAAAAgKIiUAMAAAAAAAAAAAAAAEBREagBAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFQEagAAAAAAAAAAAAAAACgqZSu6APhnbT348VSVNVvRZQAAK1B5aU0u2Srp1P+RVCwsWdHlAAAriDUBwPfDpCF7rOgSWA6TJ0/OvvvumxdeeCGVlZUpK1v0UdNjjz2Wiy++OK+99lpKS0vTsWPHXHDBBenevXu98wwbNiy9e/dOq1atarWPHTs26623Xr788sv069cv999/f7766qu0bt06v/zlL3P22WentLS01jEzZ85Mp06d0rFjx4wePTpJsuGGG+arr76qNW7evHnp2rVrnnrqqXTv3j3jx4+v1b9gwYK0bNkykyZNKrSNGTMm++23X9Zff/2MHTu2znW88cYb2WuvvTJ//vx89NFHtfq6d++e1157LY0aNSq0bb755nnwwQcLX7/33nvp27dvnn322VRWVqZjx44ZN27cct/TefPm5fjjj89NN92U0aNHZ5dddqlVQ1VVVfr375+BAwfm+uuvz9FHH12r/4knnsgpp5ySKVOmpHXr1hkwYEAOOOCAJMmXX36ZAQMG5J577smcOXPSpEmT7LPPPhk0aFDKy8uTJCUlJWnbtm2tOfv06ZNzzjmnzr0CAAAAAIDvmqLfoaampiZJsvrqq+exxx7LpEmTUlJSklmzZtUZu/XWW+f3v/99nfaSkpK88sory33OkSNHpkOHDksdU1VVlZKSkowZM6ZW+5LqmzBhQo444oistdZaady4cZo2bZpNN900AwYMyLx582qNnTVrVuE1c+bMzJgxI0nSt2/fHHzwwUu9B/W59tprl/iBWH3uu+++lJWVFe49AAAAAADw3ffcc8/lRz/6Ubp06VKn77777stpp52WTz75JB9//HEOPPDA7L777vnss8+WON8BBxyQqVOn1nqtt956SZKTTjopf/3rX/P0009n6tSpueuuu3LdddflkksuqTNPnz59sv7669dqGz9+fJ2599xzz2y22WZJkqeeeqpO/wknnFDoT5Irr7wyvXv3zrbbbltv/ffcc0969uyZbbbZZonXePfdd9c6x9fDNJMnT86OO+6Y3XbbLZMnT86MGTNy8cUXL/c9nTt3bjbeeOOstNJKSzz/tttum8mTJ9cJvSTJ+++/n549e+b888/PtGnTMmzYsBx11FF55plnkqQQ5Bk7dmymTp2acePGZfTo0enXr1+teb55H4VpAAAAAAD4b1FUgZovvvgiZWVlhVfDhg2z9tprL/fxn376aZo2bbrMccOGDUtJSUmd19I+UPmmmTNnJklWWWWVZY6dNm1att566yTJo48+mjlz5uTTTz/N7373u9x1112FJ4kt1qlTp3Tq1CmdO3fORhttlI4dOy51/j/+8Y+17tvi11VXXbXc1/N1d999dzbYYIOUlHhiLAAAAAAA/LdYb7318tZbb+Wggw6q03fllVemR48eKS0tTUlJSQ466KDMmzcv77333j91rnHjxuXQQw9Nu3btkiQbb7xx9txzz8LuLYvdc889+eSTT3LooYcudb7JkyfnzjvvzMknn1xv/9y5c3P11VfntNNOK7Ttvffeef3119O1a9d6j9lmm23y9ttv19kVZnmdffbZ6dOnT4499tiUlZWlpKQk22+/faF/Wfe0vLw8Y8aMyWWXXbbEc9x55525+eab07hx4zp91157bbbbbrvsvffeSRaFbw488MBceeWVSZLtttsuQ4YMyeqrr55k0cPpdt5557zxxhv/1PUCAAAAAMB3TVEFalq1apX58+dn/vz5WbBgQS6//PJ6n8hVn9dffz3vv/9+2rdvn2TRDjKL56pP586dM2/evFqvb+42szRvvfVWkhTOtzTPPvts5syZk+uvvz4bbLBBysrK0rRp03Tv3j0DBgzIgw8+WGs3mI8++igfffRRPvzwwwwcOHCZ5zjqqKMyZ86cwmvMmDFp3Lhx9ttvv+W+nsXuvPPO3H777fnkk09y6aWXfuvjAQAAAACAFWOVVVZJ8+bNlznu888/z4ABA9KpU6d6d7NZHgcddFD+9Kc/ZcKECUmSF154Iffee2+tMM+MGTNy6qmn5sYbb1zmQ7yGDh2avffeOz/84Q/r7b/hhhuywQYb1NqNpn379mnQYMkfpf3gBz9Io0aNvs1lFVRWVubuu+/OJptskh/96EdZbbXV0r1797z55pv1jq/vnpaWlhYCR0uy1lprLbHv2WefzXbbbVerbbvttsuzzz5bZ2x1dXX+9re/5a677sovf/nLZVwdAAAAAAD8dyiqQE2Swu4qDRo0yFtvvZWNN954uY4bNGhQkuTSSy9NVVVV+vbtmyZNmqRJkyb1ji8pKUnjxo1rvb7Nhyp/+ctfkiRXX331MsduueWWadKkSU466aS88847qaioyJdffpm//vWvGTx4cHbdddclfpD01ltv5Y033khJSckSn2BWWlpauIbp06fnkEMOycUXX1x4ItnymD9/fi644IIcdthhueWWW/Lkk0/miiuuSK9evfLKK68s9zwAAAAAAMB31yGHHJJVVlklDz30UEaOHLnUz0buuuuutGvXLmussUZ22mmn3HPPPYW+fv36Ze+9984GG2yQxo0bZ7vttssFF1yQAw88sDCmd+/eOeWUU7L22msvtaZZs2blhhtuSN++fevtr6qqytChQ2vtTvOvcuCBB2a11VbL+uuvnyOOOKKwu8zkyZNTU1OToUOHZsSIEZk0aVK23Xbb7LTTTpk9e3atOb7NPf02pk2bVufBc23bts20adNqtb355ptp2rRptt9++xxzzDF1AjVrrbVWVl111XTu3Dn9+vXLl19++S+pDwAAAAAA/t2KLlDzdWPGjMkOO+xQ+LqysjIVFRV1xl100UW5/fbbc8UVV6Sqqip77713zjvvvNTU1NTa+eXrXn311ZSUlNR6NW7ceLnqev/993PzzTenX79+ufDCC/P3v/99qePXWGONPP/88/njH/+Y7t27p23btll//fXTq1evNGrUKHfeeecSj33wwQfzl7/8JZWVlTn99NOXep7bb789W265ZT799NN8/PHHqaysXK7rOeWUU7L66qvngQceyJgxY/Lzn/88Xbp0yauvvpo11lgjW2+9dbp06ZLp06cv13wAAAAAAMB306233ppZs2Zl3333Tbdu3eqEMxbbd999M23atHz00Ud55513cvDBB+eggw7KHXfckSQZOHBg7rrrrrzyyiuZO3dunnjiiVxwwQW59dZbkyS33XZbZsyYkeOPP36ZNV199dXZaqut0rVr13r7//znP6dRo0bp1avXP3nV9fvLX/6STz75JNOnT88jjzySysrK7LDDDvn8888zderUzJs3LxdddFHWWmutNG3aNBdeeGGqq6tz//3315pnee/pt1VdXV3ngWwNGjRIdXV1rbaNN944X331VcaNG5ebb745F1xwQaFvypQp+eCDDzJ16tTceOONefDBB3PAAQf8S+oDAAAAAIB/t7IVXcCK8swzz+T9999Pz549C2277757rTFz587NEUcckdGjR2fYsGE57LDDcswxx+SUU07JRhttlPvvvz9bbbVVnbkPO+ywHHzwwUmSLl265JRTTsmhhx66xF1ivu6rr77KL3/5y3Tr1i0DBgxIo0aN0qNHj4wcOTLdunVb4nEbbLBBSktLc9ttt6V79+5JkhNOOCFz5sxJ8+bN6z3m8ccfz/Tp09OrV6+UlZXVW19NTU0efPDBDBw4MNOnT89dd92Vtm3b5sADD8ytt96aq666Kkny9NNPp6SkJNttt13Gjh1ba44dd9wxP/vZz7LTTjvVal9llVVy7bXX5qKLLspLL72U1VZbrd46KyoqagWdFj+ZrbxBTUpL6w80AQDFobxBTa3/AgDFyZoA4PtheR/ixIpXVVWVZNF7Vt+Dx5o2bZrzzjsvw4cPzx133JHevXvXGbP4IWSVlZUpLy/PIYcckjFjxuTmm2/OHnvskQsvvDAjR47MRhttlIULF2brrbfOueeem3POOSc77bRTzjjjjIwePbpQy8KFC1NTU1P4Plr834qKilx55ZW58cYbl/g9dskll+Skk07KwoULs3Dhwjr935y7vv6vn3Ox1q1bF+Zs165drrvuurRp0yaPPPJINtxww5SUlKRTp061jvvhD3+YSZMm1Zlree5pVVXVUv8eLVy4sFb/yiuvnBkzZtRqmz59etq0aVPvPF26dMmZZ56ZM888M2effXaSRZ/1LB7bpUuXXHrppdl5553zySefZNVVV11iLQDw7/bNNQEAUJysCQCgOH2bf/uLNlAzaNCgHHbYYVl55ZULbaNHj856662XtddeO8miDyf23nvvXHPNNYVxTZo0yTXXXJMLLrigEAA59dRTa4VBSkpKUlb2f7e2QYMGqaioyOeff55PPvlkiW/QBx98UHj62QMPPJAkOffcc9O8efPssssu+dvf/lar3kmTJqV///6FrysrK/Pb3/42w4cPT5KMGzcuFRUVOfzww5Mkbdq0yaWXXppk0Ycqiz/0OPLII/O///u/SZJf/vKXder685//nAMPPDDHHXdcxo8fn9LS0rzwwgu57bbbsvnmm+eBBx7Ij3/84zz66KNp0KDupkdfDy3Vp02bNvnJT36yxP7BgwfXetrZYud2rU7TpnU/2AIAis+FW1QvexAA8L1nTQDw323UqFErugSW0+uvv54keeihh1JaWpqamprU1NTU+YygoqIib7311nK/t++//34aNGiQe++9NxUVFXnllVdqPXDr7bffzqeffpqbb74506dPz+abb17oq6qqSlVVVVZdddWccsophfZHHnkkjRs3TlVVVb11vPzyy5k0aVJWXXXVJdY5YcKEzJw5c4n9r776aubPn7/M65w/f36qqqoyYcKENGzYME2aNMlNN92UNddcM8miz3kmTJiQzz77LA8++OC3vqfPP/98rfv1dXPnzs3rr79e67g2bdpk1KhR2WSTTQptf/nLX7Lmmmtm1KhRWbhwYUpLS2vN8+abby7xXiaL7mdZWVnGjh2b8vLypd4PAPhPGD169IouAQD4DrAmAIDiMnfu3OUeW1JT36PDvueuvvrqnHfeefnHP/5RCMKsvvrqGT58eCFQM3PmzLRu3bpwTPfu3fP0008vcc6XX345Xbp0Se/evfOXv/yl0D5z5sxUV1enUaNGadOmTdZcc82ccMIJOe+88zJp0qRac0ydOjVXXHFFzj777LRs2bJW39tvv50NNtggkyZNKtRXUlKSv/71r8t93U2bNi3sEnPcccdl7Nixeemll9KwYcNUV1fnjDPOyLRp03LRRRfVew+S5Gc/+1m22GKLWkGea6+9NrfffnueeuqpOufcYost8tJLLy13jfV9O9a3Q0379u3zP6fdnqqGzZZ7bgDg+6e8QU0u3KI6/V5skIrqZe8GCAB8P1kTAHw/vNF/yQ9e4rvl6aefzq677pq5c+emrKwss2bNyl577ZUhQ4Zk6623Tk1NTYYOHZohQ4bk1VdfzRprrJEzzjgjH3/8ceGhYIMGDcree++dDTfcMAsXLsxtt92WE088MU899VS6dOmSXXbZJZWVlRk+fHjat2+ft956K/vtt1+22Wab3HjjjXVquuWWW3LLLbfkoYceyujRo7PrrrumtLQ0m2yySc4888wccsgh9V7Lbrvtlm7duuXcc89d4vUOGDAgTzzxRL2fgyw+9/nnn5+JEycW2t58882MGTMmv/jFL9K6devMmDEjffr0yZQpU/LEE0+ktLQ0J554Yt55552MGDEiTZo0ybnnnptRo0bl5Zdfzrx585Z5T7+uUaNGeeihh7LzzjvXW2PHjh1z1lln5cgjjyy0vf766+nWrVtuvfXW9OzZM+PGjUvPnj0zfPjw/PSnP80555yT1q1b5+ijj85KK62UiRMnZs8998zuu++eIUOGZOTIkSktLU2PHj1SXl6eN998M7/85S/z05/+NIMHD17i/QSA/4TKysrCmqBhw4YruhwAYAWxJgCA4jR79uy0adMmX3zxRZ1cxjcV3Q41N998c0499dTcc889tXaVWZZHH3001dX1P+W0efPmhT8PGjQo55xzTpJFO9M0bNgwzZs3T5MmTQpjRo4cWe88q6++eoYMGVJv3wYbbFCnrVWrVvnZz36WJPnHP/6Riy++OGPHjs306dNTWlqadu3apUePHjnzzDML1zpv3rz07t07DzzwQJ5//vnC08EaNGiQkpLl/4WTuXPn5rPPPsu0adOWOu65556rE5K55ZZbcskll+SNN95YrnOVl5fX+xSziuqSVC30SzIAwKJ1QYV1AQAUPWsCgP9ufqnhv0dZ2aKPlxo2bJiysrKsuuqq+fWvf52zzjorEyZMSGlpaTbaaKM8/vjjWWuttZIkkyZNyqRJkwrvc/v27XPYYYflk08+yYIFC9KlS5c89thj2XLLLZMkd955Z84999zstNNOmTNnTsrLy3PwwQfnvPPOq/d7pbS0NCUlJYW+hg0b5oEHHsjcuXNzyCGH1HvMyy+/nGeffTZ33HHHUr//vjl3ff2Lz7nYD3/4w7z99tvZcsstM3fu3JSUlGT//ffP9ddfn8aNGydJLr/88vTt2zedOnXKggUL0q1bt4wePTrNmzdP8+bNl3lP63tflnUdX+/fbLPNMmLEiELQpk2bNrniiivSq1evJMlJJ52UCy64IFtttVXmzZuXli1b5qCDDso555yThg0bZsMNN0y/fv3Sp0+fVFRUpFWrVjnhhBPSp0+fwvcIAKxoDRs2tM4EAKwJAKDIfJt/94tqh5pbbrklxx13XG655Zbst99+tfqWtUPNggULlhqoefHFF9OlS5dC28yZM/PGG2/kxz/+cZ3xDz30UM4555z8/e9/X2Ktv/zlL7Ppppvm9NNPr9VeUVGRF154Idtuu23hA5r3338/nTt3zuGHH54+ffpk3XXXTVVVVV555ZXCE9HeeOONNGrUKPfff39OOeWU3Hfffdloo41qzd23b99MnTq11g41f/rTnzJo0KDCmNmzZ6eysjKNGzfOqquumo4dO2b//fdf4g419Rk2bFiGDBmS8ePHL9f4b5o9e3ZatWqVdU+9I1VldqgBgGJWXlqTS7ZamNOfL/XLswBQxKwJAL4fJg3ZY0WXwPdAZWVlRo0ald13390vygBAEbMmAAASawIAKFaL8wZ2qPmGAw44IJtttlk6der0rY/t0aNHnn766eUe/9JLL2WvvfbKnDlz6vT99Kc/zU9/+tOlHv/FF19k7ty5ddrLy8vTrVu3Wm1//etfkyRXXXVVoa2srCzbbLNNLr300nTu3DkTJkzIxhtvnJ49e+YnP/lJGjVqtFzXcdRRR2WfffZJSUlJysrKUl5enubNmxeenpYk11577XLNBQAAAAAAAAAAAAAA8F1QVIGa8vLyfypMs9jQoUNz3HHH1du3pPRyfYGaxZo3b77U8y1YsGCJxzdu3DhlZYvevh122CElJSU54YQTcsIJJ6RDhw5ZuHBhXn/99fTv3z/rr79+1l9//cKxyxumSZJWrVqlVatWyz0eAAAAAAAAAAAAAADgu67Bii7gv8lvfvObNGnSpN7Xb3/72zrjv/rqq7Ro0WKJr1mzZi31fIMHD17isXfeeWdhXIcOHfLcc89l9uzZ2XXXXdOiRYusssoqOfTQQ7PRRhtl7NixtisEAAAAAAAAAAAAAAD4/5XU1NTUrOgi4NuYPXt2WrVqlU8//TSrrLLKii4HAFiBKisrM2rUqOy+++4CxABQxKwJAIDFrAsAgMSaAABYxJoAAIrT4rzBF198kZYtWy51rB1qAAAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVgRoAAAAAAAAAAAAAAACKikANAAAAAAAAAAAAAAAARUWgBgAAAAAAAAAAAAAAgKIiUAMAAAAAAAAAAAAAAEBREagBAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFQEagAAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFYEaAAAAAAAAAAAAAAAAiopADQAAAAAAAAAAAAAAAEVFoAYAAAAAAAAAAAAAAICiIlADAAAAAAAAAAAAAABAURGoAQAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBUBGoAAAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBWBGgAAAAAAAAAAAAAAAIqKQA0AAAAAAAAAAAAAAABFRaAGAAAAAAAAAAAAAACAoiJQAwAAAAAAAAAAAAAAQFERqAEAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVARqAAAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVgRoAAAAAAAAAAAAAAACKikANAAAAAAAAAAAAAAAARUWgBgAAAAAAAAAAAAAAgKIiUAMAAAAAAAAAAAAAAEBREagBAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFQEagAAAAAAAAAAAAAAACgqAjUAAAAAAAAAAAAAAAAUFYEaAAAAAAAAAAAAAAAAiopADQAAAAAAAAAAAAAAAEVFoAYAAAAAAAAAAAAAAICiIlADAAAAAAAAAAAAAABAURGoAQAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBUBGoAAAAAAAAAAAAAAAAoKgI1AAAAAAAAAAAAAAAAFBWBGgAAAAAAAAAAAAAAAIqKQA0AAAAAAAAAAAAAAABFRaAGAAAAAAAAAAAAAACAoiJQAwAAAAAAAAAAAAAAQFERqAEAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVARqAAAAAAAAAAAAAAAAKCoCNQAAAAAAAAAAAAAAABQVgRoAAAAAAAAAAAAAAACKikANAAAAAAAAAAAAAAAARUWgBgAAAAAAAAAAAAAAgKIiUAMAAAAAAAAAAAAAAEBREagBAAAAAAAAAAAAAACgqJSt6ALgn7X14MdTVdZsRZcBAKxA5aU1uWSrpFP/R1KxsGRFlwMArCDWBPwrTRqyx4ougeUwefLk7LvvvnnhhRdSWVmZsrL/+1H3zJkz88tf/jIPPfRQJkyYkPXWW2+55nz//ffTuXPn7Lfffhk2bFihvaqqKv3798/AgQNz/fXX5+ijjy70rbvuuvnqq69qzTNv3rx07do1Tz31VCZNmpR11103q666aq0xl1xySQ499NB8+eWXGTBgQO65557MmTMnTZo0yT777JNBgwalvLw8STJixIhcfvnl+eijj9KwYcNss802GTx4cNZdd93CfC+99FLOPPPMvPHGG6msrMxOO+2UP//5z3Wu8eKLL86ZZ56ZJ598Mt27d0+SPP/88+nfv39efPHFlJaWZqONNsrll1+eLl26JEneeeednH322Xn++edTWVmZ9u3b57TTTsv++++fJJkyZUrOPvvsPPXUU5k/f35WXXXV9O7dO717906SvPvuuzn//PPz9NNPZ+HChVlllVXSp0+fHHvssUmSadOm/X/s3Xd4jff/x/HXyUlkyhArJbVp7dHaVKmVUFv7RQlqtbX3rBQ1S+xWqVl87VFBSYUaQQdq1J6VxE4ie5zfH66cn9OTEL5RbfN8XNd96fnM932fk+Zz3Sfv+6MxY8Zox44dio+Pl6urqzp16qQRI0bIYOD/6QAAAAAAAAAAAHhxstQONbt375bRaLQqX7JkifnLwT+39/X1Va5cuZQtWza5u7vrrbfe0vLly19onCaTSZL05Zdfmr/ULFiwoDZt2vTMYwUHB8vd3T1DbTt06KCxY8dKkvLmzavg4OB023700Udyd3c3H++//765LiAgwBx3Wk6cOCGDwaDr169nKC4AAAAAAAAASHX48GFVr149zXu6V69eVdmyZTOcRJMqJSVFnTt31ptvvmlVV61aNV2/fl158uSxqrt48aLCwsIsjmbNmqlixYrmNt7e3lZtOnbsKOnRvVKj0aj9+/crLCxMhw4d0q5duzR69GhJ0t69e+Xn56dRo0YpNDRUp0+flr29vXx9/z/x69dff1XTpk3Vs2dP3bx5U+Hh4erTp49VrKdOndKKFSuUL18+i/IhQ4aoV69eCg0N1R9//KEqVaqoWbNmkh7dq/bx8ZGrq6vOnDmj0NBQDR06VO3bt9fBgwclSe3bt1dYWJh+/vlnhYaGau7cuRo6dKhWrVolSdqxY4fefvttnT17VqGhoVq8eLEGDhyowMBASdK+fftUpEgRHTt2TGFhYQoMDNS8efM0f/78jL+BAAAAAAAAAAAAwHPIUgk19+/fV44cOTLUdufOnfLx8VGdOnV04sQJxcfH6/Lly+revbv69Omj6dOnP7G/u7u7DAZDukdYWJi57WuvvSZbW1vZ2trKaDSqQ4cOGT6nadOmWSWvlC9f3uIJiumpVKmS1q5dm+G5JOnmzZv68ssvVbZsWU2aNMl81KlTR19++aUuXbr01DE2bNggV1dXvfLKK880NwAAAAAAAAAULVpUZ86cUbt27azqPD09dezYMQ0YMOCZxgwICFDhwoX11ltvWdWtW7dOS5culYODw1PHuX79utatW6d+/fplaN4aNWpo0qRJyps3r6RHDzqqV6+eTp48KUkKCQlRyZIlzQkuLi4u6tOnj86ePat79+5Jkvr06aOZM2eqVatWMhgMMhqNqlmzpsU8SUlJ8vPz0+zZsy1285EePViqadOmMhqNsrGx0QcffKBr164pPDxct27d0sWLF9W3b185Oz/aLbxVq1YqVqyYQkJCzDH27NnTfO+9Vq1aqlWrlg4dOiRJ+uSTT/Thhx+a+7/55psqVqyY+RzbtGmjIUOGyMPDQ9Kj97dy5crmegAAAAAAAAAAAOBFyVIJNWfOnJG3t3eG2u7YsUM1atTQ4MGD5eXlJYPBIA8PD7Vv315+fn7aunXrU8dYt26d7t+/b3EcP37cqt2JEyf08OFDxcbGqkmTJipSpMgzndcff/yhOXPmmI87d+5Y1JtMJj148EAREREW5fHx8cqdO/czzRUXF6crV66ke8TExDyx/4EDBzRlyhTZ29trwIABSklJeab5AQAAAAAAAGRtnp6ecnFxSbPOxcVFnp6ezzTe77//rnnz5mnGjBlp1hcoUCDDY82YMUMtWrTQq6+++kwxSI92yTl48KDWr1+v9u3bS5KaNm2qa9euadWqVUpJSdHdu3c1depUNW7cWDly5NCNGzd09uxZZcuWTRUqVFDu3Ln17rvvWu0OPmHCBFWuXDnNncX/nGBz6NAh5cmTRzlz5lSePHlUr149TZkyRffu3VNycrJWrFihsLAwNWnSRJLUrl07zZ49Wzdv3pTJZNLOnTt1+PBhtWnTxmqu+Ph4rVixQlevXlXz5s2t6pOSkhQYGKj9+/frvffee+ZrCAAAAAAAAAAAADyLLJVQs3btWv3666/mJ+c9Sb169RQSEqLZs2crNDRUiYmJunv3rtauXatVq1apYcOGTx3D2dlZ7u7uFoerq6tVu2zZssnBwUF2dnY6duyYXn/99Wc6r4SEBIWFhZmPpKQki/rIyEh5eHhYfPF7584dnTlzRseOHbNo6+/vL4PBoPDw8DTnKly4sMaMGaOoqCitWbNGK1eu1OrVq3X79m0NHz5cpUuXTrNfUlKS5s2bp4YNG2rChAk6evSodu/erdq1a2vfvn3PdL4AAAAAAAAAkBmSk5Pl5+engIAAubu7/09jPXjwQAsXLtSgQYMsyv/44w+9+uqryp07typVqqRp06YpMTHRos2pU6fk5OSk2rVrq3v37uaEmpIlSyowMFADBgyQk5OTcubMqdjYWK1fv16SdO7cOaWkpGjZsmX6/vvvdeHCBbm5ualx48ZKTk6WJP3yyy9asWKFJk+e/NRzuHDhggYNGqRp06bJaDRKkrZs2aKIiAh5enrK2dlZgwcP1o4dO1S8eHFJ0oIFC1SwYEHly5dPjo6OatOmjZYuXapatWpZjL1gwQI5OTmpT58+Wr58ubl/qh07dsjJyUmtW7fW5MmT09wtCAAAAAAAAAAAAMhMWSahZu3atbp06ZIGDRqkjh07Wu3W8mdNmjTRnDlz1KdPH1WtWlW5cuVShQoV9MEHH6h9+/YaOnToE/sXL15cQ4YMUfny5S2OZs2aqUSJElZP/ZOky5cv68aNG6pXr56SkpIyvHtLoUKFNH78ePORN29ei3o3NzfzLjWpAgIC1Lt3by1atEgnTpwwlw8fPlxRUVFP3Llm2bJl2rdvn44fP65r167p9OnTOnPmjObMmZNm+ylTpih//vyaNWuWNmzYoP79+6tAgQI6evSoatWqJR8fHxUvXlwnT57M0PkCAAAAAAAAQGaYPHmyihUrZt5t5X8xb948Va5cWRUqVDCX5cuXT2FhYbp27Zr++OMPTZs2TXPmzFHfvn0t+pYqVUrR0dE6dOiQli5dKn9/f0nSyZMn1bRpU02cOFGRkZEKCwuTg4ODmjdvLpPJpLCwMN2/f1/z5s1Trly55OrqqpkzZ+rMmTMKCQlRQkKC/Pz89OWXX6a7q0+q+/fv691331Xnzp3VoUMHSY92P2/RooUcHR0VFhamyMhITZw4Ub6+vub7uT169NCFCxd08eJFPXz4UKtWrZKfn5+CgoIsxu/evbtiYmL09ddf6z//+Y92795tUd+oUSNFR0fru+++07Bhw7RkyZLneh8AAAAAAAAAAACAjLLO6vgXunDhgnr06KExY8Zo0KBBOnHihOrWrastW7YoX7586fYrVaqUJOnq1avmstKlS6tMmTIyGAxPnPPIkSPPHOeiRYtUunRppaSkyM7OTpIy9BS+vXv3PjWex82aNUvr16/XTz/9pMOHD6tBgwZavHixpEe75bi4uDxxvAYNGmjGjBlq0qSJvL29zV8I+/r6ptm+atWqWrBggXx9fc1PNZQkJycnTZw4UcOHD9fevXvT3d0mPj5e8fHx5teRkZGSJHsbk4xGU4bPGwAA/PvY25gs/gUAAFkTawJkpj/vHIK/r9SduhMTE2UyWf78p76PiYmJ6b6np06d0ldffaUjR46Y2yQnJyslJSXdPsnJyWnWxcfHa9asWVq0aJFVvaurq7msZs2aGjNmjHr37q2ZM2dajVO+fHkNGzZMw4YN04gRIzR16lS988475h1rcuTIoYULFyp37tzatWuXnJyclC9fPuXIkcM8R/bs2eXh4aHLly/ru+++U5UqVVS7dm2LuJKSkixeP3z4UI0aNVKFChU0adIkc92+ffu0Z88e3b59W05OTpKk9u3ba9euXZo0aZI+/fRTLVy4UKdPn5a3t7dMJpMaNGigbt26aezYsapdu7bF+dnY2Ojdd99V8+bNNX/+/DTvf9eqVUs9evTQnDlzzOcNPIvHf/4BAEDWxZoAAABIrAkAAMiqnuV3/78+oSYoKEht27ZVkyZNNGTIEBkMBm3atEk9evRQ5cqVdf78eYv2O3bs0OrVqyVJt2/fliR9+OGH5vqbN29q4cKFCg4OlvToC9DH611cXBQdHZ3h+C5fvqyCBQvq3r17WrBgge7fv6/bt2/LZDLpyy+/NMeSnv79++uTTz6xKk9NyClevLhmzJhhLl+4cKG++uor7dy5U87Ozqpbt66++eYbHTt2LMMxFy5cWGfOnNHZs2dVunRpLVu2TG3atFFCQoLV9ZRk9aXpn7m6uqpp06bp1k+cONH8RMbHjaqQIien5AzHDQAA/r3GvZGxnf0AAMC/G2sCZIbAwMCXHQIy6LfffpMkbd++3eJBPpIUHh4u6dHDiM6dO5dm/z179ig8PFyFCxc2l6Um56xfv16ff/65ChYsaK6LiYnRb7/9luZnZOfOnXJwcFBSUtJTP0M//fSTHB0dFRgYqOTkZKvYT506ZR7n999/l5ubm8WYycnJMhgM+uGHH1S8eHGFh4dr3bp15oSXiIgI3bt3T3/88Ye2b9+uc+fOaeXKleb+sbGxatq0qQoVKqSJEycqPj5en332mbJnz65WrVpp+/bt5rYhISEyGAwKCgqyiPPOnTu6f/++vvvuO0nSoUOHLK7z9evXdf369XTPMSwsTLGxsenWX758WVFRUfw84n+ya9eulx0CAAD4G2BNAAAAJNYEAABkNTExMRluazD9+dF9/zIHDx5USEiI+vXrJxsbG4u6s2fPqkSJElqyZIkCAgJ07NgxXbp0SadPn87w+N7e3ipXrpz5dXx8vNXTEA8ePKh69eopNjbWqr+9vb0MBoP8/Px05swZ1a5dW/v379fevXv1zTffaPXq1QoODlbBggUVEBCg5s2bpxlH2bJldevWLatyk8kkBwcHi1124uPjZW9vb9U2JCRELi4uKl26tCpWrKi5c+eqWrVqFm1q1aql0NBQ89iXLl0y72jj5uamIkWKqHnz5tq0aZOCg4PVunVrrV+/Pv0L+CepCUaPS2uHGm9vb5UcvFpJds4ZHhsAAPz72NuYNO6NFI3+yUbxKRnfsQ8AAPy7sCZAZjo5tuHLDgEZtHfvXtWvX18xMTGytbV8dtSVK1dUvHhxnT59WkWLFjWXDx06VH/88YdWrFiR5pifffaZrl69qkWLFlnVFStWTMOHD1eXLl0sylNSUlSmTBkNGzZMH3zwgUXd0qVLVbBgQVWvXl12dnY6dOiQ/vOf/2j48OHq0aOHRo4cKXd3d3344YfmXWWaNWsmHx8fTZo0ScuWLVPv3r21atUq+fj4KDo6WkOHDtX69ev122+/KWfOnGrWrJnc3d01f/58JScnq3v37rp165aCgoLSPMdixYpp4cKFeuutt5SQkKCWLVvKZDJp48aNypYtm0XbO3fuqEyZMmrVqpUmT54sZ2dnBQYG6j//+Y9mz56t999/X+XLl1fJkiX11VdfydPTU4cPH1bLli3Nu8Y3b95cHTp0UNOmTWVvb689e/aoRYsWWrlypXx8fNStWzdVrVpV77//vpydnXX8+HE1bdpUI0aMUM+ePdP/AADpSExM1K5du1S/fn3zw8cAAEDWw5oAAABIrAkAAMiqIiMjlTNnTkVERMjV1fWJbf/1O9RUr15d1atXT7OuRIkSVmWFCxc2P5EwMDBQc+fO1bFjxxQRESEHBwcVLVpUbdq0UZ8+fdJcYKWVqJL6JaSDg0OaccyZM0dr1qzRTz/9pAIFCqhcuXJq166d3n777Qyf54kTJ9Is379/v5o0aZJmjKGhoZo4caJ27Niha9euyWQyKV++fHrnnXe0bt06iyczplq1apWSkpJkMBhkNBrl4OAgFxcX/f7773J3dzcn/qRas2aNUlIsnw67d+9e+fr66uHDh1bj//mL79R407qu8SkGJSXzRzIAAODRuiCedQEAAFkeawJkBr5U/edIvZdoZ2dndV8x9X20s7OzeE+vXLmiK1eupPs+G41G2djYPLH+z3UbN25UTEyMPvjgA6u61157TWPHjtXJkyeVkJAgLy8vTZw4UR07dpQk9e3bV/7+/qpcubJiY2Pl6uqqdu3aaeTIkbKzs1PXrl2VnJysMWPGqHv37oqPj1f16tUVFBQkLy8vSdKKFSv08ccfq0iRIkpJSZGvr682bNjwxM+yra2t7OzsdPDgQX3//ffKkSOHihQpYtFmxYoVeueddxQUFKSRI0eqZMmSio2NVd68eRUQEKCuXbtKkr7//nuNGDFCb775pqKjo+Xm5qYBAwZo8ODBMhqNGj16tCZOnKiBAwcqJSVFXl5eWrRokZo1aybpUZLTuHHjNH78eCUlJSlHjhwaPny4PvnkExkM/D8dz+/PP/8AACBrYk0AAAAk1gQAAGQ1z/J7/1+/Q83jChYsqG+//VY1atSwKL9165Zu3ryp8uXLm8v++9//ys/PT1OmTFHr1q2VO3duPXz4UPv27VP//v1Vs2ZNLVmyJN25qlevrlmzZumNN97Qb7/9pt69eys4ONiqXXBwsBo1aqSNGzeqcePGkqRz585p+vTpKlmypDZs2JChHWry58+vsLCwNOtcXFz04MEDi7KYmBi9/vrrqlixooYNG6bixYvLxsZGly5d0qxZs7R161adPn1auXPnTvccU0VGRqpgwYLq1auXJkyYoJiYGMXFxSlHjhxptk8957i4uKeOnd58bm5uKjLwv0qyZYcaAACyMnujSVMqJ2vIESN/PAsAQBbGmgCZ6cok35cdAgDgf5CYmKjAwED5+PjwhzIAAGRhrAkAAIDEmgAAgKwqNd8gIzvU2PxFMf0t3LlzR4mJiVbluXPntkimkaQdO3aoXr166t27t7y8vGQ0GuXm5qamTZuqb9++2rZt2xPnOnHihHkHljJlyqSZTCNJderU0bFjx8zJNJJUvHhxffnll+adbTIiKSlJ3333nZKSkqyOPyfTpMZ37do1LVy4UFWqVJGHh4fc3NxUoUIFLVq0SDExMfrxxx+fOu/Vq1f17rvvqlChQpo7d65mzZolBweHdJNpAAAAAAAAAAAAAAAAAAAAAAAAXrYslVAjSbGxsXr48GGax+Ob9fj4+CgoKEhz5szRzZs3lZCQoAcPHmjr1q2aOXOm3n333afO9fDhQz148CDNIzY21tzutddey5RzS0lJSTOhJikpyaptmTJllD9/fvXq1Us///yzIiMjFRUVpd9++009evRQtmzZVK1atTTnCQ0N1bx589SqVSsVK1ZMRYoU0d69e/X9999r0aJFKlCggPr376/AwMBMOS8AAAAAAAAAAAAAAAAAAAAAAIDMlOUSanx8fJQ9e/Y0j/DwcHO7Nm3aaMOGDfruu+9UtmxZOTo6Kn/+/PL391evXr305ZdfPnWupk2bysPDI81j8ODBmX5uvr6+srOzS/MICQmxaOvs7KyDBw/K09NTbdu2Va5cueTp6akmTZooISFBhw8f1iuvvJLmPLa2tgoKClLVqlV1/vx5LVq0SC4uLqpcubKOHz+ulStXysnJybxDDwAAAAAAAAAAAAAAAAAAAAAAwN+JwfT4tizAP0BkZKTc3Nx0584deXp6vuxwAADAS5SYmKjAwED5+PjIzs7uZYcDAABeEtYEAAAgFesCAAAgsSYAAACPsCYAACBrSs03iIiIkKur6xPbZrkdagAAAAAAAAAAAAAAAAAAAAAAAJC1kVADAAAAAAAAAAAAAAAAAAAAAACALIWEGgAAAAAAAAAAAAAAAAAAAAAAAGQpJNQAAAAAAAAAAAAAAAAAAAAAAAAgSyGhBgAAAAAAAAAAAAAAAAAAAAAAAFkKCTUAAAAAAAAAAAAAAAAAAAAAAADIUkioAQAAAAAAAAAAAAAAAAAAAAAAQJZCQg0AAAAAAAAAAAAAAAAAAAAAAACyFBJqAAAAAAAAAAAAAAAAAAAAAAAAkKWQUAMAAAAAAAAAAAAAAAAAAAAAAIAshYQaAAAAAAAAAAAAAAAAAAAAAAAAZCkk1AAAAAAAAAAAAAAAAAAAAAAAACBLIaEGAAAAAAAAAAAAAAAAAAAAAAAAWQoJNQAAAAAAAAAAAAAAAAAAAAAAAMhSSKgBAAAAAAAAAAAAAAAAAAAAAABAlkJCDQAAAAAAAAAAAAAAAAAAAAAAALIUEmoAAAAAAAAAAAAAAAAAAAAAAACQpZBQAwAAAAAAAAAAAAAAAAAAAAAAgCyFhBoAAAAAAAAAAAAAAAAAAAAAAABkKSTUAAAAAAAAAAAAAAAAAAAAAAAAIEshoQYAAAAAAAAAAAAAAAAAAAAAAABZCgk1AAAAAAAAAAAAAAAAAAAAAAAAyFJIqAEAAAAAAAAAAAAAAAAAAAAAAECWQkINAAAAAAAAAAAAAAAAAAAAAAAAshQSagAAAAAAAAAAAAAAAAAAAAAAAJClkFADAAAAAAAAAAAAAAAAAAAAAACALIWEGgAAAAAAAAAAAAAAAAAAAAAAAGQpJNQAAAAAAAAAAAAAAAAAAAAAAAAgSyGhBgAAAAAAAAAAAAAAAAAAAAAAAFkKCTUAAAAAAAAAAAAAAAAAAAAAAADIUkioAQAAAAAAAAAAAAAAAAAAAAAAQJZCQg0AAAAAAAAAAAAAAAAAAAAAAACyFBJqAAAAAAAAAAAAAAAAAAAAAAAAkKWQUAMAAAAAAAAAAAAAAAAAAAAAAIAshYQaAAAAAAAAAAAAAAAAAAAAAAAAZCkk1AAAAAAAAAAAAAAAAAAAAAAAACBLIaEGAAAAAAAAAAAAAAAAAAAAAAAAWQoJNQAAAAAAAAAAAAAAAAAAAAAAAMhSSKgBAAAAAAAAAAAAAAAAAAAAAABAlkJCDQAAAAAAAAAAAAAAAAAAAAAAALIUEmoAAAAAAAAAAAAAAAAAAAAAAACQpZBQAwAAAAAAAAAAAAAAAAAAAAAAgCyFhBoAAAAAAAAAAAAAAAAAAAAAAABkKSTUAAAAAAAAAAAAAAAAAAAAAAAAIEshoQYAAAAAAAAAAAAAAAAAAAAAAABZCgk1AAAAAAAAAAAAAAAAAAAAAAAAyFJIqAEAAAAAAAAAAAAAAAAAAAAAAECWQkINAAAAAAAAAAAAAAAAAAAAAAAAshQSagAAAAAAAAAAAAAAAAAAAAAAAJClkFADAAAAAAAAAAAAAAAAAAAAAACALIWEGgAAAAAAAAAAAAAAAAAAAAAAAGQpJNQAAAAAAAAAAAAAAAAAAAAAAAAgSyGhBgAAAAAAAAAAAAAAAAAAAAAAAFkKCTUAAAAAAAAAAAAAAAAAAAAAAADIUkioAQAAAAAAAAAAAAAAAAAAAAAAQJZi+7IDAJ5XlYlBSrJ1ftlhAACAl8jeaNKUylLpsTsVn2x42eEAAIBMdmWS78sOAU9x4cIFDRo0SEeOHFFSUpIaNGig2bNny8PDw6rtuXPnNGLECB05ckSJiYny9vbW4MGD1aZNG0lSaGioRowYoeDgYMXFxSlXrlzq1auXevXqJUmKiorS6NGjtXXrVkVHR8vd3V3t27fXiBEjZDQaVaRIEUVHR1vMGRsbqwoVKig4OFhRUVH67LPPtHHjRj18+FCOjo5q2bKlPv/8c9nb21vF6+Pjo+3bt8tkMpnLVq1apenTp+vGjRuys7NT1apVNXHiRBUpUsTc5uTJk2revLni4uJ048YNc/n8+fPl7+9vNc/t27cVFBSkOnXqyM/PTxs3bpSjo6O5Pnfu3Dpx4oQkKSUlRWPGjNGSJUuUkJCgSpUqaf78+SpYsKDVuIcOHVLNmjU1evRojR07NlOucXh4uMaMGaMdO3YoPj5erq6u6tSpk0aMGCGDgfU4AAAAAAAAAAAAgH+Wl75DTd68eWUwGMxHhw4dzHVLlixR+fLl0+2b+mX2sGHD5OfnJ0mqU6eOAgICMjz/41+Ijx07Vs2bN89w32ed61n98ssvMhgM+uOPPzJlvKfFe+LECRkMBl2/fj1T5nsWfn5+6tev318+LwAAAAAAAJ5PdHS0GjZsqMKFC+vy5cu6ceOGvLy81LFjR6u2JpNJPj4+cnV11ZkzZxQaGqqhQ4eqffv2OnjwoCSpffv2CgsL088//6zQ0FDNnTtXQ4cO1apVqyRJffv21Y8//qi9e/cqLCxM69ev11dffaUpU6ZIki5evKiwsDCLo1mzZqpYsaKkR/e+jEaj9u/fr7CwMB06dEi7du3S6NGjreJduHChYmNjLcr27t0rPz8/jRo1SqGhoTp9+rTs7e3l6/v/iV8bN25U06ZNVbVqVasxe/XqZRXf/v375eDgoJIlS5rbzZw506JNajKNJE2ePFkbNmzQTz/9pNDQUJUsWVK+vr5KSkqymCsmJkbdunVTtWrVLMr/12u8b98+FSlSRMeOHVNYWJgCAwM1b948zZ8/3+p8AQAAAAAAAAAAAODv7qUl1Ny/f19XrlzRgQMHdP78efPx2Wef6cqVK4qLi7PqU69ePdna2pqPunXrZni+5ORki762trYyGo3KmTNnun18fX2t+hgMBp09ezZDcwYHB1skC/35sLOze2L/+fPny9XVVdmzZ8/QfPv27VPNmjXl4uKiV199VQEBAUpJSclQX0nasGGDXF1d9corr2S4z+PWr18vFxcXi6QoSbpx44YMBoOuXLnyXOMCAAAAAADg7+fgwYMKDQ3V5MmTZW9vr2zZsmny5Mk6cOCArl69atH21q1bunjxovr27Stn50c7Drdq1UrFihVTSEiIJCkkJEQ9e/ZUjhw5JEm1atVSrVq1dOjQIUmPdlzp2LGj8ufPL0kqVaqUmjVrZq7/s+vXr2vdunXmh7jUqFFDkyZNUt68eSU9etBPvXr1dPLkSYt+V69e1aRJkzR16lSL8pCQEJUsWVLNmjWTJLm4uKhPnz46e/as7t27J0mqWrWqzp49q3feeSdD13DatGnq0KGDcufO/dS2JpNJM2fO1KhRo5Q3b14ZjUaNHz9e165d065duyzaDhs2TG3atFHRokWtzuF/ucZt2rTRkCFDzDsQFS1aVJUrV7a6hgAAAAAAAAAAAADwT/DSEmrmzZunqlWrqkaNGqpZs6b5qF69uqpWrapffvnFqs/27dv18OFDxcbG6qOPPlKxYsUyPJ/RaNSDBw/Mx8OHD1W3bl3zF+BpWb9+vbl9VFSU/P39VbZsWZUoUSJDc9aqVUtRUVFpHrt375aTk1Oa/RISEjRy5Eht3bpV9erVS/OL/T87efKkGjZsqBYtWuj8+fNaunSpZsyYYZEMtG/fvnT7HzhwQFOmTJG9vb0GDBjwTIk4kjRo0CBNmzZNlSpVylD748ePW8S2bNmyZ5oPAAAAAAAAL1dsbKxsbGxkNBrNZUlJSUpMTNSZM2cs2ubJk0f16tXTlClTdO/ePSUnJ2vFihUKCwtTkyZNJEnt2rXT7NmzdfPmTZlMJu3cuVOHDx9WmzZtzPXffPONzp8/L0k6evSoNm/erHbt2qUZ34wZM9SiRQu9+uqrVnUpKSk6ePCg1q9fr/bt25vLTSaTunTpookTJ1o9iKdp06a6du2aVq1apZSUFN29e1dTp05V48aNzQkqXl5eypYtW4au361bt7R8+XINHDgwQ+0vX76s8PBw1ahRw1zm6OioihUrmpOSpEcP+dm/f79GjBhhNUZmXuOkpCQFBgZq//79eu+99zJ0DgAAAAAAAAAAAADwd/LSEmpGjhypsLAwnTlzRgsXLtTUqVO1ZcsWhYWFKSwsTNWrV7fqky1bNjk4OMjOzk4///yzypYt+0xzuri4mI81a9bo8OHDmjBhQrrtHRwczO0vXLigyZMna/r06RZt+vfvL4PBoICAAKv+RqPRYs7Hj+TkZLm5uVm0v379umbPnq0yZcpox44d+vHHH7V+/Xq99957qlatmpo2baply5bpwYMHVnMtXLhQVapU0cCBA+Xl5aW3335b/v7+KlmypJKSkpSUlJTmjj5JSUmaN2+eGjZsqAkTJujo0aPavXu3ateu/cQEnD/r3bu3Dh06pEKFCmWofbly5RQXF2c+OnfunOG5AAAAAAAA8PLVqFFD9vb28vf3V1xcnCIjI9W3b18ZjUbzji2P27JliyIiIuTp6SlnZ2cNHjxYO3bsUPHixSVJCxYsUMGCBZUvXz45OjqqTZs2Wrp0qWrVqiVJGj16tFq0aKESJUrIwcFBNWrUkL+/v95//32ruR48eKCFCxdq0KBBVnWnTp2Sk5OTateure7du1sk1MyZM0ceHh7mBJPHlSxZUoGBgRowYICcnJyUM2dOxcbGav369c91/WbNmqX69eubzz/V4MGDlSdPHhUuXFht27bVsWPHJEnh4eGSHiUnPS5PnjzmuqioKHXr1k2LFi1Kc3fszLrGO3bskJOTk1q3bq3Jkyfrrbfeeq5rAAAAAAAAAAAAAAAv00tLqJGkPXv2qGjRovrqq6+0Z88edejQQb6+vjp06JAMBkO6SRYRERH65ZdfzE+vlKTk5GTFxcVlaGeVpUuXqnv37jIajRlKGvn555/VuHFjVatWTQEBAYqJiTHXff7557p//7569eqVgTP+f3fu3FGuXLksytauXastW7bo008/1eHDh3Xnzh0VKlRIgwYN0uXLl1WrVi1t3rxZtra2VuMlJiZaPf3SwcFBSUlJ6cYwZcoU5c+fX7NmzdKGDRvUv39/FShQQEePHlWtWrXk4+Oj4sWLP3V3HEkqUKBABs/8kWPHjsnOzs58fPPNN8/UHwAAAAAAAC+Xp6endu7cqUOHDqlIkSLmHahz5Mih7NmzW7Q1mUxq0aKFHB0dFRYWpsjISE2cOFG+vr7me089evTQhQsXdPHiRT18+FCrVq2Sn5+fgoKCJEkTJkzQ+vXrdezYMcXExOiHH36Qv7+/li9fbhXbvHnzVLlyZVWoUMGqrlSpUoqOjtahQ4e0dOlS+fv7S5IuXLigadOmad68eWme78mTJ9W0aVNNnDhRkZGRCgsLk4ODg5o3by6TyfRM1y46Olrz58+3Svj54osvFBoaqvDwcB04cEDe3t566623dOHCBfN9T4PBYNHHxsbGXDdw4EC9//77aZ63lHnXuFGjRoqOjtZ3332nYcOGacmSJc90/gAAAAAAAAAAAADwd2CdmfEXmjBhgnr37q2xY8dKkmJiYuTt7a3o6GglJiZq5cqVVjvCSNKKFSuUI0cOFSxY0KJsxYoVkqSWLVumOd/Nmzc1YMAA7dq1S5s3b1aOHDnk4+Oj4OBgTZw40ap9ZGSkpk+frjlz5mjx4sVq0qSJunTpovLly2v+/PmSJEdHR7m7u1v1jYuLe+K5X7lyRXny5DG3c3Bw0IABAzRgwABzm/j4eN24cUOSlDNnTg0ZMiTd8Tp27KhatWpp8eLFatOmjS5cuCB/f3/dvHlT5cuXlyRdvHjRIgmpatWqWrBggXx9fWU0Gs3lTk5OmjhxooYPH669e/eqdOnSTzyXZ5WUlKSCBQvq7Nmzunr1qipVqmRx3n8WHx+v+Ph48+vIyEhJkr2NSUbjs/2xAgAA+HextzFZ/AsAAP5dEhMTn6ldRtsj85QrV07btm0zv37w4IH8/PxUsmRJi/dj37592rNnj27fvi0nJydJUvv27bVr1y5NmjRJn376qRYuXKjTp0/L29tbJpNJDRo0ULdu3TR27FhVqVJF48aN06ZNm/T6668rOTlZVapU0ahRozRy5EiLHVTi4+M1a9YsLVq06ImfifLly2vYsGEaNmyYRowYoU6dOmn8+PHy8PBQYmKi1edq6tSpeuedd8w72uTIkUMLFy5U7ty5tWvXLr399tvmsZOTky36/tmXX36pYsWKqUqVKhZtXF1dZTKZlJiYqJw5c2rSpEnauHGj1q1bJ19fX0mPdqrx8vIy97l7964KFCig7du369ChQwoJCTGPmZKSouTkZCUmJurKlSuZdo1T1apVSz169NCcOXMsdvoBgJeJdQEAAJBYEwAAgEdYEwAAkDU9y+/+l5pQ8+qrr+ro0aMKDw+Xp6en9u3bp5iYGEVFRalmzZq6c+eOXFxcLPqkfiEeHh6uTZs2qXnz5pKkTp06acmSJapTp06acw0fPlwzZszQe++9p9OnTytPnjySpBMnTmjo0KG6cOGCRftjx46pdu3aqlq1qg4fPqwiRYpIkhYvXqz58+fL3t4+3fNKa/eZ9Dg6OkqSfH19Lf744HF/fupkahx+fn7m11WqVNHatWs1dOhQde3aVS4uLhoyZIh69uxpbtOsWTOLMWrXrv3E2FxdXdW0adMMnUdGFCpUyGLsQoUKqWTJkipZsuQT+02cONH8pNDHjaqQIien5EyLDwAA/HONe+PpuxQCAIB/nsDAwGdqv2vXrhcUCTJqw4YNKly4sE6ePGmx63FISIgMBoOCgoIsHuxy584d3b9/X999950k6dChQzp37py5/vr167p+/bo2b96s+Ph4HTt2zOLBK2fPntWdO3csPis7d+4079z8eHlycrLF3JJ06tQpc7ujR4/q2LFj5vtpqbvOuLu7q3Hjxrp+/brc3NysxjQYDPrhhx8UGxtrLj9+/Lji4uLS/AwnJydr8uTJ6ty581M/4yaTSZGRkbpx44bOnz8vJycnLViwQG+++aZ5rCNHjqhixYpasWKFLly4oNy5c5v7JyQkyGAwaPr06RoxYsT/fI3TuoaXL19WVFTUM/+8AsCLxroAAABIrAkAAMAjrAkAAMhaYmJiMtz2pSbUfPHFF+rXr5/KlSunqKgoFSlSREuWLJGPj4/KlCmjDRs2aOXKlRZ9xo8fLycnJ82bN08DBw5MN4Hmz3r27KkePXpY7GojSV5eXlq2bJmkRxeuVKlSkh49ofLw4cN6/fXXLdqbTCb16tVLklSyZEmLp0Gmypkzp/kL94xKTEw0P7kyI+zs7KzKmjVrpmbNmik+Pl7ZsmWzSsR5vE/r1q21fv36DM93+fJlq2uXUfny5dP9+/clPUoOcnR0VLZs2TLcf/jw4RY72ERGRsrb21vjf7VRkp3xCT0BAMC/nb2NSePeSNHon2wUn2KdhAwAAP7ZTo5tmKF2iYmJ2rVrl+rXr5/mPRO8OCEhIapcubIMBoPWrVunrVu3auvWrSpXrpxatGihhg0bqm/fvqpcubK+/vpr7dy5U5MnT5azs7MCAwP1448/avbs2Xr//fc1b948bd68WV999ZU8PT11+PBh7dy5Uz169FDbtm21YMECbdmyRW3btpW3t7fOnDmjwYMHq3Xr1vLx8ZH0aEeWwYMHa8yYMeayVCNHjpS7u7s+/PBDeXh46PLlyxo2bJi6dOkiHx8fRUdHW7S/cuWKihcvrgcPHkiSli1bpt69e+vjjz82tx86dKhcXFzUt29f5cyZ09z3zp072rBhg1UMkvTtt9/Kzc1Nn332mWxsbMzlt27dMj9EJ0+ePIqKitLo0aPl7u6ucePGycXFRb169dKWLVvUvXt35cyZU59++qk8PDw0cuRIOTo6asmSJRZzde3aVQUKFNCYMWOUkJCgJUuW/E/XuFu3bqpataref/99OTs76/jx4woKCtKIESPSPFcAeBlYFwAAAIk1AQAAeIQ1AQAAWVNkZGSG277UhBoPDw8tXbo0zbqiRYtaPE1RkrZt26Zp06Zp3759qlSpkpYvX64mTZqoUqVKT52rQIECkh4l5IwePTrdds2aNVObNm0kyZxMs2bNGs2cOVMnTpzQw4cPlT17dpUvX16DBg3Su+++m+5YCQkJ2rdvn2rXrv3UBBI7OzvZ2dkpPj7+ick4dnZ2Vk+B/LMn7Z6Tas2aNUpJsXyS+969e+Xr66uHDx9atbe1ff6PisFgkLu7+3P3t7e3T/Oc4lMMSkrmD2cBAMCjdUE86wIAAP51nvXLrdT7K/jrzJo1S8HBwbKxsVGpUqW0fft2ValSRdHR0Tp37pxKly4tOzs7eXl5KSgoSCNHjlTJkiUVGxurvHnzKiAgQF27dpUkff/99xoxYoTefPNNRUdHy83NTQMGDNDgwYNlNBq1bt06jRo1SnXr1tXDhw9lb2+vDh06aMyYMeb3fePGjYqJidEHH3xg9Vno27ev/P39VblyZcXGxsrV1VXt2rXTyJEj0/zcpJal/tu1a1clJydrzJgx6t69u+Lj41W9enUFBQVZPXQn9f5dWuMGBASof//+Vve7PD09FRMTozp16igyMlIpKSlq1KiR9uzZIw8PD0mPdnJOTEzUG2+8ocTERFWsWFE7d+6Uq6trmu+PjY2NjEaj+Wfjf73GQ4cO1bhx4zR+/HglJSUpR44cGj58uD755JM0d9kGgJeJdQEAAJBYEwAAgEdYEwAAkLU8y+99g+lZt1LJZCaTSREREXJ1dbV4IqMk/frrrzp48KA+/vhjhYSE6O2339bcuXPVpUsXSY+e2ti/f3+5uroqNjZWS5YsUZ06ddS8eXP169cvzfmSk5OVmJiYZt348eN18uRJbdq0yVy2fv16dejQQV988YWaNGkiDw8P3b17V5s2bdLQoUO1adMmNW7cOM3xwsLC5OXlpdDQUOXNmzdD18PFxcXqaZiPmz17tj755JN06wMCAhQYGKjvv//equ63336Tp6enXnnllTT7BgcHq1GjRoqLi8tQrGnx8/NTUlKSVqxYYVW3fft2TZgwQfv377eq+/3332Vra6uiRYs+dY7IyEi5ubmpyMD/KsnW+bljBQAA/3z2RpOmVE7WkCNGEmoAAPgXujLJN0PtEhMTFRgYKB8fH74QAwAgi2NdAAAAJNYEAADgEdYEAABkTan5Bql5Kk/yUneokaS7d+8qV65cunz5sgoWLGhRV6FCBVWoUEGSVKlSJW3YsMEieSV37tz69ttvNWzYMMXGxmZoPqPRmO4OL2ntwrJnzx698847+uijj8xl2bNnV79+/bR582b98MMP6SbUPI+0dodJVbVq1af2T0pKUkJCQpp1ZcqUee64MkN0dLRu3LiRZt1rr732F0cDAAAAAAAAAAAAAAAAAAAAAACyqpeeUJMqJiYm3WQSZ2dn2dnZZWriSkY1aNBA77//vubPny9fX195eHjo/v372rBhgw4ePKjhw4c/dYzIyEg5ODikWefi4pJmIs//Ijk5Od1raWtrm24smWHJkiVPrDeZTOnGZmNjIycnpxcQFQAAAAAAAAAAAAAAAAAAAAAAwP+zedkBpCpVqpSyZ8+e5hEeHv6XxFCxYkXVr1/fouzdd9/VqlWrtG7dOpUrV07u7u4qX768tm3bpo0bN6pBgwZPHbdEiRLy8PBI89ixY0emn8f+/fvTvZbNmzd/rjEDAgKUN29eq2Px4sXPNM61a9fSja1ixYrPFRsAAAAAAAAAAAAAAAAAAAAAAMCzMJhMJtPLDgIZExoaKhcXF2XPnv1lh/JSRUZGys3NTXfu3JGnp+fLDgcAALxEiYmJCgwMlI+Pj+zs7F52OAAA4CVhTQAAAFKxLgAAABJrAgAA8AhrAgAAsqbUfIOIiAi5uro+sa3tXxQTMoGXl9fLDgEAAAAAAAAAAAAAAAAAAAAAAOAfz+ZlBwAAAAAAAAAAAAAAAAAAAAAAAAD8lUioAQAAAAAAAAAAAAAAAAAAAAAAQJbyXAk1kZGRun79uvn1li1btHz5cplMpkwLDAAAAAAAAAAAAAAAAAAAAAAAAHgRniuhpn///tq6daskae3aterSpYuGDRum0aNHZ2pwAAAAAAAAAAAAAAAAAAAAAAAAQGZ7roSanTt3qnPnzpKkadOmaefOnfrll1/07bffZmpwAAAAAAAAAAAAAAAAAAAAAAAAQGazfd6Ojo6O+uWXX2QymVSpUiVJUlxcXKYFBgAAAAAAAAAAAAAAAAAAAAAAALwIz5VQky9fPo0ZM0ZBQUHq06ePJOnGjRvKnj17pgYHAAAAAAAAAAAAAAAAAAAAAAAAZDab5+k0ffp0BQYGqnz58urQoYMkaeHChWrRokWmBgcAAAAAAAAAAAAAAAAAAAAAAABktufaoaZGjRr66aefLMr69+8vR0fHTAkKAAAAAAAAAAAAAAAAAAAAAAAAeFGea4easLAwNWzYUHny5DGXfffdd9qzZ0+mBQYAAAAAAAAAAAAAAAAAAAAAAAC8CM+VUDNo0CCVLVvWoqxkyZLy9/fPlKAAAAAAAAAAAAAAAAAAAAAAAACAF+W5EmoOHDigzz//XDY2/9+9fPnyunr1aqYFBgAAAAAAAAAAAAAAAAAAAAAAALwIz5VQEx8fLzs7O4uylJQUJSUlZUpQAAAAAAAAAAAAAAAAAAAAAAAAwIvyXAk13t7eunbtmgwGg7ls+fLlKly4cKYFBgAAAAAAAAAAAAAAAAAAAAAAALwIts/TafLkyfrggw8UGxurgIAAHT16VGvXrtXGjRszOz4AAAAAAAAAAAAAAAAAAAAAAAAgUz3XDjV16tTRlClTVLVqVc2fP1+hoaHatm2bfH19Mzs+AAAAAAAAAAAAAAAAAAAAAAAAIFM91w41RYsW1alTp7R9+/bMjgcAAAAAAAAAAAAAAAAAAAAAAAB4oZ5rh5q4uDgZjcbMjgUAAAAAAAAAAAAAAAAAAAAAAAB44Z4roaZ3797q16+fEhMTMzseAAAAAAAAAAAAAAAAAAAAAAAA4IWyfZ5OU6dO1b1797Ro0SLlypXLou7atWuZEhgAAAAAAAAAAAAAAAAAAAAAAADwIjxXQs0XX3yR2XEAAAAAAAAAAAAAAAAAAAAAAAAAf4nnSqjp1KlTZscBAAAAAAAAAAAAAAAAAAAAAAAA/CWeK6GmS5cu6dZ98803zx0MAAAAAAAAAAAAAAAAAAAAAAAA8KLZPE+nAgUKmI9XX31VsbGxWrVqlVxcXDI7PgAAAAAAAAAAAAAAAAAAAAAAACBTPdcONZ9++qlV2X//+199//33/3NAAAAAAAAAAAAAAAAAAAAAAAAAwIv0XDvUpOW9997Tjh07Mms4AAAAAAAAAAAAAAAAAAAAAAAA4IXItISaP/74QyaTKbOGAwAAAAAAAAAAAAAAAAAAAAAAAF4I2+fp1LFjR4vX0dHR2rdvnz744INMCQoAAAAAAAAAAAAAAAAAAAAAAAB4UZ4rocZoNFq89vb21pw5c9SmTZtMCQoAAAAAAAAAAAAAAAAAAAAAAAB4UZ4roWbSpEnKkyePRVl4eLiCgoJUv379TAkMAAAAAAAAAAAAAAAAAAAAAAAAeBFsnqdThQoVrMqcnZ3Vrl27/zkgAAAAAAAAAAAAAAAAAAAAAAAA4EXK8A41Dx480L179yRJSUlJunz5skwmk7k+PDxccXFxmR8hAAAAAAAAAAAAAAAAAAAAAAAAkIkynFAzc+ZM+fv7y2AwSJKKFi1qrjOZTDIYDOrcuXPmRwgAAAAAAAAAAAAAAAAAAAAAAABkogwn1PTr109+fn4ymUyqXLmyjh49alHv5OSkXLlyZXqAAAAAAAAAAAAAAAAAAAAAAAAAQGbKcEKNm5ub3NzcJEmff/65ChQo8MKCAgAAAAAAAAAAAAAAAAAAAAAAAF6UDCfUPK5t27aaNGmSLl68qOTkZIu6b775JlMCAwAAAAAAAAAAAAAAAAAAAAAAAF4Em+fp5Ofnp23btunkyZOKiYmRvb291q5dK2dn58yODwAAAAAAAAAAAAAAAAAAAAAAAMhUz7VDTUhIiC5fvqzFixfLxsZG3bt3V6NGjbRly5bMjg8AAAAAAAAAAAAAAAAAAAAAAADIVM+1Q43RaJS9vb0KFiyoK1euSJKaNWumnTt3ZmZsAAAAAAAAAAAAAAAAAAAAAAAAQKZ7roSaQoUK6aefflLFihX13XffKSkpSeHh4YqNjc3s+AAAAAAAAAAAAAAAAAAAAAAAAIBM9VwJNf369dPOnTuVO3duvfbaaypatKgqVKighg0bZnZ8AAAAAAAAAAAAAAAAAAAAAAAAQKayfZ5OLVu2NP/3ypUr9e233yo2NladOnXKtMAAAAAAAAAAAAAAAAAAAAAAAACAF+G5dqhJSUnRpEmT1KpVK9na2qpTp04qXbq0bt68mdnxAQAAAAAAAAAAAAAAAAAAAAAAAJnquRJqRo8erR07dmjv3r3msoiICPXv3z/TAgMAAAAAAAAAAAAAAAAAAAAAAABehOdKqFmzZo02b94sOzs7c1mDBg3066+/ZlpgAAAAAAAAAAAAAAAAAAAAAAAAwIvwXAk1MTExcnNzsyizs7NTfHx8pgQFAAAAAAAAAAAAAAAAAAAAAAAAvCjPlVDj7OysqKgoi7IDBw4oZ86cmRIUAAAAAAAAAAAAAAAAAAAAAAAA8KI8V0LNwIEDNXToUKWkpOj48eP6+uuv1bZtW3Xr1i2z4wMAAAAAAAAAAAAAAAAAAAAAAAAyVYYTajZu3Gj+7x49eqhw4cKKjY1VhQoV1LdvX3Xu3Fl9+/Z9IUECAAAAAAAAAAAAAAAAAAAAAAAAmcU2ow0//vhjtWjRwvx6+vTpunfvnm7fvi1PT09ly5bthQQIAAAAAAAAAAAAAAAAAAAAAAAAZKYMJ9SYTCar17a2tvLy8sr0oAAAAAAAAAAAAAAAAAAAAAAAAIAXxSajDQ0GwxNfAwAAAAAAAAAAAAAAAAAAAAAAAP8EGU6oAQAAAAAAAAAAAAAAAAAAAAAAAP4NbDPaMCYmRosXL5bJZJIkxcbGWrxO1aVLl8yNEAAAAAAAAAAAAAAAAAAAAAAAAMhEGU6ocXd312effZbua0kyGAwk1OAvU2VikJJsnV92GAAA4CWyN5o0pbJUeuxOxScbXnY4AADgGV2Z5PuyQ8BTXLhwQYMGDdKRI0eUlJSkBg0aaPbs2fLw8LBqe+7cOY0YMUJHjhxRYmKivL29NXjwYLVp08bcJjY2Vh9//LEWL16sXbt26Z133jHXLVmyRL169ZKbm5vFuPv371fRokV1//59TZgwQWvWrFFCQoLc3NzUp08fffzxx1ax3L9/X6VLl1axYsUUHBxsUTd37lz169dPQ4cO1fjx4y3qZs2apa+//lp37tyRvb296tWrp4kTJyp37tzmNvv27VPr1q1VvHhx7d+/32rsRYsW6Y8//pCdnZ2qV6+uqVOnqkCBAuY2Fy9e1KBBgxQSEqLExEQVK1ZMhw4dkiT5+flp48aNcnR0NLfPnTu3Tpw4IUkKDw/X4MGD9cMPPyg+Pl5VqlTR/Pnz5e3tbW5/69YtDRkyRLt27VJCQoLy58+vXbt2KWfOnJKkhw8fatSoUdqwYYPi4uLk6emp9evXq2TJkoqKitLo0aO1detWRUdHy93dXe3bt9eIESNkNBqtrjMAAAAAAAAAAAAA/JPZZLThlStXdPny5Scely5deuYA8ubNK4PBYD46dOhgrluyZInKly+fbt/U3XGGDRsmPz8/SVKdOnUUEBCQ4fkf32Fn7Nixat68eYb7Putcz+qXX36RwWDQH3/8kSnjPS3eEydOyGAw6Pr165ky37Pw8/NTv379/vJ5AQAAAAAAkLbo6Gg1bNhQhQsX1uXLl3Xjxg15eXmpY8eOVm1NJpN8fHzk6uqqM2fOKDQ0VEOHDlX79u118OBBSY92wC5VqlSayTip3nvvPYWFhVkcRYsWlSTNnDlTrq6uOnbsmMLCwrRq1Spzcsmf9e7dW8WLF7cqb9WqlQIDA/Xaa69Z1S1btkyffvqpvvrqK4WGhuqnn37StWvX9MEHH5jbzJo1S7169VK1atXSjD8oKEhLly5VeHi4zp8/L0dHR4uEouvXr+vtt99Wo0aNdP36dd2+fVuTJ0+2GGPmzJkW55+aTGMymdS8eXMlJCTo999/V1hYmOrXr6+mTZsqJSVFkhQZGam33npLhQsX1sWLF3X79m0tWrRI9vb2kqSkpCQ1btxYCQkJOnXqlG7duqXNmzeb35O+ffvqxx9/1N69exUWFqb169frq6++0pQpU9J9zwAAAAAAAAAAAADgnyrDCTWZ7f79+7py5YoOHDig8+fPm4/PPvtMV65cUVxcnFWfevXqydbW1nzUrVs3w/MlJydb9LW1tZXRaDQ/mTEtvr6+Vn0MBoPOnj2boTmDg4MtkoX+fNjZ2T2x//z58+Xq6qrs2bNnaL59+/apZs2acnFx0auvvqqAgADzl+kZsWHDBrm6uuqVV17JcB/p0Rfx8+bNU8mSJZUnTx55e3urd+/e5vfwxo0bMhgMunLlyjONCwAAAAAAgJfn4MGDCg0N1eTJk2Vvb69s2bJp8uTJOnDggK5evWrR9tatW7p48aL69u0rZ+dHOwq3atVKxYoVU0hIiCTJ3t5e+/bt0xdffPFc8YwaNUpjxoxRjhw5JEkVK1ZU6dKldfToUYt2Gzdu1M2bN9NM/Jk+fbq2bdsmT09Pq7pDhw6pTp06ql69uiQpZ86c6t69u3n3GElq0aKFfvvtN1WoUCHNGDds2KAyZcpIkhwdHdWyZUudOnXKXD9ixAj17t1bPXr0MN9rrF27dobO/8KFCwoJCdG0adPk4uIio9Govn37KiUlxbxTztSpU1W3bl2NGTNGDg4O5uuUen9x6dKlcnV11bx588xlxYsXl5eXl/kadOzYUfnz55cklSpVSs2aNbO4BgAAAAAAAAAAAADwb/HSEmrmzZunqlWrqkaNGqpZs6b5qF69uqpWrapffvnFqs/27dv18OFDxcbG6qOPPlKxYsUyPJ/RaNSDBw/Mx8OHD1W3bl01a9Ys3T7r1683t4+KipK/v7/Kli2rEiVKZGjOWrVqKSoqKs1j9+7dcnJySrNfQkKCRo4cqa1bt6pevXqqV6+eTp48+cS5Tp48qYYNG6pFixY6f/68li5dqhkzZlgkA+3bty/d/gcOHNCUKVNkb2+vAQMGPFMiTlBQkA4ePKjNmzcrPDxcv/zyi4KDg/X555+n2+f48eMWsS1btizD8wEAAAAAAODFi42NlY2NjYxGo7ksKSlJiYmJOnPmjEXbPHnyqF69epoyZYru3bun5ORkrVixQmFhYWrSpImkR/fnUhM1noetra3F6/v37+vs2bMqXbq0uez27dsaOHCgFi1aJIPBYDVGgQIF0h2/devW2r9/v3bv3i2TyaQbN25o7ty5Fjtqe3t7y8YmY7dUL126pFmzZpn7JyYmmhNuqlevrty5c6tOnToWCTdPEhsbK0nKli2bRXl8fLxOnz4tSVq1apXq1Kmj+vXrK0+ePHrjjTfMyTap9c2aNVOLFi3k5eWlUqVKaePGjeb6du3a6ZtvvtH58+clSUePHtXmzZvVrl27DMUIAAAAAAAAAAAAAP8kLy2hZuTIkQoLC9OZM2e0cOFCTZ06VVu2bFFYWJjCwsLMT4J8XLZs2eTg4CA7Ozv9/PPPKlu27DPN6eLiYj7WrFmjw4cPa8KECem2d3BwMLe/cOGCJk+erOnTp1u06d+/vwwGgwICAqz6G41GizkfP5KTk+Xm5mbR/vr165o9e7bKlCmjHTt26Mcff9T69ev13nvvqVq1amratKmWLVumBw8eWM21cOFCValSRQMHDpSXl5fefvtt+fv7q2TJkkpKSlJSUlKaO/qk7i7TsGFDTZgwQUePHtXu3btVu3btJybgPK5evXpasWKFOcEpV65caty4sdXTQR9Xrlw5xcXFmY/OnTtnaC4AAAAAAAD8NWrUqCF7e3v5+/srLi5OkZGR6tu3r4xGo+7du2fVfsuWLYqIiJCnp6ecnZ01ePBg7dixQ8WLF8/wnOvXr1f+/Pn1yiuvqG7duhbJHo8zmUzq1KmTqlSpIl9fX3N5r169NGDAABUqVOiZz7devXpavHixWrZsKUdHR3l7e6tYsWKaM2fOM4/l7e2tIkWKyMXFRTNnzpT06N6fyWTSjBkztGrVKl25ckXVqlVT3bp1FRkZae47ePBg5cmTR4ULF1bbtm117NgxSdLrr7+uokWLavjw4YqKilJsbKw+++wz3bp1S/fu3VNiYqIuX76s2bNna8aMGbp+/bo6d+6s+vXrm3cUOnfunObOnatBgwbp+vXrGjdunNq2bWveRWj06NFq0aKFSpQoIQcHB9WoUUP+/v56//33n/kaAAAAAAAAAAAAAMDf3UtLqJGkPXv2qGjRovrqq6+0Z88edejQQb6+vjp06JAMBkO6SRYRERH65ZdfzE+3lKTk5GTFxcVlaGeVpUuXqnv37jIajRlKGvn555/VuHFjVatWTQEBAYqJiTHXff7557p//7569eqVgTP+f3fu3FGuXLksytauXastW7bo008/1eHDh3Xnzh0VKlRIgwYN0uXLl1WrVi1t3rzZ6mmc0qMnXP756ZQODg5KSkpKN4YpU6Yof/78mjVrljZs2KD+/furQIECOnr0qGrVqiUfHx8VL178qbvjpBVPSEiIxdNB/+zYsWOys7MzH998880T5wAAAAAAAMBfy9PTUzt37tShQ4dUpEgR8w7TOXLkUPbs2S3amkwmtWjRQo6OjgoLC1NkZKQmTpwoX1/fp95bStWqVSuFh4frxo0bOnfunDp06KB27drpv//9r1Xb4cOH6/fff9fKlSvNZStXrtTt27f18ccfP9f5BgUFqXPnzlq1apUePnyoixcv6vz58+rRo8czj3X9+nVduXJFKSkp8vX1lclkUlhYmGJjYzV+/HgVKFBATk5OGjdunFJSUrR161ZJ0hdffKHQ0FCFh4frwIED8vb21ltvvaULFy7Izs5OgYGBunfvnl5//XVVqFBB2bNnN/97+/ZtpaSkqHfv3ipdurSyZcumjz/+WK+99ppWrFghSQoLC1OHDh1Uo0YN2draqmXLlmrSpIkWLVokSZowYYLWr1+vY8eOKSYmRj/88IP8/f21fPny57qmAAAAAAAAAAAAAPB3Zp0J8ReaMGGCevfurbFjx0qSYmJi5O3trejoaCUmJmrlypVWO8JI0ooVK5QjRw4VLFjQoiz1i+GWLVumOd/Nmzc1YMAA7dq1S5s3b1aOHDnk4+Oj4OBgTZw40ap9ZGSkpk+frjlz5mjx4sVq0qSJunTpovLly2v+/PmSJEdHR7m7u1v1jYuLe+K5X7lyRXny5DG3c3Bw0IABAzRgwABzm/j4eN24cUOSlDNnTg0ZMiTd8Tp27KhatWpp8eLFatOmjS5cuCB/f3/dvHlT5cuXlyRdvHjRIgmpatWqWrBggXx9fWU0Gs3lTk5OmjhxooYPH669e/c+MTEmLdOmTdOFCxe0fv36NOuTkpJUsGBBnT17VlevXlWlSpUszvvP4uPjFR8fb36d+sROexuTjEbTM8UGAAD+XextTBb/AgCAf5bExMRMHSezxsP/K1eunLZt22Z+/eDBA/n5+alkyZIW13vfvn3as2ePbt++LScnJ0lS+/bttWvXLk2aNEmLFy+2GjspKcliDAcHB0mP3kd7e3t98MEH2rdvn5YuXWpxv++LL77QihUr9MMPP8jNzU2JiYm6deuWhg4dql27dpkfMJOcnCyTyZTm58JkMik5Odmibty4cfrwww/VoEEDmUwmeXt768svv9Trr7+uQYMGqXDhwua2Txo71SuvvKLp06erePHiOn78uBwdHWUwGFS6dGmLfq+++qquXLmixMREubq6msfNmTOnJk2apI0bN2rdunUaOHCgChYsqDVr1ljEMXnyZI0aNUqOjo6SpLJly1qMX6hQIV29etU8frly5azqT506pYcPH2rcuHHatGmTXn/9dSUnJ6tKlSoaNWqURo4cyS41AP4xWBcAAACJNQEAAHiENQEAAFnTs/zuf6kJNa+++qqOHj2q8PBweXp6at++fYqJiVFUVJRq1qypO3fuyMXFxaJPfHy8Zs2apfDwcG3atEnNmzeXJHXq1ElLlixRnTp10pxr+PDhmjFjht577z2dPn1aefLkkSSdOHFCQ4cO1YULFyzaHzt2TLVr11bVqlV1+PBhFSlSRJK0ePFizZ8/X/b29umeV1q7z6Qn9YtuX19fiz9OeJzBYLAqW7x4sfz8/Myvq1SporVr12ro0KHq2rWrXFxcNGTIEPXs2dPcplmzZhZj1K5d+4mxubq6qmnTphk6j1Tbtm2Tv7+/du3aZXUNChUqZDF2oUKFVLJkSZUsWfKJY06cOFH+/v5W5aMqpMjJKfmZ4gMAAP9O4954+i6FAADg7ycwMDBTx9u1a1emjgdrGzZsUOHChXXy5EmLnWdCQkJkMBgUFBRk8eCWO3fu6P79+2m+10eOHLF4iEpaLl26JBsbG3P/wMBA/fe//9WECRN05swZnTlzRpJ06tQp3bp1S5UqVTL3TUpKUlJSktzd3TVgwAC98cYb5rq7d+/q4sWLFnFdvXpV+fPntyi7d++epEf3vFLvD0rS+fPnrc4rOTnZ4txT55GkAwcOKE+ePHJ0dNTixYuVL18+SY9u5J4/f153795N8xqZTCZFRkbqxo0badbv379fSUlJevDggfbt26dXXnlFq1atUoUKFcxtfv75Z9WqVUuBgYHy9vbWpk2bFBsba67/8ccf5eHhoc2bNys+Pl7Hjh2zeF/Onj2rO3fuZPrPKwC8aKwLAACAxJoAAAA8wpoAAICsJSYmJsNtX2pCzRdffKF+/fqpXLlyioqKUpEiRbRkyRL5+PioTJky2rBhg1auXGnRZ/z48XJyctK8efM0cODAdBNo/qxnz57q0aOHxa42kuTl5aVly5ZJenThSpUqJUkqX768Dh8+rNdff92ivclkUq9evSRJJUuWlJeXl9VcOXPmlMn0bE9JT0xMVHJyxpND7OzsrMqaNWumZs2aKT4+XtmyZbNKxHm8T+vWrdPdQSYtly9ftrp2f7Z37161b99eq1evVtWqVc3l+fLl0/379yU9Sg5ydHRUtmzZMjz38OHDLXawiYyMlLe3t8b/aqMkO+MTegIAgH87exuTxr2RotE/2Sg+xToJGQAA/L2dHNswU8ZJTEzUrl27VL9+/TTvmeD5hYSEqHLlyjIYDFq3bp22bt2qrVu3qly5cmrRooUaNmyovn37qnLlyvr666+1c+dOTZ48Wc7OzgoMDNSPP/6o2bNny8fHx2rsypUrq169eubXn3/+uVq0aKHXXntNycnJWrlypX7++WcFBwerfPnyWrZsmdatW6ddu3aZd2RO5ePjo8GDB1uULVu2TMuWLdPu3but5p4+fbqKFCliEddPP/2kBQsWqGfPnqpSpYru3r2rHj16qGjRourRo4fF/ayffvpJ169ft+i/ZcsWbdq0ScOGDVPhwoUVFRWl7t27680331S3bt1kMBjUsWNHrV+/XqtWrZKjo6NGjRqlPHny6LPPPlNERIT5ITp58uRRVFSURo8eLXd3d40bN04uLi46evSoypcvLzs7O/3www9atmyZ5s+fb34oTu/evbVy5Up16tRJefPm1Zw5c/Tw4UNNmTJFuXLlUkxMjIYOHaru3bvr9ddf17p163Ty5EkdOXJEr732mhYsWKAtW7aobdu28vb21pkzZzR48GC1bt06zfcQAP6OWBcAAACJNQEAAHiENQEAAFlTZGRkhtu+1IQaDw8PLV26NM26okWLKnfu3BZl27Zt07Rp07Rv3z5VqlRJy5cvV5MmTSyePJmeAgUKSHqUkDN69Oh02zVr1kxt2rSRJHMyzZo1azRz5kydOHFCDx8+VPbs2VW+fHkNGjRI7777brpjJSQkaN++fapdu/ZTE0js7OxkZ2en+Pj4Jybj2NnZWT3p8s+etHtOqjVr1iglxfJJ7nv37pWvr68ePnxo1d7W9skflcOHD6t58+b6+uuv5evra1FnMBjk7u7+1JjSY29vn+Y5xacYlJTMH84CAIBH64J41gUAAPzjZPaXV6n3V5B5Zs2apeDgYNnY2KhUqVLavn27qlSpoujoaJ07d06lS5eWnZ2dvLy8FBQUpJEjR6pkyZKKjY1V3rx5FRAQoK5du6Y5tq2trcX75e3trU6dOunmzZtKSEhQ+fLltXv3br355puSHt3Xi42NtdpRuWnTpvr666+txjcajTIYDGl+JgwGg4xGo0Xd2LFj5ezsrA8//FB3795VSkqK6tevr++//17Ozs5PHdvX11enT59Wy5YtdefOHdnb26tOnTrasmWL+d7g9OnTNWjQIJUuXVoJCQmqWbOmdu3aJRcXF9na2iomJkZ16tRRZGSkUlJS1KhRI+3Zs0ceHh6SpHXr1ql58+YyGAwqWLCglixZosaNG5tjGDJkiGJiYlSjRg3FxMSobNmy2rNnj1555RVJ0n/+8x/duXNHzZs314MHD1SoUCHt2LFDZcqUMY8/atQo1a1bVw8fPpS9vb06dOigMWPG8LMF4B+HdQEAAJBYEwAAgEdYEwAAkLU8y+99g+lZt1LJZCaTSREREXJ1dZWNjY1F3a+//qqDBw/q448/VkhIiN5++23NnTtXXbp0kSTdunVL/fv3l6urq2JjY7VkyRLVqVNHzZs3V79+/dKcLzk5WYmJiWnWjR8/XidPntSmTZvMZevXr1eHDh30xRdfqEmTJvLw8NDdu3e1adMmDR06VJs2bbL40vpxYWFh8vLyUmhoqPLmzZuh6+Hi4qLo6Oh062fPnq1PPvkk3fqAgAAFBgbq+++/t6r77bff5Onpaf4C/c+Cg4PVqFEjxcXFZSjWVMePH1fdunU1bdo0de7cOd1227dv14QJE7R//36rut9//122trYqWrToU+eLjIyUm5ubigz8r5JsnZ/aHgAA/HvZG02aUjlZQ44YSagBAOAf6Mok36c3yoDExEQFBgbKx8eHL8QAAMjiWBcAAACJNQEAAHiENQEAAFlTar5Bap7Kk9g8sfYvcPfuXXl4eOjatWtWdRUqVNDHH38sSapUqZI2bNhgTqaRpNy5c+vbb7+Vm5tbhuczGo1ycHBI80hrF5Y9e/bonXfe0UcffaRXX31V2bNnV8GCBdWvXz9Vr15dP/zww3OcdfoePnwok8mU5lGlSpWn9k9KSlJCQkKadWXKlEk3meZ/ERAQoIiICA0fPlx58+Y1H6VKlbJoFx0drRs3bqQ5xmuvvZahZBoAAAAAAAAAAAAAAAAAAAAAAID/lXUGyUsSExOjhw8fplnn7OwsOzu7dHeCeZEaNGig999/X/Pnz5evr688PDx0//59bdiwQQcPHtTw4cOfOkZkZKQcHBzSrHNxcUkzked/kZycnO61tLW1TTeW57V48WItXrw4Q21NJlO6sdnY2MjJySkzQwMAAAAAAAAAAAAAAAAAAAAAALDy0neoSVWqVCllz549zSM8PPwviaFixYqqX7++Rdm7776rVatWad26dSpXrpzc3d1Vvnx5bdu2TRs3blSDBg2eOm6JEiXk4eGR5rFjx45MP4/9+/eney2bN2/+XGMGBARY7D6TemQ0kSbVtWvX0o2tYsWKzxUbAAAAAAAAAAAAAAAAAAAAAADAszCYTCbTyw4CGRMaGioXFxdlz579ZYfyUkVGRsrNzU137tyRp6fnyw4HAAC8RImJiQoMDJSPj4/s7OxedjgAAOAlYU0AAABSsS4AAAASawIAAPAIawIAALKm1HyDiIgIubq6PrGt7V8UEzKBl5fXyw4BAAAAAAAAAAAAAAAAAAAAAADgH8/mZQcAAAAAAAAAAAAAAAAAAAAAAAAA/JVIqAEAAAAAAAAAAAAAAAAAAAAAAECWQkINAAAAAAAAAAAAAAAAAAAAAAAAshQSagAAAAAAAAAAAAAAAAAAAAAAAJClkFADAAAAAAAAAAAAAAAAAAAAAACALIWEGgAAAAAAAAAAAAAAAAAAAAAAAGQpJNQAAAAAAAAAAAAAAAAAAAAAAAAgSyGhBgAAAAAAAAAAAAAAAAAAAAAAAFkKCTUAAAAAAAAAAAAAAAAAAAAAAADIUkioAQAAAAAAAAAAAAAAAAAAAAAAQJZCQg0AAAAAAAAAAAAAAAAAAAAAAACyFBJqAAAAAAAAAAAAAAAAAAAAAAAAkKWQUAMAAAAAAAAAAAAAAAAAAAAAAIAshYQaAAAAAAAAAAAAAAAAAAAAAAAAZCkk1AAAAAAAAAAAAAAAAAAAAAAAACBLIaEGAAAAAAAAAAAAAAAAAAAAAAAAWQoJNQAAAAAAAAAAAAAAAAAAAAAAAMhSSKgBAAAAAAAAAAAAAAAAAAAAAABAlkJCDQAAAAAAAAAAAAAAAAAAAAAAALIUEmoAAAAAAAAAAAAAAAAAAAAAAACQpZBQAwAAAAAAAAAAAAAAAAAAAAAAgCyFhBoAAAAAAAAAAAAAAAAAAAAAAABkKSTUAAAAAAAAAAAAAAAAAAAAAAAAIEshoQYAAAAAAAAAAAAAAAAAAAAAAABZCgk1AAAAAAAAAAAAAAAAAAAAAAAAyFJIqAEAAAAAAAAAAAAAAAAAAAAAAECWQkINAAAAAAAAAAAAAAAAAAAAAAAAshQSagAAAAAAAAAAAAAAAAAAAAAAAJClkFADAAAAAAAAAAAAAAAAAAAAAACALIWEGgAAAAAAAAAAAAAAAAAAAAAAAGQpJNQAAAAAAAAAAAAAAAAAAAAAAAAgSyGhBgAAAAAAAAAAAAAAAAAAAAAAAFkKCTUAAAAAAAAAAAAAAAAAAAAAAADIUkioAQAAAAAAAAAAAAAAAAAAAAAAQJZCQg0AAAAAAAAAAAAAAAAAAAAAAACyFBJqAAAAAAAAAAAAAAAAAAAAAAAAkKWQUAMAAAAAAAAAAAAAAAAAAAAAAIAshYQaAAAAAAAAAAAAAAAAAAAAAAAAZCkk1AAAAAAAAAAAAAAAAAAAAAAAACBLIaEGAAAAAAAAAAAAAAAAAAAAAAAAWQoJNQAAAAAAAAAAAAAAAAAAAAAAAMhSSKgBAAAAAAAAAAAAAAAAAAAAAABAlkJCDQAAAAAAAAAAAAAAAAAAAAAAALIUEmoAAAAAAAAAAAAAAAAAAAAAAACQpZBQAwAAAAAAAAAAAAAAAAAAAAAAgCyFhBoAAAAAAAAAAAAAAAAAAAAAAABkKSTUAAAAAAAAAAAAAAAAAAAAAAAAIEshoQYAAAAAAAAAAAAAAAAAAAAAAABZCgk1AAAAAAAAAAAAAAAAAAAAAAAAyFJIqAEAAAAAAAAAAAAAAAAAAAAAAECWQkINAAAAAAAAAAAAAAAAAAAAAAAAshQSagAAAAAAAAAAAAAAAAAAAAAAAJClkFADAAAAAAAAAAAAAAAAAAAAAACALIWEGgAAAAAAAAAAAAAAAAAAAAAAAGQpti87AOB5VZkYpCRb55cdBgAAeInsjSZNqSyVHrtT8cmGlx0OAAD/syuTfF92CHiKCxcuaNCgQTpy5IiSkpLUoEEDzZ49Wx4eHlZtz549qzFjxig4OFgGg0EFCxbU559/rrp160qSfv75Z40bN06HDx+WJOXPn1/Dhw9Xy5YtzWP897//1aeffqr79+/Ly8tL06dPN/eXJJPJpLlz52ru3Lm6d++e7OzsNHXqVP3nP/+xiCUhIUGVK1fWgwcPdOXKFatY06pPSkrSggULNGfOHN29e1fZsmVT8+bNNXXqVDk4OMhkMmn16tWaNm2arl+/Ljs7O9WtW1cBAQHy9PQ0j/3zzz9r2LBhOnnypBITE1W3bl2tWbNGkhQXF6f+/ftr06ZNSklJ0dtvv625c+fK09NT3333nT788EOrWO/du6cFCxbIz8/PovzQoUOqWbOmRo8erbFjx0qS/vjjD40dO1bbtm1TSkqKcufOrdGjR6tNmzbmfklJSRo7dqwmTJigr7/+2mrOOXPmaO7cubpz545y5cqlzz77TK1bt7aKCwAAAAAAAAAAAADwz8IONf8iu3fvltFotCpfsmSJypcvn2Z7X19f5cqVS9myZZO7u7veeustLV++/JnnNplM5v8eO3asmjdv/sT2OXLkeK55AAAAAAAAXpbo6Gg1bNhQhQsX1uXLl3Xjxg15eXmpY8eOabYfPny43n33XV27dk1hYWHq1KmTmjdvroiICEnS1q1b1aFDB129elWhoaEaO3as2rZtq5MnT0qS9u/fr65du2rJkiUKDw/XmDFj1LRpU126dMlijtWrV2v79u0KDw/X8ePHVaZMGatYPvvsszSTfp5UHxQUpIMHD2rz5s0KDw/XL7/8ouDgYH3++eeSpHPnzmnZsmX6+uuvdevWLZ09e1ahoaHq37+/eYxff/1VTZs2Vc+ePXXz5k2Fh4erT58+5vq+ffvq9OnTOnv2rK5duyZJateunSSpSZMmCgsLszjOnj0rR0dHVaxY0SLWmJgYdevWTdWqVbMoHzdunMqVK6dz584pLCxMkyZNUrt27XTu3Dlzm2rVqun69evKkyeP1XWZP3++Pv/8c61evVq3b9/W6tWrNWjQIB09ejTdawkAAAAAAAAAAAAA+GcgoeZf5P79+8qRI0eG2u7cuVM+Pj6qU6eOTpw4ofj4eF2+fFndu3dXnz59NH369HT75s+fX7a2tubDxsZGjRo1ynCcwcHBun//vl577bUM9wEAAAAAAHjZDh48qNDQUE2ePFn29vbKli2bJk+erAMHDujq1atW7desWaP27dvL3t5ektSpUydFRUXp999/l/TooSStW7dWtmzZJEm+vr7Knj27Tp8+LUmaNWuW2rVrp6pVq0qSWrZsqWrVqumrr76S9CihZfny5dqxY4cKFiwoSfL09FTp0qUt4jh69Kg2b96soUOHpnle6dXXq1dPK1asULFixSRJuXLlUuPGjc3JJEWLFtX27dvNyS0uLi5q2bKlRbJJnz59NHPmTLVq1UoGg0FGo1E1a9aUJEVERGjx4sWaOHGiXF1dZW9vr2nTpun777/XmTNn0ox1/vz5qlq1qsqWLWtRPmzYMLVp00ZFixa1KJ8zZ44++eQTubi4SJJ8fHzk4eGhX3/91dxm3bp1Wrp0qRwcHKzmW7FihT766COVK1dOklS2bFn16dNH8+fPTzM+AAAAAAAAAAAAAMA/Bwk1/yJnzpyRt7d3htru2LFDNWrU0ODBg+Xl5SWDwSAPDw+1b99efn5+2rp1a7p9z507pwcPHigiIkIREREqXLiw3nvvvQzNe+vWLXXr1k25c+dW//799eDBgwz1AwAAAAAAeNliY2NlY2NjsUNwUlKSEhMT00wAsbW1tXh96NAhOTg4qEiRIlZtHz58qC+++EKOjo6qV6+eJCkkJEQ1atSwaFejRg2FhIRIepSw07p1a3366acqUKCAChQooPHjxys5OdncPi4uTp07d9bXX3+dZsLIk+r/HH9qTKkJO2ntlHzo0CFz/Y0bN3T27Flly5ZNFSpUUO7cufXuu+/q+vXrkqSff/5ZJpNJlStXNvfPnz+/Xn31VfM5Pi4+Pl6zZs3SoEGDLMqDg4O1f/9+jRgxwqrPn8/h/PnzunfvnkqVKmUuK1CggFW/VLGxseaEp8fjSE16AgAAAAAAAAAAAAD8c5FQ8y+ydu1a/frrr2n+wcGf1atXTyEhIZo9e7ZCQ0OVmJiou3fvau3atVq1apUaNmyYbl8nJye5uLjI2dlZ/v7+yps3r/z8/PTOO+/IYDDI398/zX67d+9W5cqVVb58eV26dEl58+ZV2bJltWLFCiUlJT33eQMAAAAAAPwVatSoIXt7e/n7+ysuLk6RkZHq27evjEaj7t2798S+d+/eVdeuXTVq1CjlzJnTom7UqFHKnj27AgICtGnTJnl6ekqSwsPDlSdPHou2efLkUXh4uKRHDz1Zu3atSpcurfPnz2vr1q1asGCBpk6dam4/cuRINWrUyLzLzZ89rf5x06ZN04ULFzRkyJA069etW6dNmzZp/Pjx5vhSUlK0bNkyff/997pw4YLc3NzUuHFjJScnKzw8XJ6enlZJL4+f4+OWL1+u3Llzq379+uayqKgodevWTYsWLZKdnd0T44+Li1O7du3UuXNnq1180tO0aVN9+eWXOnXqlFJSUnTw4EEtXrz4qe83AAAAAAAAAAAAAODvj4Saf4m1a9fq0qVLGjRokDp27KiIiIgntm/SpInmzJmjPn36qGrVqsqVK5cqVKigDz74QO3bt9fQoUOf2D85OVnDhw/XqlWrlJCQoFu3bmnz5s26f/++Vd/AwECVLl1abdu2Vf/+/bVmzRo5Oztr3bp1Gjt2rEaMGCEvLy99++23//N1AAAAAAAAeFE8PT21c+dOHTp0SEWKFFHNmjVVs2ZN5ciRQ9mzZ0+3X3x8vFq1aqU33nhDw4cPt6ofP368oqOjNWLECNWvX18nT56UJKWkpMhgMFi0tbGxUUpKiiQpLCxMFSpUUOfOnZUtWzaVLVtWAwcO1KJFiyRJ+/fvV2BgoMaNG5dmXE+rf9y2bdvk7++vDRs2KFeuXFb1v/zyi7p06aJly5apRIkS5vju37+vefPmKVeuXHJ1ddXMmTN15swZhYSEpHl+fz7HVCaTSdOmTbPanWbgwIF6//33VaFChSfGbzKZ1KVLF2XLlk2zZ89+6vmmGjlypDp06KA2bdrI29tbs2fPVrdu3Z74fgMAAAAAAAAAAAAA/hlsn94Ef3cXLlxQjx49NGbMGA0aNEgnTpxQ3bp1tWXLFuXLly/dfqVKlZIkXb161VxWunRplSlTJs0/Zkh14MABDRgwQI6Ojjpx4oQ2bNigcuXKyd/fX127dpWDg4NF+7Jly6pPnz56//335erqalHXpUsXdezYUXv27FHFihXTnC8+Pl7x8fHm15GRkZIkexuTjEZTunECAIB/P3sbk8W/AAD80yUmJr7sEP6RUq/bX3H9ypUrp23btplfP3jwQH5+fipZsmSa8yclJalt27aysbHR4sWLlZycrOTkZKt2dnZ2+vDDD7V69WotXrxYkyZNkqenp27dumUx7u3bt+Xp6anExES5uLjo9ddft6gvUKCArl+/rqioKHXu3FkLFy6Ura2tEhMTzTsEJyYmKi4u7on1j9u3b5/at2+vFStWqFKlSlb1p0+fVqNGjTR58mQ1adLEXO/k5KR8+fIpR44c5rLs2bPLw8NDly9flru7ux48eKCEhASLe1F3796Vh4eHxTybN29WTEyMWrVqZS7fvXu3Dh06pJCQEHNZSkqKkpOTrWLs06ePTpw4oaCgIBmNxnQ/K3/uazAYNHr0aI0ePdpcNnToUJUpU4afVwD4m/or1wUAAODvizUBAACQWBMAAJBVPcvvfhJq/uGCgoLUtm1bNWnSREOGDJHBYNCmTZvUo0cPVa5cWefPn7dov2PHDq1evVrSoz/AkKQPP/zQXH/z5k0tXLhQwcHBkqSaNWta1Pv7+ysgIECjRo1Sv379ZDQa1bVrV5UtW1bjx49XmzZtrGLMnz+/unfvnu452Nraqn79+unWT5w4Uf7+/lbloyqkyMnJ+g9QAABA1jPujZSnNwIA4B8gMDDwZYfwj7Zr166/fM4NGzaocOHCOnnypHlnmVQpKSmaMWOGbt26pbFjx+qHH36wqE9OTpbRaLQoi4iI0JUrVxQYGChvb2+tX7/e4gEl3333nXLmzKnAwEA5Ozvrxx9/tPjcbN68WZ6enlq9erWuXbsmHx8fi3ji4+Pl7u6ud99994n1H3zwgRo3bqxz587J399fH330kSTrz2hoaKhGjBih5s2b65VXXrGov3fvnsLDw7Vu3To5OTmZz+/evXv6448/lJycrISEBH355ZcqUKCAJCkqKkqXLl1STEyMxVijR49WvXr19P3335vL1qxZowsXLih37tzmstTknOnTp+vrr7+Ws7OzlixZoiNHjmjChAkKCQlJ832UpJiYGP32229P/DmMj4/XwoUL1b9/f35eAeBv7mWsCwAAwN8PawIAACCxJgAAIKuJiYnJcFuDyWTicd7/YAcPHlRISIj69esnGxsbi7qzZ8+qRIkSWrJkiQICAnTs2DFdunRJp0+fzvD43t7eKleunPl1fHy8+Qmo6Tly5Iju3LkjHx8fzZkzR717987wfIsXL5afn59FWVo71Hh7e6vk4NVKsnPO8NgAAODfx97GpHFvpGj0TzaKT0l/hz0AAP4pTo5t+LJD+EdKTEzUrl27VL9+fdnZ2b3QuUJCQlS5cmUZDAatW7dOn3zyibZu3apy5cqpRYsWatiwofr27SuTyaQePXro119/1a5du+Tu7m411ltvvaVRo0apbt26MhqNWr16tbp166Yff/xR5cuX144dO/TBBx9o69atqlKlijZv3qyOHTtq//79Klu2rK5evaqKFStq0aJFatasmU6cOKGmTZvqs88+s7q/Ikl79+7Vhx9+aPUAlvTqjx8/roYNG2ry5Mnq1KmTVfvr16+rbt266tixo8UOLo9r1qyZ3N3dNX/+fCUnJ6t79+66deuWgoKCJEnt2rXT/fv3tXr1amXLlk09e/bUhQsXdODAAfMYBw4cUPPmzXXp0iVlz579ie9P165dVaBAAY0ZM0aSNG7cOC1dulQ//PCDXn311Sf2LVasmIYPH64uXbqYyy5duiRHR0d5eXkpNDRUPXv2lJ2dndatW/fEsQAAL89fuS4AAAB/X6wJAACAxJoAAICsKjIyUjlz5lRERITFAyzTwg41/3DVq1dX9erV06wrUaKEVVnhwoVVuHBhSY+eKDp37lwdO3ZMERERcnBwUNGiRdWmTRv16dMnzQWkvb297O3tdezYMVWoUCHduJo1ayYfHx99/PHH6tmzp1W9nZ2d9u/frypVqliU//mprI/P+WfxKQYlJfOHswAA4NG6IJ51AQDgX4Avc/43dnZ2L/wazpo1S8HBwbKxsVGpUqW0fft2ValSRdHR0Tp37pxKly4tOzs7Xb16VUuWLJGbm5vKlCljMcbEiRPVuXNnjR49WtOnTzcncBQqVEhbt27Vm2++KUlq2rSppkyZok6dOunu3bvy9vbW2rVrValSJUlS0aJFtWnTJg0aNEjdu3eXq6urxowZo27duqUZu63to1uB6V2jP9fPnTtXERERGjVqlEaNGmVu5+npqVOnTmn58uW6evWqFixYoAULFliMdenSJTk5OWnFihX6+OOPVaRIEaWkpMjX11cbNmwwz7Fo0SJ98sknKlGihFJSUvT2229r8+bNFjHOmDFD3bt3V44cOZ76/tjY2MhoNJr7jxs3Ti4uLqpRo4ZFu48++sicdPO4x/tKj3Zz7tKli2JiYuTo6KgOHTpozJgx/KwCwD/AX7EuAAAAf3+sCQAAgMSaAACArOZZfu+zQ82/SMGCBfXtt99a/YHArVu3dPPmTZUv/3/s3XmYnePhP/73zGQyIfsiC0IQWltElFDU9kUlYiulaomipPattiBiCZoQoZaWSkjtW6uiEbukET5a1C5IJGSxZF8nM/P7w5X5mc5koZhyXq/rOhdz7885IXeenPdzd60uu+uuu9K7d+9cccUV2X///dO2bdvMnTs3zzzzTE455ZRst912GTp06DLnWhqomTFjRq26yy67LG+++WYefPDBZfYvKirK2LFjs/XWW3/Zy8zs2bPTvHnzrHfaXVnSwAk1AFDIykqqcsVWFfnt8yUCNQB8L0y4rGd9L+E7qby8PCNGjEiPHj38hRgAFDj7AgAgsScAAD5nTwAAhWlp3sAJNQXmk08+SXl5ea3ytm3bpm3btjXK/v73v2eXXXbJCSecUF3WvHnz9OrVKxMmTEj//v1Xas4WLVrUKmvUqNGXWzgAAAAAAAAAAAAAAMC3SKDme2bBggWZO3dunXWNGzdOUdHnT27v0aNHDjvssFx77bXZb7/90qZNm8yfPz/PPvtsrr766uy1114rNd/MmTNrlS1cuPArrx8AAAAAAAAAAAAAAOCbJlDzPdOjR49l1k2ZMiXt27dPkhxwwAFp0qRJrr766vTr1y8zZszIKquskh/+8Ifp06dPTjzxxJWar2XLlnWW77333l9+8QAAAAAAAAAAAAAAAN8CgZrvkWWdTLMse+yxR/bYY4+vNFfXrl1TVVX1lfom+a/6LjXu7F3SunXr/3ocAOC7q7y8PCNGjMir/XZPaWlpfS8HAAAAAAAAAAAA+I4oru8FAAAAAAAAAAAAAAAAwLdJoAYAAAAAAAAAAAAAAICCIlADAAAAAAAAAAAAAABAQRGoAQAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBQBGoAAAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBSBGgAAAAAAAAAAAAAAAAqKQA0AAAAAAAAAAAAAAAAFRaAGAAAAAAAAAAAAAACAgiJQAwAAAAAAAAAAAAAAQEERqAEAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUARqAAAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUgRoAAAAAAAAAAAAAAAAKikANAAAAAAAAAAAAAAAABUWgBgAAAAAAAAAAAAAAgIIiUAMAAAAAAAAAAAAAAEBBEagBAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFAEagAAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFIEaAAAAAAAAAAAAAAAACopADQAAAAAAAAAAAAAAAAVFoAYAAAAAAAAAAAAAAICCIlADAAAAAAAAAAAAAABAQRGoAQAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBQBGoAAAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBSBGgAAAAAAAAAAAAAAAAqKQA0AAAAAAAAAAAAAAAAFRaAGAAAAAAAAAAAAAACAgiJQAwAAAAAAAAAAAAAAQEERqAEAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUARqAAAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUgRoAAAAAAAAAAAAAAAAKikANAAAAAAAAAAAAAAAABUWgBgAAAAAAAAAAAAAAgIIiUAMAAAAAAAAAAAAAAEBBEagBAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFAEagAAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFIEaAAAAAAAAAAAAAAAACopADQAAAAAAAAAAAAAAAAVFoAYAAAAAAAAAAAAAAICCIlADAAAAAAAAAAAAAABAQRGoAQAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBQBGoAAAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFJQG9b0A+Kq6D3g8Sxo0ru9lAAD1qKykKldslWzSb2QWVRTV93IA4EuZcFnP+l4CKzB+/Picfvrpef7557NkyZLstttuueaaa9KyZcs628+YMSO//OUv88gjj+Sdd95J586dq+umTJmSc845J0899VQWLlyY1VZbLX369EmfPn1qjfPee++lS5cu2X///TN06NDqtVxwwQV5+umnU1FRkdatW+eEE07IMcccU93viSeeyKmnnpopU6akRYsW6d+/fw488MAaY99555257LLLMnXq1CTJGWeckdNOO626/plnnsn++++fDTbYIKNHj17me9OnT5/ccMMNef/999OpU6cV1p9zzjn505/+VKvdtGnTaowxadKk/OxnP8sLL7yQ8vLyNGhQ9+3Lu+66KwcddFBuueWW9O7dO0ny2GOP5fLLL88rr7ySkpKSrL/++rnwwguz4447Jkn69euXgQMHpkmTJjXGmjhxYsrKylZYDwAAAAAAAMD3ixNqCsDQoUPTtWvXFbarqqpKkvTu3Tsnn3zyN7soAAAAgP9h8+bNy+677551110377//fiZPnpwOHTrksMMOq7P9xIkT06VLlxohmi/65S9/malTp+bFF1/MlClT8vvf/z5nnnlm7rjjjhrtKisrc8QRR2TLLbesUf73v/89O+20U956661MmTIlt9xyS0477bSMGDEiyechnF69euWCCy7ItGnTMnTo0Bx55JEZM2ZM9Rg33HBD+vfvn1tvvTVTp07N+PHjq8MmSTJkyJD06dMn22yzzXLfm1GjRuWtt976UvWXXnpppk6dWuN1++23p3379ll99dWTJOPGjcuPf/zjFd7HmjZtWs4777x06dKlRvlf//rXnHHGGfnoo4/y4Ycf5qCDDkqPHj3y6aefVrc5/fTTa63ji2GZFdUDAAAAAAAA8P0hUPM98Mknn+TII49Mhw4d0rRp0/ziF7+ofspoXfr3758GDRrUeBUVFeXOO+/8SvNfffXV2XzzzZfb5thjj01RUdEyX9dee+1XmhsAAADgm/CPf/wjU6ZMyeWXX56ysrI0bNgwl19+ecaMGZOJEyfWat+6deu89NJLOfXUU+sc77nnnsuxxx6bVq1aJUm23377bL/99hk7dmyNdoMHD866666bHXbYoUb58ccfn6OOOiqNG39+Wu+WW26Z9ddfP6+++mqSz8My2267bfbdd98kyTbbbJODDjooQ4YMSZLMnDkzF1xwQUaOHFkdRGnSpEm22GKL6jn23Xff/Pvf/17ufZ5Zs2bluOOOy/XXX/+V6r/oiiuuyIknnpiGDRsmSTp37pw33ngjBx988HL7/frXv865555b66SgIUOGZLfddktJSUmKiopy8MEHZ8GCBXn33XdXuBYAAAAAAAAACo9AzXdcVVVV9ttvv0ycODFPPPFEXn755RQVFaVDhw7VYZkjjzyyRp+zzjorM2fOzMyZMzN79uzqJ4auzCk2dRk/fnzat2+/wnYHHnhg5syZU+frmGOO+UpzAwAAAHwTFixYkOLi4pSUlFSXLVmyJOXl5XnjjTdqtW/SpElat269zPEOPvjgXHPNNfnoo49SVVWVkSNHZty4cTnggAOq27z55pu57rrrctVVVy13bYsWLcrw4cMzceLE7LPPPkk+D+xsu+22Ndptu+22ee6555Ikf/vb37L99ttn+PDh6dy5czp06JCTTz45CxYsqG7fsWPHFBcv/3bhySefnKOPPjo/+MEPvlL9Uq+88krGjBmTY489trqsdevWadKkyXL7DRs2LEuWLMnhhx++3HafffZZ+vfvn0022eQr3/MCAAAAAAAA4PtNoOY77uWXX86zzz6bm266KRtuuGHWXXfd/OlPf0qjRo3y3HPPZcmSJRk2bFiNPg0bNkyTJk3SpEmTrLrqqnnooYey/vrrZ8MNN/zS88+bNy933313nnzyybzwwgvLbVtSUpJGjRrV+fril1MAAAAA6tu2226bsrKyXHjhhVm4cGFmz56dk046KSUlJfnss8++9Hh/+MMf0qlTp6yxxhpZZZVVcsABB2TYsGHZfvvtkyQVFRXp3bt3Bg8enBYtWix3nFVXXTUnnnhibrvttmywwQZJkmnTpqVdu3Y12rZr1y7Tpk1Lkrz99tsZPXp0Kioq8sorr2Ts2LF58sknc8opp6z0NTz00EN54403lnkKz4rqv+iKK67IkUceWeuUmeWZPHlyLrjggvzhD39YbrtDDz00rVu3ziOPPJIHH3yw+gSc5POTljt06JC11lorPXv2zFNPPVWj74rqAQAAAAAAAPj+EKj5jisvL0+SGl8MaNCgQUpKSrJkyZIV9p8+fXoGDBiQs846q0b51VdfnaKiopx88snL7FtRUZGjjjoqG220UW666abss88+efvtt5fZ/vbbb09paWmdr/79+69wrQAAAADfltatW2fkyJEZO3Zs1ltvvWy33XbZbrvt0qpVqzRt2vRLj3fMMcdk/PjxeffddzN37tzccccd6d27dx5//PEkyeWXX571118/e+6553LH+fWvf5358+fnj3/8Y37xi1/kscceS5JUVlamqKioRtvi4uJUVlYmSaZOnZo2bdqkb9++WXXVVdOpU6f0798/Q4cOrW6zPJ999llOOOGE/OlPf6rzwSgrqv+iDz74IPfdd9+XCvMkyZFHHpnzzjsva6yxxnLb3XbbbZk5c2Z+9rOfZbvttqsOFZ100kmZOnVqpkyZkpdeeik77LBDfvrTn2bMmDErVQ8AAAAAAADA90uD+l4A/51u3bqla9euOf7443PttdemrKwsffv2zbx583LUUUelQYMGmTFjRp1P+5w4cWL23XffbLnlljniiCNq1B177LEZMGBAysrK6pz35ZdfzimnnJKZM2dm5MiRWW211TJp0qRsu+22ueaaa3LQQQfVaH/DDTfkhhtu+ErXuGjRoixatKj659mzZydJyoqrUlJS9ZXGBAC+H8qKq2r8EwC+S5Y+JIP/3tL38ut+TzfbbLM8/PDD1T/PnDkzvXv3zkYbbbTMub64lqX/PmHChNx00015/fXX07Fjx1RVVWW33XbL0UcfnX79+qV169a58cYb8/zzz1f3qaioSGVlZZ3zFBcXZ6+99so+++yT66+/PjvssENatWqVjz/+uEb76dOnp02bNikvL0+TJk3StWvXGvVrrbVWFi1alA8//DDt27evLq+oqEhVVVWNtscff3yOOuqorL/++jXKl17niuq/aODAgdlrr72y+uqr13l9Sx8SU15enqqqz/d5f/rTn1JVVZXDDjusuk9VVVUqKirqHGPVVVfN+eefn+HDh+euu+5Knz590qRJk+pxmzZtmlNOOSWPPPJIhg8fnq222mqF9QB8N3xT+wIA4LvFngAASOwJAKBQfZnf+wVqvuNKSkry17/+Nccff3w6d+6cRYsWZffdd89bb72VVq1aJUnuvPPO3HTTTdV9FixYkNtuuy1nnXVWunfvnrvuuqvWE0zLysrSokWLOuc85phjMmzYsBx33HG56KKLMnXq1EyePDlnn312Ntxwwxx//PG5+OKL8+STT+bCCy/M73//+5W+ngsuuCD9+vWrUTZgwIBceOGFtdr23bwyq65asdJjAwDfXxf9aMVPVQeA/zUjRoyo7yV874waNeobHf/+++/Puuuum1dffTWvvvpqnW2Wnoby9NNPV5/k+9577yVJxo4dW+N030mTJmXSpEkZOnRopk2blnXXXbe6bmmY5L777sull16ajh071jr5ZerUqVmwYEFGjBiRNm3aZMSIEdl0002r6++5556sscYaGTFiRIqKivJ///d/NX7d/eMf/0ijRo3y/PPPp0GD//824TvvvJMZM2bUaPv000/nL3/5SwYMGFBjDZtttlm23HLLjB8/frn1p556apJk7ty5+eMf/5iLL754mf8N/Pvf/06SPPLII9XXfN999+XZZ5+tcb9q4cKFee6553L22WfnD3/4Q6qqqlJcXPNA7kWLFuWNN95Y5lxTpkzJaqut9pXrAfjf9U3vCwCA7wZ7AgAgsScAgEIzf/78lW5bVLX0MY9851VWVmbJkiVp2LBhjfKhQ4dm8ODBeemllzJnzpxsuOGGmT9/fs4///yceOKJtb5o0Lt377Ro0SKDBw+uc57JkyentLQ07dq1S5L069cvo0ePzmOPPZYkWbx4cf71r3+le/fuWbx4cRYvXrzS19CwYcNa66/rhJqOHTtmozPuzJLSxis9NgDw/VNWXJWLflSZ8/6vOIsqi1bcAQD+h7zab/f6XsL3Rnl5eUaNGpVdd901paWlX9u4zz33XLbaaqsUFRXl3nvvzfHHH5+HHnoom222Wfbdd9/svvvuOemkk2r0mTBhQjbYYIO8/vrr6dy5c5LP75V07do1G220UW688ca0bt0648aNy3777Zdjjjkm559/fq25+/fvn4kTJ+bmm29Okuyzzz455JBD0qtXr5SVleXJJ5/Mvvvum9tvvz09evTIv//972y33Xa57bbb0qtXr4wdOza9evXK8OHDs8cee2TevHn5wQ9+kHPPPTfHHHNMPvjgg+y1117Zb7/9aj3cpH///nniiSfy1FNPLff9adiwYd5+++106tRppesvvfTSPPXUU3n00UeXOe7TTz+dXXfdNfPnz68R9PlP/+///b8cdthhOeywwzJz5szss88+ueyyy9K9e/dUVVXlqquuymWXXZaXX345q6++evr27Zujjz46a6+9dhYtWpSrr746V155ZV588cWsscYaK6wH4Lvhm9oXAADfLfYEAEBiTwAAhWr27Nlp06ZNZs2alWbNmi23rRNqvkeKi4trhVH+U9OmTXPfffdlk002SePGXy2Msuaaay63vmHDhunevXv1vzds2DCLFy9OZeWynxzfoEGDZX5BoqysLGVlZbXKF1UWZUmFL84CAJ/vCxbZFwDwHeMvbr5+paWlX+v7OmTIkDz11FMpLi7OxhtvnEceeSTdu3fPvHnz8vbbb2eTTTapNd/Sn7+4ltLS0jz66KM555xzsuWWW2bevHlp3rx5Tj311Jxxxhm1Tp5JPj+VuLi4uHqM8847LwMGDMhpp52WysrKdOjQITfffHP23nvvJEm3bt1yxx135Oyzz86vfvWrtGnTJoMHD85ee+2VJGnRokUeffTRHH/88enXr18aNmyY3/zmNznnnHNq3ZMpKSlJUVHRSr2XK3rPv1i/cOHCXHfddbnllluW22fpekpLS5cbqCkqKkpJSUlKS0uz2mqr5Te/+U3OPvvsvPPOOykpKcmGG26Yxx9/PGuvvXaSpFWrVtlrr73yySefZMmSJdluu+3y7LPPVgd+VlQPwHfL170vAAC+m+wJAIDEngAACs2X+X3fCTXfE59++mnWWGONvPXWW9VfElhq+vTp+eijj9K1a9fqstmzZ6dLly55+umna7V/+eWXU1pamo022qjWPBUVFfnPXzL9+/fPmDFjMnLkyFrtl37pYZNNNslrr722zPWfdtppGThw4Aqvc+namzdvnvVOuytLGjihBgAKWVlJVa7YqiK/fb5EoAaA75wJl/Ws7yV8b5SXl2fEiBHp0aOHvxADgAJnXwAAJPYEAMDn7AkAoDAtzRs4oaaAVFVVZdGiRbXCLknStm3btG3btkZZZWVlJk6cmPLy8lrtN9tss2XO071797z44ot11tW14Vy6nldffXWZYx500EHLrAMAAAAAAAAAAAAAAPi6CdR8z8yfPz9z586ts65x48YpKipaqfbFxcVZddVVa5WPGzeuztAOAAAAAAAAAAAAAADAd4VAzffMxhtvvMy6KVOmpH379jXKlnUazQ9+8IO8+eabtcpLSkr+uwUCAAAAAAAAAAAAAADUM4Ga74k2bdp8qZNjWrRo8T9z0szVV1+dBg2+/C/FcWfvktatW38DKwIAvivKy8szYsSIvNpv95SWltb3cgAAAAAAAAAAAIDvCIEa6l27du3qewkAAAAAAAAAAAAAAEABKa7vBQAAAAAAAAAAAAAAAMC3SaAGAAAAAAAAAAAAAACAgiJQAwAAAAAAAAAAAAAAQEERqAEAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUARqAAAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUgRoAAAAAAAAAAAAAAAAKikANAAAAAAAAAAAAAAAABUWgBgAAAAAAAAAAAAAAgIIiUAMAAAAAAAAAAAAAAEBBEagBAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFAEagAAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFIEaAAAAAAAAAAAAAAAACopADQAAAAAAAAAAAAAAAAVFoAYAAAAAAAAAAAAAAICCIlADAAAAAAAAAAAAAABAQRGoAQAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBQBGoAAAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBSBGgAAAAAAAAAAAAAAAAqKQA0AAAAAAAAAAAAAAAAFRaAGAAAAAAAAAAAAAACAgiJQAwAAAAAAAAAAAAAAQEERqAEAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUARqAAAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUgRoAAAAAAAAAAAAAAAAKikANAAAAAAAAAAAAAAAABUWgBgAAAAAAAAAAAAAAgIIiUAMAAAAAAAAAAAAAAEBBEagBAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFAEagAAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFIEaAAAAAAAAAAAAAAAACopADQAAAAAAAAAAAAAAAAVFoAYAAAAAAAAAAAAAAICCIlADAAAAAAAAAAAAAABAQRGoAQAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBQBGoAAAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBSBGgAAAAAAAAAAAAAAAAqKQA0AAAAAAAAAAAAAAAAFRaAGAAAAAAAAAAAAAACAgiJQAwAAAAAAAAAAAAAAQEERqAEAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUARqAAAAAAAAAAAAAAAAKCgN6nsB8FV1H/B4ljRoXN/LAADqUVlJVa7YKtmk38gsqiiq7+UA/6MmXNazvpfAclx//fW58MILa5V//PHHefzxx7PjjjvWKO/Xr18GDhyYJk2a1CifOHFi3nzzzey+++61xpo1a1bOPPPM9OvXL0myZMmS9OvXL5dcckn++Mc/5qijjqpuu95662XevHk1+i9YsCCbb755nnrqqcyZMyf9+/fPAw88kLlz52aVVVbJfvvtl0svvTRlZWXVfUaNGpULLrgg7733XioqKnLooYfmyiuvTJL8/ve/z80335wPP/wwpaWl+fGPf5zf/e53WXvttZMkd999d66++uqMHz8+DRo0yGabbZYBAwZks802S5L07t07DzzwQFZZZZXq+dq2bZtXXnklf/vb32pcz1KfffZZ/vCHP6R3797LfQ+/eA1JMnbs2Gy33XY577zzqt+/F198MRdddFHGjRuXJFlzzTVz9tlnZ7/99kuSlJeX59JLL82tt96aWbNmpVOnThk4cGCtzzJJ3nvvvXTp0iX7779/hg4dmiQZOnRo+vTpk+bNm9doO3r06HTu3LnWGAAAAAAAAAAAX0W9n1DTvn37FBUVVb8OOeSQ6rqhQ4ema9euy+xbVVWVJDnrrLPSu3fvJMmOO+6YwYMHr/T8S8dIPv9Szj777LPSfb/sXF/WP//5zxQVFeXDDz/8WsZb0XpfeeWVFBUVZdKkSV/LfF9G7969c/LJJ3/r8wIAAFC/+vTpk6lTp9Z4jR49Oo0aNcpGG21UZ5/TTz+9Vp+ysrJsttlmtco//PDDdOjQId26davuv80222TSpElp165drbHffffdWmPsvffe1f1feeWVlJSUZPTo0Zk6dWrGjh2bUaNG5bzzzqseY8SIETnyyCMzYMCATJ06NZMnT84BBxxQXf/4449n2LBhmTZtWt55552sssoqNeoffvjhDBw4MFOnTs3EiROz+eab56c//WkqKyur21x99dU11vjKK68kSfbcc89a63/rrbeyyiqr1HgPlvUeftH8+fNz9NFHZ5tttqlR/tBDD+WQQw7JxIkTM2XKlPTr1y8///nP8+qrryZJ+vbtm3vuuSePP/54PvnkkwwaNCi/+MUv8sEHH9QYp7KyMkcccUS23HLLWp/DgQceWGt9wjQAAAAAAAAAwNep3gI1M2bMyIQJEzJmzJi888471a/+/ftnwoQJWbhwYa0+u+yySxo0aFD92nnnnVd6voqKihp9GzRokJKSkrRp02aZfXr27FmrT1FRUd56662VmvOpp56qERb6z1dpaely+19//fVp1qxZmjZtulLzPfPMM9luu+3SpEmTrLXWWhk8eHCNL9usyP33359mzZpl9dVXX+k+X3TnnXema9euad++fdq3b59BgwYlSSZPnpyioqJMmDDhK40LAABAYRk4cGAOOeSQtG3b9r8e65577klZWVl69epVXXbvvfdm2LBhadSo0Qr7T5o0Kffee2/1QyC23XbbXHbZZWnfvn2Szx8Usssuu1SHSSoqKnLcccfl3nvvzQ477JAkKSsrqxFKuf/++7PpppsmSfUJN6+99lp1/bBhw7LNNtukqKgoDRo0yM9//vNMnTo1n3zyyVd6D66//vpsvfXW6dKly5fqd9ZZZ+WAAw6oFWTp169f9t9//zRs2DDJ5/dPmjZtmtdffz1JMnz48Jx11lnp1KlTkmSHHXbIAQccUH0CzVKDBw/OuuuuW/0+AQAAAAAAAAB8m+otUHPddddl6623zrbbbpvtttuu+vXjH/84W2+9df75z3/W6vPII49k7ty5WbBgQX7zm99k/fXXX+n5SkpKMnPmzOrX3Llzs/POO2fvvfdeZp/77ruvuv2cOXNy4YUXpkuXLvnBD36wUnNuv/32mTNnTp2vxx57LKuuumqd/RYvXpxzzz03Dz30UHbZZZcaX8xZlldffTW777579t1337zzzjsZNmxYrrrqqhphoGeeeWaZ/ceMGZMrrrgiZWVlOfXUU79UECdJbrjhhvTv3z+33nprpk6dmvHjx2fHHXdcZvuXX365xtpuvfXWLzUfAAAA30/Tp0/PbbfdltNOO+1rGe93v/tdTj311BQVFVWXrb322ivd/6qrrsq+++6btdZaq1ZdZWVl/vGPf+S+++7LL3/5yyTJ2LFj06ZNm7zyyivZaKON0rZt2xx22GGZMWNGneO/9957GTJkSI0Te79oypQpufzyy7Pbbrt9pYDRokWLMmTIkJx++ulfqt9TTz2V0aNH55xzzlluu7lz52bQoEFZZZVVsssuuyRJFixYUB22+eI6lgZukuTNN9/Mddddl6uuuupLrQsAAAAAAAAA4OtSb4Gac889N1OnTs0bb7yRm266Kb/73e/y17/+NVOnTs3UqVPz4x//uFafhg0bplGjRiktLc2LL774pZ+s2qRJk+rX3XffnXHjxuWSSy5ZZvtGjRpVtx8/fnwuv/zyXHnllTXanHLKKSkqKsrgwYNr9S8pKakx5xdfFRUVad68eY32kyZNyjXXXJNNN900f//73/Pss8/mvvvuy4EHHphtttkmvXr1yq233pqZM2fWmuumm25K9+7dc9ppp6VDhw7ZaaedcuGFF2ajjTbKkiVLsmTJkjpP9FmyZEmuu+667L777rnkkkvywgsv5LHHHstPfvKT5QZwvmjmzJm54IILMnLkyOrPpEmTJtliiy2W2WezzTbLwoULq19HHHHESs0FAADA99uQIUOy6667ZoMNNlhmm6uvvjodOnTIWmutlZ49e+app56qs91jjz2WDz/8MIcddthXWsvMmTNz00031RlGee2117LqqqvmJz/5SX79619XB2refvvtTJo0KS+++GKee+65vPbaa5kyZUp+8Ytf1BqjY8eOWW+99dKkSZNcffXVteq33377rL766pk4cWL+/Oc/16g744wz0q5du6y77rr5+c9/npdeeqnOa7jtttvStm3b7LrrrjXKl/cezpkzJ0cffXRuvvnm5Z6u27dv3zRt2jSDBw/Ogw8+mNatWydJevXqld/97nf54IMPUlFRkYcffjh//etf89lnnyX5/BSf3r17Z/DgwWnRokWdY993331Zc801s/rqq2fnnXfOAw88sMx1AAAAAAAAAAB8FfUWqEmSJ598Mp07d86NN96YJ598Moccckh69uyZsWPHpqioaJkhi1mzZuWf//xn9txzz+qyioqKLFy4cKVOVhk2bFh+/etfp6SkZKVCIy+++GL22GOPbLPNNhk8eHDmz59fXXfppZdmxowZ6dOnz0pc8f/vk08+yWqrrVaj7J577slf//rXXHDBBRk3blw++eSTrLPOOjn99NPz/vvvZ/vtt89f/vKXNGjQoNZ45eXltZ7+2qhRoyxZsmSZa7jiiiuy5pprZsiQIbn//vtzyimnZO21184LL7yQ7bffPj169MgGG2ywwtNx/va3v2X77bfP8OHD07lz53To0CEnn3xyFixYsMw+L730UkpLS6tff/rTn5Y7BwAAAN9/8+bNy/XXX7/c01ROOumkTJ06NVOmTMlLL72UHXbYIT/96U8zZsyYWm2vuOKKHH/88SkrK/tK67nuuuuy1VZbZfPNN69Vt/HGG2fevHkZO3Zshg0blgsvvDBJMnXq1JSXl2fw4MFp1qxZVltttQwcODAjR47Mhx9+WGOMSZMmZcKECamsrEzPnj1TVVVVo/7ZZ5/NtGnTsuGGG+YnP/lJFi5cmCQZNGhQpkyZkmnTpmXMmDHp2LFjdthhh4wfP75G/6qqqgwcOLDW+7mi9/C0007LQQcdVOd1f9HFF1+cefPm5Zxzzsmuu+5aff/gmmuuydZbb52dd94566yzTv72t7/l0EMPTdOmTZMkl19+edZff/0a93W+6Gc/+1mmTZuWyZMn5+23384hhxySgw8+OHfddddy1wMAAAAAAAAA8GXUTmZ8iy655JKccMIJ6devX5Jk/vz56dixY+bNm5fy8vLcfvvttU6ESZLhw4enVatW6dSpU42y4cOHJ0n222+/Ouf76KOPcuqpp2bUqFH5y1/+klatWqVHjx556qmnMmDAgFrtZ8+enSuvvDLXXnttbrnlluy555751a9+la5du+b6669Pkqyyyip1Pk116ZdclmXChAlp165ddbtGjRrl1FNPzamnnlrdZtGiRZk8eXKSpE2bNvntb3+7zPEOO+ywbL/99rnllltywAEHZPz48bnwwgvz0UcfpWvXrkmSd999t8aXVbbeeuv84Q9/SM+ePVNSUlJdvuqqq2bAgAE5++yz8/TTT2eTTTZZ7rW8/fbbGT16dLp27ZpXXnkl06dPz957751TTjklN9xwQ632S5YsSadOnfLWW29l4sSJ2WKLLWpc939atGhRFi1aVP3z7NmzkyRlxVUpKalaVjcAoACUFVfV+CdAXcrLy+t7CaykG264Ieuvv366d+++zM+tSZMmST7/XJs2bZpTTjkljzzySIYPH56tttqqut1LL72Uf/zjH7ntttuW+2ugoqKizvpFixZlyJAhufnmm5fbv2vXrjnrrLNy1lln5Zxzzknjxo2z0UYbpbi4uLrfWmutlSR5//3307Zt2xr9V1999Vx55ZXZYIMN8vLLL2fjjTeuUd+yZctcffXVadWqVUaOHJkePXqkWbNmqaqqSnl5edq0aZPLLrssDzzwQO69996cdtpp1X3/8pe/ZP78+fnZz35W4xqW9x7Onj07Y8eOzXPPPVfdp7KycpnvU2lpaY466qjceeedueWWW3LZZZdllVVWyZVXXlnjns6BBx6YTTfdNC+99FJuvPHGPP/889XjVVRUpLKysvrnRo0aVa+vrKwshx56aJ555pkMGzZsmfd8lvb13zsAYF8AACT2BADA5+wJAKAwfZnf++s1ULPWWmvlhRdeyLRp09K6des888wzmT9/fubMmZPtttsun3zySfWXPJZa+oWWadOm5cEHH8w+++yTJDn88MMzdOjQ7LjjjnXOdfbZZ+eqq67KgQcemNdffz3t2rVLkrzyyis588wzaz3F9aWXXspPfvKTbL311hk3blzWW2+9JMktt9yS66+/frlPt63r9JllWWWVVZIkPXv2zMMPP1xnm6Kiolplt9xyS3r37l39c/fu3XPPPffkzDPPzJFHHpkmTZrkt7/9bY499tjqNnvvvXeNMX7yk58sd23NmjVLr169VngNU6dOTZs2bdK3b98kSadOndK/f/8ceOCBue6666rbrbPOOjXGXmeddbLRRhtlo402Wu74AwYMqH7S7xf13bwyq65ascL1AQDffxf9aMWnFAKFa8SIEfW9BFZCRUVFLr/88hxxxBFf+jObMmVKVltttRr9Bg0alB122CHPPffcMvvNnz8///73v+ucb+TIkdUnv36xvqKiosZDKZLktddeq263cOHCvPHGG3nooYeq2y295/DOO+9k+vTptfp/+umnSZIxY8bkvffeq1VfUfH5n33/+c9/1nkdVVVVmT17diZPnlxjreedd1522WWXPProo8t8D5Za+h4OHz4848ePrxH8Wbx4cYqKinLllVfmj3/8Yxo1alRrjbNmzcqECRPqfC8/+eST/O1vf8vOO++coUOHZtq0aVl33XWr68vLy1NVVZX77rsvl156aY0HqCz13nvvpbi4eIW/NkaNGrXCawUACoN9AQCQ2BMAAJ+zJwCAwjJ//vyVbluvgZpBgwbl5JNPzmabbZY5c+ZkvfXWy9ChQ9OjR49suummuf/++3P77bfX6HPxxRdn1VVXzXXXXZfTTjttmQGa/3TsscfmmGOOqfWljA4dOuTWW29N8vkbt/RJsF27ds24ceOy4YYb1mhfVVWVPn36JEk22mijdOjQodZcbdq0SVXVl3tKenl5efUXZFZGaWlprbK99947e++9dxYtWpSGDRvWCuJ8sc/++++f++67b6Xne//99+v8QkvyeTimW7duNcrWW2+9LFq0KNOnT88aa6yRGTNmJPk8HLTKKqukYcOGKz332WefXeMEm9mzZ6djx465+F/FWVJaspyeAMD3XVlxVS76UWXO+7/iLKqsHUIGSJJX++1e30tgJfz5z39O8+bN079//xQXF1eXH3LIIVljjTVy+eWXJ0n69u2bo48+OmuvvXYWLVqUq6++Oh9//HGuuOKKrLHGGkmSiRMn5vnnn88rr7xS4+EO/2nVVVfNpptumh49etQor6yszBlnnJHzzz+/Vt25556bFi1a5KijjkrLli3z/vvv56yzzsqvfvWr9OjRI3vssUduvfXWjB07NhdeeGFmzpyZgQMH5pe//GUOOeSQ/PWvf82DDz6Ys846K+uuu27mzJmTX//619lyyy1z9NFH5+WXX86FF16Y/v37Z9NNN83ixYtz1llnZfXVV88pp5ySefPmVT9ko127dpkzZ07OO++8tGjRIhdddFH1g0nGjBmTKVOmZNCgQWnatGmNa1jRezh06NAa7Y888sisvfbaOf/885MkO+ywQ/r27Zudd945JSUlufPOO/Pmm2/mj3/8Y7p27ZrXX389HTp0SMuWLTN+/PhcfPHF1fdlkuR3v/tdjfH79++fiRMn5uabb06SXHrppdl3333zwx/+MBUVFbn99tvz4osv5qmnnqo+hfc/lZeXZ9SoUdl1113rvGcCABQO+wIAILEnAAA+Z08AAIVp9uzZK922XgM1LVu2zLBhw+qs69y5c42noSbJww8/nIEDB+aZZ57JFltskdtuuy177rlntthiixXOtfbaayf5PJBz3nnnLbPd3nvvnQMOOCBJqsM0d999d66++uq88sormTt3bpo2bZquXbvm9NNPz1577bXMsRYvXpxnnnkmP/nJT1YYICktLU1paWkWLVq03DBOaWlprafA/qflnZ6z1N13353KyppPcn/66afTs2fPzJ07t1b7Bg2W/Utliy22yJAhQ2qUvfnmm2ncuHFat26doqKitGjRYoVrWpaysrI6r2lRZVGWVPjiLADw+b5gkX0BsAxujn83DB48OKecckqtP/+NHz8+5eXl1Z9jq1atstdee+WTTz7JkiVLst122+XZZ5+t8RCIa665JnvttVc22GCDFc5bUlJS69fIAw88kPnz5+fQQw+tVXfSSSflwgsvzFZbbZUFCxakWbNmOfjgg3PuuedWtx0xYkT69OmTjh07pqioKAcffHAGDBiQ0tLS9OzZM6+//nr222+/fPLJJykrK8uOO+6Yv/71r2nYsGG6deuW3XffPUcffXQmT56cBg0aZMstt8yoUaPSokWLNGrUKPPnz8+OO+6Y2bNnp7KyMj/96U/z5JNPpmXLltXrvOqqq/LrX/86rVq1qnXNK/MeflFxcXGN9+m8887LlVdemV/96ldJPj+R9qGHHsqWW26Z5PMTe3r27Jny8vK0aNEixx57bE4++eQ6T+Bd+hkUFxdXj9+xY8ccfvjh+eijj7J48eJ07do1jz32WPX4y7P0/goAgH0BAJDYEwAAn7MnAIDC8mV+3y+q+rJHqXzNqqqqMmvWrDRr1qzGE2iT5F//+lf+8Y9/5Ljjjstzzz2XnXbaKb///e+rv7Axffr0nHLKKWnWrFkWLFiQoUOHZscdd8w+++yTk08+uc75KioqUl5eXmfdxRdfnFdffTUPPvhgddl9992XQw45JIMGDcqee+6Zli1b5tNPP82DDz6YM888Mw8++GD22GOPOsebOnVqOnTokClTpqR9+/Yr9X40adIk8+bNW2b9Nddck+OPP36Z9YMHD86IESPy6KOP1qr797//ndatW2f11Vevs+9TTz2Vn/70p1m4cOFKrXWpefPmZd11183555+fPn365IMPPkiPHj2y//77p3///tXtHnnkkVxyySUZPXp0rTHefPPNNGjQIJ07d17hfLNnz07z5s2z3ml3ZUmDxl9qrQDA90tZSVWu2Koiv32+RKAGWKYJl/Ws7yUA37Dy8vKMGDEiPXr08BdiAFDg7AsAgMSeAAD4nD0BABSmpXmDpTmV5Slebu234NNPP03Lli3zwQcf1KrbfPPNc9xxxyX5/BSU+++/vzpMkyRt27bNn//85zRv3nyl5yspKUmjRo3qfNV1CsuTTz6Z//f//l9+85vfZK211krTpk3TqVOnnHzyyfnxj3+cJ5544itc9bLNnTs3VVVVdb66d+++wv5LlizJ4sWL66zbdNNNlxmm+W80btw4jz76aO688860adMmW2+9dQ466KCcf/75NdrNmzcvkydPrnOMH/7whysVpgEAAAAAAAAAAAAAAPhv1U6Q1JP58+dn7ty5ddY1btw4paWlyzwJ5pu022675aCDDsr111+fnj17pmXLlpkxY0buv//+/OMf/8jZZ5+9wjFmz56dRo0a1VnXpEmTOoM8/42KioplvpcNGjRY5lr+G5tttlmeffbZFbarqqpa5tqKi385fUkAACvzSURBVIuz6qqrft1LAwAAAAAAAAAAAAAAqKHeT6hZauONN07Tpk3rfE2bNu1bWUO3bt2y66671ijba6+9cscdd+Tee+/NZpttlhYtWqRr1655+OGH88ADD2S33XZb4bg/+MEP0rJlyzpff//737/26xg9evQy38t99tnnK405ePDgtG/fvtbrlltu+VLjfPDBB8tcW7du3b7S2gAAAAAAAAAAAAAAAL6Moqqqqqr6XgQrZ8qUKWnSpEmaNm1a30upV7Nnz07z5s3zySefpHXr1vW9HACgHpWXl2fEiBHp0aNHSktL63s5AEA9sScAAJayLwAAEnsCAOBz9gQAUJiW5g1mzZqVZs2aLbdtg29pTXwNOnToUN9LAAAAAAAAAAAAAAAA+M4rru8FAAAAAAAAAAAAAAAAwLdJoAYAAAAAAAAAAAAAAICCIlADAAAAAAAAAAAAAABAQRGoAQAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBQBGoAAAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBSBGgAAAAAAAAAAAAAAAAqKQA0AAAAAAAAAAAAAAAAFRaAGAAAAAAAAAAAAAACAgiJQAwAAAAAAAAAAAAAAQEERqAEAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUARqAAAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUgRoAAAAAAAAAAAAAAAAKikANAAAAAAAAAAAAAAAABUWgBgAAAAAAAAAAAAAAgIIiUAMAAAAAAAAAAAAAAEBBEagBAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFAEagAAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFIEaAAAAAAAAAAAAAAAACopADQAAAAAAAAAAAAAAAAVFoAYAAAAAAAAAAAAAAICCIlADAAAAAAAAAAAAAABAQRGoAQAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBQBGoAAAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBSBGgAAAAAAAAAAAAAAAAqKQA0AAAAAAAAAAAAAAAAFRaAGAAAAAAAAAAAAAACAgiJQAwAAAAAAAAAAAAAAQEERqAEAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUARqAAAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUgRoAAAAAAAAAAAAAAAAKikANAAAAAAAAAAAAAAAABUWgBgAAAAAAAAAAAAAAgIIiUAMAAAAAAAAAAAAAAEBBEagBAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFAEagAAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFIEaAAAAAAAAAAAAAAAACopADQAAAAAAAAAAAAAAAAVFoAYAAAAAAAAAAAAAAICCIlADAAAAAAAAAAAAAABAQRGoAQAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBQBGoAAAAAAAAAAAAAAAAoKA3qewHwVXUf8HiWNGhc38sAAOpRWUlVrtgq2aTfyCyqKKrv5UDBm3BZz/peAstx/fXX58ILL6xV/vHHH+fxxx/PjjvuWKP8ww8/TL9+/fLwww+nsrIybdu2zXnnnZcDDjigus1dd92VCy64IDNmzEiHDh1y5ZVXZuedd66uf+KJJ3LqqadmypQpadGiRfr3758DDzywRv8BAwbko48+SpMmTXL66afnN7/5Ta01Ll68OFtttVVmzpyZCRMmVJe//PLLOe644/L222+ncePGOeWUU3LiiSfW6Dtq1KhccMEFee+991JRUZFDDz00V155ZZLk008/zfHHH58nnngixcXF2WeffXLVVVelUaNGSZIXXngh5513Xl599dVUVlZm/fXXzwUXXFB9jdOmTcsZZ5yRJ554IosWLUr37t1z/fXXp2PHjvnb3/6Wo446qta1fPbZZ/nDH/6Q3r17Z8qUKTnnnHPy1FNPZeHChVlttdXSp0+f9OnTJ0kyY8aMXHLJJbn77ruzePHiNG/ePCeeeGKOO+64JMl6662XefPm1Rh/wYIF2XzzzfPUU09Vl9133305/PDDs88++2T48OE12hcVFaVdu3Y1yk444YSce+65tdYOAAAAAAAAAPB94oSab0FVVVWSpH379nnssccyYcKEFBUVZebMmSs9RlFRUV566aUvPfdXmWufffZJv379ltvmsssuS4sWLapfP/7xj6vrHnzwwXTq1GmZfWfPnp2ioqI8++yzK70mAAAA/jt9+vTJ1KlTa7xGjx6dRo0aZaONNqrV/qKLLspmm22Wt99+O1OnTs1ll12Wgw8+OG+//XaSZPTo0TnyyCMzdOjQTJs2Leeff3569eqV9957L0ny3nvvpVevXrngggsybdq0DB06NEceeWTGjBmTJHnkkUdy5JFHZvDgwZk+fXqeeOKJ3HDDDbn//vtrraV///5p2bJljbKZM2dmt912y89//vNMnz49f//733PJJZfkjjvuqG4zYsSIHHnkkRkwYECmTp2ayZMn1wgEHXzwwUmSDz74IG+99VZef/31nHTSSUmSWbNmZffdd8+PfvSjvP/++5k8eXL233//9OzZM++//36qqqqyzz77ZPHixXnzzTczderU7LrrrunVq1cqKyuz55571nq/33rrrayyyirp1q1bkuSXv/xlpk6dmhdffDFTpkzJ73//+5x55pnV13D11VenWbNmeemllzJ16tTccccd1QGeJHn33XdrzbH33ntXj58kp59+egYOHJgttthimb82/nMMYRoAAAAAAAAAoBAI1HzNZs2alQYNGlS/SktLs84666yw3x/+8IdsvPHGadKkSbbaaquMGDFipebbcccdU1RUVOdr6NChy+07duzYFBUVpby8fKXmSpI5c+bkhhtuSIsWLXLZZZdVvw477LDccMMNefnll1c4xtIvR/3whz9c6XkBAAD4+g0cODCHHHJI2rZtW6vu2muvzfHHH58mTZokSXr06JGWLVvmX//6V5JkyJAhOfjgg7P11lsnSfbbb79ss802ufHGG5MkN9xwQ7bddtvsu+++SZJtttkmBx10UIYMGZIkGT58eA466KDqk3E6deqUfv365dprr62xjhdeeCF/+ctfcuaZZ9Yov/3226tPbEmSH/zgBznhhBMyePDgJElFRUWOO+643Hvvvdlhhx2SJGVlZdlmm22SJK+//noeffTRDBw4MGVlZWnWrFkuueSSDB06NLNmzcqbb76ZGTNm5IwzzkhpaWmKi4tzwgknpKSkJP/6178yfvz4PPfccxk4cGCaNGmSkpKSnHTSSamsrMzo0aPrfL+vv/76bL311unSpUuS5Lnnnsuxxx6bVq1aJUm23377bL/99hk7dmySpG/fvjn//POr67t165ZNNtkkL7zwQp3jT5o0Kffee29OPvnk6rITTjghY8eOXal7EwAAAAAAAAAAhUSg5mvWvHnzLFy4MAsXLszixYtz5ZVXpl27dsvtc9NNN+XMM8/MgAEDMn78+Bx33HH52c9+tlInuDz++OP585//nBtvvDHl5eUpLy/P+eefn6eeeiqHH374cvt++umnad26dUpLS1f6+pYsWZIJEyYs8zV79uzl9n/77bdzxhlnpG3btunTp08WLly40nMDAADw9Zk+fXpuu+22nHbaaXXWN2jQoMbP77zzTj777LNsvPHGST4Pg2y77bY12my77bZ57rnnVqp+wYIFadiwYY36RYsW5fXXX6/+eeHChTniiCPyxz/+MY0aNarRdlnj//Of/0x5eXnGjh2bNm3a5JVXXslGG22Utm3b5rDDDsuMGTOq+3fq1ClrrLFGdf/u3bunoqIi//znP7PZZptl4403zkUXXZR58+Zl8eLFueKKK9KqVavssMMOWbBgQZKs8Bq+WD5kyJCcfvrp1WUHH3xwrrnmmnz00UepqqrKyJEjM27cuOpTdP7zM5gxY0beeuutbLLJJrXGT5Krrroq++67b9Zaa63qsrXXXrvOtgAAAAAAAAAAhU6g5huw9HSa4uLivPHGG9VfNlqWa6+9NieddFL22muvtG/fPocffngOPPDA/P73v1/hXCUlJXn11VczZsyY6nkffvjhTJ48OUVFRcvt+/TTT2eVVVbJ4sWLa9UtXLgwM2fOrBV4admyZS655JKUlpbm/vvvz+2335477rgj7777bo4//vhsv/32dc5VVVWVu+++Oz/+8Y9zyCGH5M0338y0adPyox/9KA899FCqqqpWeK0AAAB8fYYMGZJdd901G2ywwQrbLly4MAcffHCOOOKI6jDHtGnTaj1Aol27dpk2bdpK1ffq1St33HFHxo4dm8rKyrz66qsZPHhwPvvss+r25557bn76059Wn4LzRcsaf8mSJfn000/z9ttvZ9KkSXnxxRfz3HPP5bXXXsuUKVPyi1/8Ypn9S0tL06pVq0ybNi2NGjXKE088kWeffTbNmjVLkyZNctNNN+XJJ59M69ats+GGG6Zz5845++yzM2fOnCxYsCD9+/fP9OnTa1zDUrfddlvatm2bXXfdtbrsD3/4Q3WoZ5VVVskBBxyQYcOG1fln66qqqhx++OHp3r17evbsWat+5syZuemmm2oEdlbW2muvndVWWy1dunTJeeedlzlz5nzpMQAAAAAAAAAAvmsEar5hzzzzTHbYYYfqn8vLy7No0aIabcrLy2s90bZRo0YpLy9fqTlKS0trtF2yZElKSkpqtJk1a1ZmzpyZJUuWJEnmzp2b4cOHp3379unbt2+tMS+//PK0bNkyl112Wa26UaNG5cYbb8zo0aPzwQcfZPz48UmSCy+8sM71DRs2LOuuu25OPfXUDBkyJFdddVVatmxZfYrOEUcckbXWWiuPP/74Sl0vAAAA/5158+bl+uuvX6nwRVVVVX71q1+lYcOGueaaa6rLKysraz3Iobi4OJWVlStV37t37/Tr1y/HHnts1lhjjZx55pk55phj0rRp0yTJ6NGjM2LEiFx00UV1rmtZ4y+tmzp1asrLyzN48OA0a9Ysq622WgYOHJiRI0fmww8/rLP/F9c4f/787Lrrrtlqq63y2WefZebMmTniiCOy8847Z8qUKSktLc2IESPy2WefZcMNN8zmm2+epk2bVv/zP9/DgQMH1nq/jznmmIwfPz7vvvtu5s6dmzvuuCO9e/eu88/HZ599dt58883cfvvtdb4f1113XbbaaqtsvvnmddYvy5QpUzJx4sRMnTo1N998cx5++OEceOCBX2oMAAAAAAAAAIDvogb1vYDvszFjxuS9995Lr169qst69OhRq92vfvWr/O53v8tPfvKTdOvWLY8//nhuu+223HPPPSs1z38GaioqKtKgQc2PtlOnTkmSJ598MjvuuGOOPPLIbL755hk+fHh+9KMfpUWLFjnnnHOq219wwQXp169fnfNttdVWWWedddKzZ8/84Ac/yGeffZZ//vOfGTZsWJ3tN99881xyySXZb7/90qhRo+rykpKSnHHGGTnhhBPy2GOPZbvttquz/6JFi2qEkGbPnp0kKSuuSkmJk20AoJCVFVfV+CdQv1b2oQDUvxtuuCHrr79+unfvvsLP7cQTT8wrr7ySxx9/PCUlJdXtW7dunenTp9fo//HHH6d169YpLy9Pq1at8vHHH9eonz59etq0aVNd9pvf/Ca/+c1vquuvu+66dOnSJXPmzMkRRxyRm266KQ0aNEh5eXn1AyKW9m3ZsmU++eSTWuMXFRWladOmady4cTbaaKMUFxdXt1lrrbWSJO+//35atGiRTz/9tEb/qqqqzJw5My1atMgdd9yRGTNmZNCgQdXBm9NPPz0PP/xwrr322vTr1y+dOnXK3XffXd2/oqIil19+efr27Vtj3L/85S+ZP39+fvazn1WXT5gwITfddFNef/31dOzYMVVVVdltt91y9NFHp1+/fvnJT35S3X/QoEEZPnx4nnjiiTRv3rzWZ7Zo0aIMGTIkN9988zI/z8rKylRWVtaqX/p5JUnXrl0zcODA7LLLLvnoo4+y2mqr1TnW/6Kl1+D/QwCAfQEAkNgTAACfsycAgML0ZX7vF6j5Bl166aU5/PDD06pVq+qyUaNGpXPnzllnnXWqy0499dQsXLgwP/vZzzJ9+vSsu+66ufHGG+sM39SlrhNq/jNQM2PGjLRo0SIzZszIz372s7z88ssZM2ZMWrVqlUcffTT77LNPnnnmmTz00EMrnK9Vq1YZN25c3n333eywww454YQTct999yVJ3n333eovOS3VpUuXdOnSZZnjNWrUKHvuuecy6wcMGFDn6Td9N6/MqqtWrHC9AMD330U/qqzvJQBJRowYUd9LYCUsDX0cccQRK/zMhg4dmueffz6XXHJJnnvuuRp1HTt2zH333ZdmzZpVl/3tb39LmzZtMmLEiOp/brrpptX199xzT9ZYY406562srMyVV16ZHj165M4778wHH3xQ48/FlZWVWbRoUVq0aJFDDz00jRs3zpNPPlljrL/+9a/p2LFjnnjiiSxcuDBvvPFGHnrooepTXJeesPrOO+9k4cKFeffdd3P33XenSZMmSZL33nsv5eXl+fjjj/OPf/wjS5YsySOPPFJjnfPmzcvLL79c5zWMHj06S5YsycyZM2vUn3feedlll13y6KOPVpe99957SZKxY8fm7bffri6fNGlSJk2aVN1/xIgRueuuu3LJJZfkjTfeyBtvvFFr3pEjR6ZRo0ZZsmTJMj/TyZMnp7KycoWf+b/+9a80aNAgo0ePTllZ2XLb/i8aNWpUfS8BAPgfYV8AACT2BADA5+wJAKCwzJ8/f6XbCtR8Q6677rqMGzcut9xyywrbFhUV5dxzz825556bxYsXp2HDhl9qrrpOqJk9e3ZeeumlWuGWF154IYsXL87o0aPTrl27JEnnzp0zbty4PP744yktLV3uXAcddFD+7//+r/rnadOmpX///rnooovSrFmzrLnmmunTp091/emnn55Bgwat9LUsPUHni84+++yceuqp1T/Pnj07HTt2zMX/Ks6S0pKVHhsA+P4pK67KRT+qzHn/V5xFlUX1vRwoeK/2272+l8BK+POf/5zmzZunf//+KS4uri4/5JBDssYaa+Tyyy9Pklx00UX55z//mWeeeab6ZJcvKi4uzqGHHprTTjst3bt3z1/+8pe88sorGT16dLp06ZKOHTtmu+22y5IlS9KrV6+MHTs2Tz/9dIYPH5499tgjU6dOzbx587Leeutl5syZOeOMM9K2bdsMHDgwDRs2TO/evWvM9/TTT+eoo47KO++8k+TzP49uvPHGmTx5co466qi89dZb+fvf/56zzjorPXr0yB577JFbb701Y8eOzYUXXpiZM2dm4MCB+eUvf5lDDjkkSXL33Xfn73//e37/+99n0aJFGTx4cPbdd98cfPDB2XzzzXP77bfnpZdeyhlnnJGSkpLceuut+fe//53LL788O+20U1544YV07do1paWleeKJJ3Lrrbfm+uuvr3FS7ZgxYzJlypQMGjQoTZs2rS5fvHhxrrvuuvzlL3/JjTfemNatW2fcuHEZOXJkjjnmmPTo0SO33npr7r333owaNSpdu3at8/OsrKzMGWeckfPPP3+5D+a47777smTJkhptHnzwwZSUlGS33XZLWVlZXnvttZxzzjk56aSTsu+++y5zrP9F5eXlGTVqVHbdddcV3tsAAL7f7AsAgMSeAAD4nD0BABSm2bNnr3RbgZpvwLBhw3LaaaflgQceSNu2bb9U3y8bpmnUqFEWLVqU5PNgTpKUlJTklFNOyfrrr59zzjmnRvvddtstu+22W61xGjdunL322muF8w0ePDgLFy5MUVFRSkpKUlZWliZNmmTixIlJkh/+8Id58MEHq9tfccUVueyyy2qMMXHixHTu3DmTJ0+uDvUstfSpwV9UVlZW51NxF1UWZUmFL84CAJ/vCxbZF0C9cxP6u2Hw4ME55ZRTav05a/z48SkvL6/+HC+66KI0adIk2267bY12v/nNb3L++eenV69eueKKK3L44Yfn008/TceOHXPPPfdkiy22SJJ069Ytd9xxR84+++z86le/Sps2bTJ48ODqP3vOmTMn++23Xz777LM0bNgw++yzTx5//PE0bty4znUvPYl16frWXHPNjBgxIieddFLOPffcNGnSJMcff3xOOOGE6j4jRoxInz590rFjxxQVFeXggw/OgAEDqse4//7706dPn6y99topLi7OXnvtlSFDhqS0tDRdunTJ3//+9/Tr1y833HBDFixYkPXWWy/33HNP9Z+r77333uyzzz4pKipKp06dMnTo0Oyxxx411n3VVVfl17/+dY3Ta5dex6OPPppzzjknW265ZebNm5fmzZvn1FNPrQ7wXHzxxVmwYEGNgE6S9OrVK3/84x+TJA888EDmz5+fQw89dLn/DRYXF6e4uLhGmx/+8Ic577zzcsIJJ2TRokVp3rx59Xv4nyfffleUlpb6fxEAkMS+AAD4nD0BAJDYEwBAofkyv+8XVVVVVX2Dayk4t956a4499tjceuut2X///WvUtW/fPsOHD0/nzp2zzjrrZMaMGWnRokV1/X777Zdu3bqlb9++tcYdPXp0Nt9881pfLFq0aFG++BE2aNCgxpdeJkyYUOdckyZNyuabb56333671pd63njjjTRu3LjOJxDXZcmSJdlkk02yxRZb5M9//nMWLVqU2bNnZ7XVVquz/dI1TZkyJe3bt1+pOb5o9uzZad68edY77a4saVD3F60AgMJQVlKVK7aqyG+fLxGogf8BEy7rWd9LAApUeXl5RowYkR49evgLMQAocPYFAEBiTwAAfM6eAAAK09K8waxZs9KsWbPlti3+ltZUMA488MA8//zztcI0K2Px4sVZsmRJnXXbbbddnU/pLSsrS6NGjapfK/sE2YqKinz66aeprKysVbfhhhuudJjm448/zsEHH5wkGTVqVM4999wkWWaYBgAAAAAAAAAAAAAAoL4J1HzNysrKsskmm3zl/osXL87cuXPrfJWXl3+NK/3cvHnz6pxrwYIFy+wza9as3HzzzTn00EOz1lprZfHixXn66aczevTojB49OmussUaOPfbY3HHHHV/7egEAAAAAAAAAAAAAAP5bAjX/YwYMGJCmTZvW+Ro0aNDXPl+nTp3qnGunnXZaZp9GjRpl1KhRWX/99fPiiy/mwQcfTLt27bLBBhvk6aefzqOPPprVV189M2bM+NrXCwAAAAAAAAAAAAAA8N9qUN8LKCRTp06t/veqqqpa9X/729++9jk7depU51zLKl8ZZWVlufPOO5dZ361bt3Tr1u1Lr+nLGnf2LmnduvV/PQ4A8N1VXl6eESNG5NV+u6e0tLS+lwMAAAAAAAAAAAB8RzihBgAAAAAAAAAAAAAAgIIiUAMAAAAAAAAAAAAAAEBBEagBAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFAEagAAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFIEaAAAAAAAAAAAAAAAACopADQAAAAAAAAAAAAAAAAVFoAYAAAAAAAAAAAAAAICCIlADAAAAAAAAAAAAAABAQRGoAQAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBQBGoAAAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBSBGgAAAAAAAAAAAAAAAAqKQA0AAAAAAAAAAAAAAAAFRaAGAAAAAAAAAAAAAACAgiJQAwAAAAAAAAAAAAAAQEERqAEAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUARqAAAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUgRoAAAAAAAAAAAAAAAAKikANAAAAAAAAAAAAAAAABUWgBgAAAAAAAAAAAAAAgIIiUAMAAAAAAAAAAAAAAEBBEagBAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFAEagAAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFIEaAAAAAAAAAAAAAAAACopADQAAAAAAAAAAAAAAAAVFoAYAAAAAAAAAAAAAAICCIlADAAAAAAAAAAAAAABAQRGoAQAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBQBGoAAAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBSBGgAAAAAAAAAAAAAAAAqKQA0AAAAAAAAAAAAAAAAFRaAGAAAAAAAAAAAAAACAgiJQAwAAAAAAAAAAAAAAQEERqAEAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUARqAAAAAAAAAAAAAAAAKCgCNQAAAAAAAAAAAAAAABQUgRoAAAAAAAAAAAAAAAAKikANAAAAAAAAAAAAAAAABUWgBgAAAAAAAAAAAAAAgIIiUAMAAAAAAAAAAAAAAEBBEagBAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFAEagAAAAAAAAAAAAAAACgoAjUAAAAAAAAAAAAAAAAUFIEaAAAAAAAAAAAAAAAACopADQAAAAAAAAAAAAAAAAVFoAYAAAAAAAAAAAAAAICCIlADAAAAAAAAAAAAAABAQRGoAQAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBQBGoAAAAAAAAAAAAAAAAoKA3qewHwZVVVVSVJ5syZk9LS0npeDQBQn8rLyzN//vzMnj3bvgAACpg9AQCwlH0BAJDYEwAAn7MnAIDCNHv27CT/f+5geQRq+M759NNPkyTrrLNOPa8EAAAAAAAAAAAAAAD4XzNnzpw0b958uW0EavjOadWqVZLkgw8+WOEvcADg+2327Nnp2LFjJk2alGbNmtX3cgCAemJPAAAsZV8AACT2BADA5+wJAKAwVVVVZc6cOVl99dVX2Faghu+c4uLiJEnz5s1tcgGAJEmzZs3sCwAAewIAoJp9AQCQ2BMAAJ+zJwCAwrOyB3cUf8PrAAAAAAAAAAAAAAAAgP8pAjUAAAAAAAAAAAAAAAAUFIEavnPKyspywQUXpKysrL6XAgDUM/sCACCxJwAA/n/2BQBAYk8AAHzOngAAWJGiqqqqqvpeBAAAAAAAAAAAAAAAAHxbnFADAAAAAAAAAAAAAABAQRGoAQAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBQBGr4Tlm4cGH69OmTDh06pF27djnooIPy6aef1veyAIB6sOOOO6ZVq1Zp37599atnz571vSwA4FswadKkbLXVVikqKsqSJUuqyysrK9O3b9+sueaaadu2bfbYY49MmDCh/hYKAHyjlrUn6N27d5o3b17jnkGXLl3qcaUAwDfp+eefT48ePdK2bdt06NAhO++8c1566aUk7hUAQCFZ3p7AvQIAYFkEavhOOemkk/L666/nrbfeygcffJAkOfjgg+t5VQBAfbn//vszderU6tfDDz9c30sCAL5h48aNy49//ON07dq1Vt3ll1+e+++/P//3f/+XKVOmZKONNkrPnj1rfMEWAPh+WN6eIEmuvvrqGvcMXnnllW93gQDAt+a3v/1t+vTpkylTpuTDDz9M9+7ds/feeydxrwAACsny9gSJewUAQN0EavjOmDVrVm655ZYMGDAgzZo1S1lZWQYOHJhHH300b7zxRn0vDwAAAPgWdO7cOW+88UatB2xUVVXl6quvTt++fdO+ffuUlJTk4osvzgcffJBRo0bV02oBgG/KsvYEAEDheeyxx9KrV6+UlJSkuLg4hx56aD744INMmzbNvQIAKCDL2xMAACyLQA3fGS+++GKqqqqy1VZbVZetueaaWWuttfLcc8/V48oAAACAb0vr1q3TpEmTWuXvv/9+pk2blm233ba6bJVVVkm3bt3cNwCA76Fl7QkAgMLToEGDGj+PHTs27dq1y9y5c90rAIACsqw9QZs2beppRQDAd4FADd8Z06ZNS+vWrWttfNu1aydFDgAF6qCDDkrbtm2zwQYb5Igjjsi7775b30sCAOrJ0nsD7dq1q1HuvgEAFKYzzjgj7dq1y7rrrpuf//zneemll+p7SQDAt2D8+PE5/fTTM3DgwEyfPj2JewUAUIi+uCcoKSlJ4l4BAFA3gRq+MyorK1NUVFSrvLi4OJWVlfWwIgCgPt1zzz356KOPMn369IwcOTLl5eXZYYcd8tlnn9X30gCAerD03sB/3jtw3wAACs+gQYMyZcqUTJs2LWPGjEnHjh2zww47ZPz48fW9NADgGzRjxozstddeOeKII3LIIYe4VwAABeo/9wSJewUAwLIJ1PCd0bp168ycOTNVVVU1yj/77DPHMgJAAVpttdVSXPz5dnadddbJn/70p3z66ad5/PHH63llAEB9aN26dZLUCte6bwAAheeLp9136NAhgwYNSuvWrfPAAw/U88oAgG/K3Llzs8cee2SLLbbIoEGDkrhXAACFqK49QeJeAQCwbAI1fGdsvvnmWbx4cV577bXqss8++yzvvvtuunXrVo8rAwD+F5SXl6eioiKtWrWq76UAAPWgc+fOad68eV588cXqsiVLluRf//qX+wYAUOCqqqqyePFi9wwA4HtqwYIF2XPPPbP66qvnlltuqT6Rxr0CACgsy9oT1MW9AgBgKYEavjPatWuX/fffP6ecckpmzZqVBQsW5MQTT8yPfvSj/OhHP6rv5QEA36LXXnstv//97zNz5swkyccff5zevXtnyy23zI477livawMA6keDBg1yzDHH5Nxzz82UKVNSXl6evn37pnHjxunZs2d9Lw8A+JZMnz49AwYMyLRp05Ikc+bMyYknnphGjRrlwAMPrOfVAQBft8WLF2ffffdNWVlZ7rzzzuonzyfuFQBAIVnensC9AgBgeRqsuAn87/jjH/+Y448/Puuuu24qKyuz00475cEHH6zvZQEA37IOHTrk9ddfT9euXTN//vwUFRXlgAMOyI033piSkpL6Xh4AUE8uvvjiLFy4MJtttlnKy8vTrVu3jBw5Mqusskp9Lw0A+JY0a9Ysc+bMybbbbpvZs2ensrIyP/3pT/Pkk0+mSZMm9b08AOBrNnbs2IwcOTKtWrXKWmutVaNu+PDh7hUAQIFY3p7gpptucq8AAFimoqqqqqr6XgQAAAAAAAAAAAAAAAB8W4rrewEAAAAAAAAAAAAAAADwbRKoAQAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBQBGoAAAAAAAAAAAAAAAAoKAI1AAAAAAAAAAAAAAAAFBSBGgAAAAAAAAAAAAAAAAqKQA0AAAAAAAAAAAAAAAAFRaAGAAAAAAAAAAAAAACAgiJQAwAAAAAAAAAAAAAAQEERqAEAAAAAAOBb06lTpzRv3jzt27ev8brvvvvqe2kAAAAAAEABaVDfCwAAAAAAAKCwDBo0KEcddVR9LwMAAAAAAChgTqgBAAAAAAAAAAAAAACgoAjUAAAAAAAA8D9n7ty5OfTQQ7PGGmtktdVWy3bbbZdnnnkmSVJVVZVbbrklG220UVq2bJmOHTvmtNNOS5K8/PLL2WmnndKqVau0adMmhx56aD7++OMkyYQJE1JUVJQrrrgiG2ywQZo0aZLx48dnwoQJ2XfffdOhQ4esueaa2WmnnTJu3Lh6u3YAAAAAAOCbJ1ADAAAAAADAt+q0005L+/bta7zGjx9fo80tt9ySsWPH5t133820adNy2WWX5aOPPkqSDBw4MOedd15uvPHGfPbZZxk/fny6deuWKVOmZPvtt0/v3r3zySefZPLkyWncuHF69OiRysrK6rEffPDBjB49OjNnzkyLFi2y33775dRTT82UKVMyefLknHDCCdljjz0yd+7cb/V9AQAAAAAAvj1FVVVVVfW9CAAAAAAAAApDp06d0rdv3xx11FHLbTdmzJj06NEj11xzTQ466KA0bNgwSVJeXp5WrVrlhhtuyC9/+csafS6//PLcf//9NU6XmT9/fpo1a5Znnnkmq6++etZZZ5088cQT2WmnnZIkl112WS688MI0b968xlhz587Nk08+mS233PLruGwAAAAAAOB/jBNqAAAAAAAA+J+z7bbb5tlnn83IkSPTuXPnnHPOOZk1a1Y+/vjjzJ07N126dKnVZ+LEiVlrrbVqlK266qpp06ZNJk6cWF3WsWPH6n9/7733suuuu2bq1Kk1XnPnzhWmAQAAAACA7zGBGgAAAAAAAP4ndenSJX/+85/z8ssv57XXXsvhhx+eVq1apWHDhnnrrbdqtV9rrbVqBGeSZN68efnkk0+yzjrr1DnHGmuskZdeeinl5eXfyDUAAAAAAAD/mwRqAAAAAAAA+J8zZMiQjB49OhUVFWnWrFnatm2bWbNmpVGjRjn55JNz5pln5vnnn09VVVUWLlyY66+/Pr17986bb76ZYcOGpbKyMgsXLsxpp52WH/3oR+nevXud8/z617/O/Pnzc+KJJ2bu3LlJkg8++CBXXnnlt3m5AAAAAADAt0ygBgAAAAAAgP85HTt2zJlnnpnVV189a665ZiZPnpybbropSXLJJZfkhBNOyJFHHpl27dplgw02yIcffpj27dtn9OjR+dOf/pQ2bdpkzTXXzNy5c/Pwww+nqKioznk6dOiQp59+OpMnT07nzp3z/7V3B0UAxCAQBHMqYgn/guBckMd2K1gETHHvPVV1unvzXAAAAAAAYNk3M/N6BAAAAAAAAAAAAAAAAGzxoQYAAAAAAAAAAAAAAIAoghoAAAAAAAAAAAAAAACiCGoAAAAAAAAAAAAAAACIIqgBAAAAAAAAAAAAAAAgiqAGAAAAAAAAAAAAAACAKIIaAAAAAAAAAAAAAAAAoghqAAAAAAAAAAAAAAAAiCKoAQAAAAAAAAAAAAAAIIqgBgAAAAAAAAAAAAAAgCiCGgAAAAAAAAAAAAAAAKIIagAAAAAAAAAAAAAAAIgiqAEAAAAAAAAAAAAAACDKD/r/mVXouq78AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max(preds))\n",
        "print(min(preds))\n",
        "print(preds.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-USM5uS8ckS",
        "outputId": "6a19245a-772f-496d-d7d6-e8671031b7e8"
      },
      "id": "O-USM5uS8ckS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.90583485\n",
            "0.018932145\n",
            "0.29047662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "171c1744-9ae8-4d87-b545-e1b262fc5534",
      "metadata": {
        "id": "171c1744-9ae8-4d87-b545-e1b262fc5534"
      },
      "source": [
        "## 7. Submission (제출 파일 생성)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5052885-f65f-4fc7-9a53-4d8bdce39a58",
      "metadata": {
        "id": "a5052885-f65f-4fc7-9a53-4d8bdce39a58"
      },
      "outputs": [],
      "source": [
        "submit = pd.read_csv('/content/drive/MyDrive/dacon_project_default_prediction/sample_submission.csv')\n",
        "\n",
        "# 결과 저장\n",
        "submit['채무 불이행 확률'] = preds\n",
        "submit.to_csv('/content/drive/MyDrive/dacon_project_default_prediction/submission.csv', encoding='UTF-8-sig', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gimin_py38",
      "language": "python",
      "name": "gimin_py38"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}